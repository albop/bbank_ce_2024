{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Learning consumption rules\n",
        "\n",
        "This exercise is inspired from *Individual learning about consumption*\n",
        "by Todd Allen and Chris Carroll\n",
        "[link](https://www.econstor.eu/bitstream/10419/72016/1/328292125.pdf)\n",
        "and from *Deep Learning for Solving Economic models* by Maliar, Maliar\n",
        "and Winant [link](https://web.stanford.edu/~maliars/Files/JME2021.pdf)\n",
        "\n",
        "We consider the following consumption saving problem. An agent receives\n",
        "random income $y_t = \\exp(\\epsilon_t)$ where\n",
        "$\\epsilon_t\\sim \\mathcal{N}(\\sigma)$ ($\\sigma$ is the standard\n",
        "deviation.)\n",
        "\n",
        "Consumer starts the period with available income $w_t$. The law of\n",
        "motion for available income is:\n",
        "\n",
        "$$w_t = \\exp(\\epsilon_t) + (w_{t-1}-c_{t-1}) r$$\n",
        "\n",
        "where consumption $c_t \\in ]0,w_t]$ is chosen in each period in order to\n",
        "maximize:\n",
        "\n",
        "$$E_t \\sum_{t=0}^T \\beta^t U(c_t)$$\n",
        "\n",
        "given initial available income $w_0$.\n",
        "\n",
        "In the questions below, we will use the following calibration:\n",
        "\n",
        "-   $\\beta = 0.9$\n",
        "-   $\\sigma = 0.1$\n",
        "-   $T=100$\n",
        "-   $U(x) = \\frac{x^{1-\\gamma}}{1-\\gamma}$ with $\\gamma=2$\n",
        "-   $w_0 = 1.1$ (alternatively, consider values 0.5 and 1)\n",
        "\n",
        "The theoretical solution to this problem is a concave function $\\varphi$\n",
        "such that $\\varphi(x)\\in ]0,x]$ and $\\forall t,  c_t=\\varphi(w_t)$.\n",
        "Qualitatively, agents accumulate savings, up to a certain point (a\n",
        "buffer stock), beyond which wealth is not increasing any more (in\n",
        "expectation).\n",
        "\n",
        "Carroll and Allen have noticed that the true solution can be\n",
        "approximated very well by a simple rule:\n",
        "\n",
        "$$\\psi(x) = \\min(x, \\theta_0 + \\theta_1 (x - \\theta_0) )$$\n",
        "\n",
        "The main question they ask in the aforementioned paper is whether it is\n",
        "realistic that agents would learn good values of $\\theta_0$ and\n",
        "$\\theta_1$ by observing past experiences.\n",
        "\n",
        "We would like to examine this result by learning the optimal rule using\n",
        "stochastic gradient descent.\n",
        "\n",
        "In the whole notebook, we use JAX to perform the calculations."
      ],
      "id": "ffc05990-f9b7-40c5-ad02-b2ec5755802e"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from jax import numpy as jnp"
      ],
      "id": "efdff7e4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span class=\"theorem-title\">**Exercise 1**</span> Define a class to\n",
        "represent the parameter values"
      ],
      "id": "a4511b36-6f75-4d19-87d7-da2b5f8bd8b7"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Model:\n",
        "    pass"
      ],
      "id": "d76824f3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span class=\"theorem-title\">**Exercise 2**</span> Define simple rule\n",
        "fonction `consumption(w: float, θ_0:float, θ_1:float, p:Model)->float`\n",
        "which compute consumption using a simple rule. What is the meaning of\n",
        "$\\theta_0$ and $\\theta_1$? Make a plot in the space $w,c$, including\n",
        "consumption rule and the line where $w_{t+1} = w_t$. Check that it works\n",
        "when `w` is a JAX vector."
      ],
      "id": "12dbec9f-d5b4-413e-9201-7a347e4fc4b6"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here"
      ],
      "id": "082caf2e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span class=\"theorem-title\">**Exercise 3**</span> Write a function\n",
        "`lifetime_reward(w_0: float, θ_0: float, θ_1: float, p:Model, key, T)->float`\n",
        "which computes one realization of $\\sum_{t=0}^T \\beta^t U(c_t)$ for\n",
        "initial wealth `w_0` and simple rule `θ_0`, `θ_1` and random key `key`.\n",
        "Mathematically, we denote it by $\\xi(\\omega; \\theta_0, \\theta_1)$, where\n",
        "$\\omega$ represents the succession of random income draws. Check the\n",
        "result is unchanged, when the result is computed from the same original\n",
        "key.\n",
        "\n",
        "What is the gain of using native a JAX loop?\n",
        "\n",
        "Can you JIT compile the resulting fonction? What is the gain of using a\n",
        "native JAX loop?\n",
        "\n",
        "(hint: to use native loop, T needs to be treated as a constant paramete\n",
        ")"
      ],
      "id": "d19b634f-12d1-4708-90f2-3230813e2099"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here"
      ],
      "id": "b4db8afa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span class=\"theorem-title\">**Exercise 4**</span> Write a function\n",
        "`lifetime_reward(w_0: float, θ_0: float, θ_1: float, p:Model, key, N, T)->float`\n",
        "which computes expected lifetime reward using `N` Monte-Carlo draws.\n",
        "Mathematically, we write it\n",
        "$\\Xi^{N}(\\theta_0, \\theta_1) =\\frac{1}{N} \\sum_1^N {\\xi(\\omega_N; \\theta_0, \\theta_1)}$.\n",
        "Check empirically that standard deviation of these draws decrease\n",
        "proportionally to $\\frac{1}{\\sqrt{N}}$ ."
      ],
      "id": "ae63529b-a03b-41c6-9570-a1af3e889bcd"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here"
      ],
      "id": "bcc02e54"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span class=\"theorem-title\">**Exercise 5**</span> Using a high enough\n",
        "number for `N`, compute optimal values for $\\theta_0$ and $\\theta_1$.\n",
        "What is the matching value for the objective function converted into an\n",
        "equivalent stream of deterministic consumption ? That is if `V` is the\n",
        "approximated value computed above, what is $\\bar{c}\\in R$ such that\n",
        "$V= \\sum_{t=0}^T \\beta^t U(\\bar{c})$ ?"
      ],
      "id": "1846de1b-b19d-4db3-b990-15ca3d6e4177"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here"
      ],
      "id": "ff45a8d7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span class=\"theorem-title\">**Exercise 6**</span> Using a high enough\n",
        "number for `N`, make contour plots of lifetime rewards as a function of\n",
        "`θ_0` and `θ_1`. Ideally, represent lines with $1\\%$ consumption loss,\n",
        "$5\\%$ and $10\\%$ deterministic consumption loss w.r.t. to maximum."
      ],
      "id": "020fb990-9410-4b26-868f-211d4be154ef"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here"
      ],
      "id": "ff26876b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Learning to save\n",
        "\n",
        "We now focus on the number of steps it takes to optimize $\\theta_0$,\n",
        "$\\theta_1$.\\_\\_\n",
        "\n",
        "<span class=\"theorem-title\">**Exercise 7**</span> Implement a function\n",
        "`∇(θ:Vector, T, N)::Vector` which computes the gradient of the objective\n",
        "w.r.t. `θ==[θ_0,θ_1]`\\_\\_"
      ],
      "id": "7e9db958-f43f-4455-90fa-3ff545bfa6e2"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here"
      ],
      "id": "19bcfcee"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<span class=\"theorem-title\">**Exercise 8**</span> Implement a gradient\n",
        "descent algorithm to maximize $\\Xi^N(\\theta_0, \\theta_1)$ using learning\n",
        "rate $\\lambda \\in ]0,1]$. Stop after a predefined number of iterations.\n",
        "Compare convergence speed for different values of $\\lambda$ and plot\n",
        "them on the $\\theta_0, \\theta_1$ plan. How many steps does it take to\n",
        "enter the `1%` error zone? The `5%` and the `10%` error zone?"
      ],
      "id": "ca71802b-d188-4f36-abc7-99a1f0855699"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here"
      ],
      "id": "92e6ee6c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Even for big N, the evaluated value of ∇ are stochastic, and always\n",
        "slightly inaccurate. In average, they are non-biased and the algorithm\n",
        "converges in expectation (it fluctuates around the maximum). This is\n",
        "called the stochastic gradient method.\n",
        "\n",
        "<span class=\"theorem-title\">**Exercise 9**</span> What are the values of\n",
        "$N$ and $\\lambda$ which minimize the number of iterations before\n",
        "reaching the target zones (at 1%, 2%, etc…)? How many simulations\n",
        "periods does it correspond to? Would you say it is realistic that\n",
        "consumers learn from their own experience?"
      ],
      "id": "eff1bf4b-f24f-41cf-bd4e-dd07fd7a0093"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here"
      ],
      "id": "3e1b27c3"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/home/pablo/.local/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  }
}