[
  {
    "objectID": "misc/syllabus.html#preparation-session-online-21h",
    "href": "misc/syllabus.html#preparation-session-online-21h",
    "title": "Deep Learning and DSGE modeling",
    "section": "Preparation Session (online: 2*1h)",
    "text": "Preparation Session (online: 2*1h)\n\nInstalling Python\nManaging Python Environments\nSetting up JAX / GPU\nQuick Introduction to Scientific Programming with Python"
  },
  {
    "objectID": "misc/syllabus.html#session-1-introduction-to-deep-learning-3h",
    "href": "misc/syllabus.html#session-1-introduction-to-deep-learning-3h",
    "title": "Deep Learning and DSGE modeling",
    "section": "Session 1: Introduction to Deep Learning (3h)",
    "text": "Session 1: Introduction to Deep Learning (3h)\nPreliminaries:\n\ndifferentiable programming\nscaling-up calculations (vectorization, compilation)\n\nOptimization: Stochastic Gradient Algorithm\nDeep Learning:\n\ncommon neural network topologies\ndealing with symmetries\n\nLiterature Review: Deep Learning Applications in Macroeconomics"
  },
  {
    "objectID": "misc/syllabus.html#session-2-solving-dsge-model-with-deep-learning-3h",
    "href": "misc/syllabus.html#session-2-solving-dsge-model-with-deep-learning-3h",
    "title": "Deep Learning and DSGE modeling",
    "section": "Session 2: Solving DSGE Model with Deep Learning (3h)",
    "text": "Session 2: Solving DSGE Model with Deep Learning (3h)\nWriting DSGE Models with Python\n\nImporting Existing Models\nNonlinearities / Occasionally Binding Constraints\n\nLocal Solution\n\nExistence and Unicity\nPerturbation Solution\n\nGlobal Nonlinear Solution for Generic DSGE Models\nApplication: Zero Lower Bound Model"
  },
  {
    "objectID": "exercises/numeric.html",
    "href": "exercises/numeric.html",
    "title": "Numeric",
    "section": "",
    "text": "Selection from w3resources and rougier/numpy100\n\nExercise 1  \n\nWrite a NumPy program to generate five random numbers from the normal distribution.\n\n\n\n# code here\n\n\nExercise 2 Write a NumPy program to generate six random integers between 10 and 30.\n\n\n# code here\n\n\nExercise 3 Create a 3x3 matrix with values ranging from 0 to 8\n\n\n# code here\n\n\nExercise 4 Create 2d array \\(M\\) such of size 3*3 such that \\(M_{ij} = i\\times j\\)\n\n\n# code here\n\n\nExercise 5 Create 3 vectors of length 5 and create a matrix where each column is one of the vector.\n\n\n# code here\n\n\nExercise 6 Create 3 vectors of length 5 and create a matrix where each row is one of the vector.\n\n\n# code here\n\n\nExercise 7 Find indices of non-zero elements from np.array([1,2,0,0,4,0]). Replace them with -1.0\n\n\n# code here\n\n\nExercise 8 Write a NumPy program to normalize a 3x3 random matrix. (Define norm \\(|x|=\\sqrt{\\sum x_i^2}\\) and compute \\(M/|M|\\))\n\n\n# code here\n\n\nExercise 9 Create 2d array \\(M\\) such of size 3*3 such that \\(M_{ij} = i\\times j\\)\n\n\n# code here\n\n\nExercise 10 Take a random matrix \\(A\\) of size \\(N\\times 2\\) (N=10) where each line represents a different 2d point. Compute the euclidean distance matrix such that \\(E_{ij}\\) is the distance between point \\(i\\) and point \\(j\\).\n\n\n# code here\n\n\nExercise 11 Create A of size \\(10\\times 3\\). Create matrix \\(B\\) with the same column as \\(A\\) reordered by sum of absolute values.",
    "crumbs": [
      "Exercises",
      "Numeric"
    ]
  },
  {
    "objectID": "exercises/numeric.html#using-numpy",
    "href": "exercises/numeric.html#using-numpy",
    "title": "Numeric",
    "section": "",
    "text": "Selection from w3resources and rougier/numpy100\n\nExercise 1  \n\nWrite a NumPy program to generate five random numbers from the normal distribution.\n\n\n\n# code here\n\n\nExercise 2 Write a NumPy program to generate six random integers between 10 and 30.\n\n\n# code here\n\n\nExercise 3 Create a 3x3 matrix with values ranging from 0 to 8\n\n\n# code here\n\n\nExercise 4 Create 2d array \\(M\\) such of size 3*3 such that \\(M_{ij} = i\\times j\\)\n\n\n# code here\n\n\nExercise 5 Create 3 vectors of length 5 and create a matrix where each column is one of the vector.\n\n\n# code here\n\n\nExercise 6 Create 3 vectors of length 5 and create a matrix where each row is one of the vector.\n\n\n# code here\n\n\nExercise 7 Find indices of non-zero elements from np.array([1,2,0,0,4,0]). Replace them with -1.0\n\n\n# code here\n\n\nExercise 8 Write a NumPy program to normalize a 3x3 random matrix. (Define norm \\(|x|=\\sqrt{\\sum x_i^2}\\) and compute \\(M/|M|\\))\n\n\n# code here\n\n\nExercise 9 Create 2d array \\(M\\) such of size 3*3 such that \\(M_{ij} = i\\times j\\)\n\n\n# code here\n\n\nExercise 10 Take a random matrix \\(A\\) of size \\(N\\times 2\\) (N=10) where each line represents a different 2d point. Compute the euclidean distance matrix such that \\(E_{ij}\\) is the distance between point \\(i\\) and point \\(j\\).\n\n\n# code here\n\n\nExercise 11 Create A of size \\(10\\times 3\\). Create matrix \\(B\\) with the same column as \\(A\\) reordered by sum of absolute values.",
    "crumbs": [
      "Exercises",
      "Numeric"
    ]
  },
  {
    "objectID": "exercises/numeric.html#simulating-an-ar1",
    "href": "exercises/numeric.html#simulating-an-ar1",
    "title": "Numeric",
    "section": "Simulating an AR1",
    "text": "Simulating an AR1\nTake an AR1 process \\(x_t = A \\rho x_{t-1} + \\epsilon_t\\) with \\(\\epsilon_t \\sim \\Sigma\\) where \\(\\Sigma\\) is a positive definite matrix.\n\nExercise 12 Define 2x2 matrices \\(A\\) and \\(\\Sigma\\), the latter being symmetric positive definite\n\n\n# code here\n\n\nExercise 13 Compute asymptotic variance using matrix algebra (there is a recursive formula)\n\n\n# code here\n\n\nExercise 14 Simulate \\(N\\) draws for \\(T\\) periods and store the result in sim.\n\n\n# code here\n\n\nExercise 15 Compute ergodic variance (bonus compute std of the variance estimate)\n\n\n# code here\n\n\nExercise 16 Plot a few simulations on the same graph\n\n\n# code here\n\n\nExercise 17 Plot asymptotic distribution (seaborn)\n\n\n# code here\n\n\nExercise 18 Bonus: write a faster simulation routine.\n\n\n# code here",
    "crumbs": [
      "Exercises",
      "Numeric"
    ]
  },
  {
    "objectID": "exercises/training_nl.html",
    "href": "exercises/training_nl.html",
    "title": "Training a Neural Network",
    "section": "",
    "text": "Consider the following (pseudo)-function\n\nimport jax\nfrom jax import numpy as jnp\n\ndef mystery(key):\n    \n    key1, key2 = jax.random.split(key)\n    x = jax.random.uniform(-1,1)\n    epsilon = jax.random.normal(key2)*0.01 # random nmer\n    y = jnp.sin(x)/x + epsilon\n    return (x,y)\n\nThe goal is to learn a function representation using a finite (possibly big) number of draws from the function.\n\nExercise 1 Draw 100 different values and plot them.\n\n\nExercise 2 Create a neural network using library flax (with the linen API), to predict \\(y\\) from \\(x\\).\nInitialize it with random weights and plot the initial guess.\nWe will call \\(\\varphi(x;\\theta)\\) the prediction from the neural network for weights \\(\\theta\\).\n\n\n#\n\n\nExercise 3 Create an objective function \\(\\xi(key, theta, N)\\) for the empirical risk using a minibatch of size \\(N\\).\n\n\n#\n\n\nExercise 4 Compute the gradient of \\(\\xi\\) using jax.\n\n\nExercise 5 Train the neural network, either by hand, or by using Optax. Inspect the result.\n\n\n#"
  },
  {
    "objectID": "exercises/training_nl.html#learning-a-function",
    "href": "exercises/training_nl.html#learning-a-function",
    "title": "Training a Neural Network",
    "section": "",
    "text": "Consider the following (pseudo)-function\n\nimport jax\nfrom jax import numpy as jnp\n\ndef mystery(key):\n    \n    key1, key2 = jax.random.split(key)\n    x = jax.random.uniform(-1,1)\n    epsilon = jax.random.normal(key2)*0.01 # random nmer\n    y = jnp.sin(x)/x + epsilon\n    return (x,y)\n\nThe goal is to learn a function representation using a finite (possibly big) number of draws from the function.\n\nExercise 1 Draw 100 different values and plot them.\n\n\nExercise 2 Create a neural network using library flax (with the linen API), to predict \\(y\\) from \\(x\\).\nInitialize it with random weights and plot the initial guess.\nWe will call \\(\\varphi(x;\\theta)\\) the prediction from the neural network for weights \\(\\theta\\).\n\n\n#\n\n\nExercise 3 Create an objective function \\(\\xi(key, theta, N)\\) for the empirical risk using a minibatch of size \\(N\\).\n\n\n#\n\n\nExercise 4 Compute the gradient of \\(\\xi\\) using jax.\n\n\nExercise 5 Train the neural network, either by hand, or by using Optax. Inspect the result.\n\n\n#"
  },
  {
    "objectID": "exercises/python.html",
    "href": "exercises/python.html",
    "title": "Python Basics",
    "section": "",
    "text": "(adapted from Quantecon)",
    "crumbs": [
      "Exercises",
      "Python Basics"
    ]
  },
  {
    "objectID": "exercises/python.html#basics",
    "href": "exercises/python.html#basics",
    "title": "Python Basics",
    "section": "Basics",
    "text": "Basics\n\nExercise 1 Run the following code in the python interpreter:\ndef say_hello(name):\n    \"\"\"This function prints morning greetings\"\"\"\n\n    print(f\"Good morning {name}!\\n\")\n\n    # we can import libraries\n    import datetime\n    t = datetime.datetime.now()\n\n    # blocks are defined by indentation and colons\n    if (t.hour,t.min) &lt;= (9,15):\n        print(\"All good?\\n\")\n    else:\n        print(\"Time to get started?\\n\")\n\n\nsay_hello(\"Pablo\")\n\n\nExercise 2 What do you think the value of z is after running the code below?\n\nz = 3\nz = z + 4\nprint(\"z is\", z)\n\nz is 7\n\n\n\n\n# your response there\n\n\nExercise 3 Read about what the len function does (by writing len?).\nWhat will it produce if we give it the variable x?\nCheck whether you were right by running the code len(x).\n\n\n# your code here\n\n\nExercise 4 We can use our introspection skills to investigate a package’s contents.\nIn the cell below, use tab completion to find a function from the time module that will display the local time.\nUse time.FUNC_NAME? (where FUNC_NAME is replaced with the function you found) to see information about that function and then call the function.\nLook for something to do with the word local\n\n\nimport time\n# your code here\n\n\nExercise 5 The code below is invalid Python code (once uncommented)\n\n\n# x = 'What's wrong with this string'",
    "crumbs": [
      "Exercises",
      "Python Basics"
    ]
  },
  {
    "objectID": "exercises/python.html#collections",
    "href": "exercises/python.html#collections",
    "title": "Python Basics",
    "section": "Collections",
    "text": "Collections\n\nExercise 6 In the first cell, try y.append(z).\nIn the second cell try y.extend(z).\nExplain the behavior.\nWhen you are trying to explain use y.append? and y.extend? to see a description of what these methods are supposed to do.\n\n\ny = [\"a\", \"b\", \"c\"]\nz = [1, 2, 3]\n# \n\n\ny = [\"a\", \"b\", \"c\"]\nz = [1, 2, 3]\n# \n\n\nExercise 7 Verify that tuples are indeed immutable by attempting the following:\n\nChanging the first element of t to be 100\n\nAppending a new element \"!!\" to the end of t (remember with a list x we would use x.append(\"!!\") to do this\n\nSorting t\n\nReversing t\n\n\n\nt = (1,2,3,4)\n\n\nExercise 8 Look at the World Factbook for Australia and create a dictionary with data containing the following types: float, string, integer, list, and dict. Choose any data you wish.\nTo confirm, you should have a dictionary that you identified via a key.\n\n\n# your code here\n\n\nExercise 9 Use Jupyter’s help facilities to learn how to use the pop method to remove the key \"irrigated_land\" (and its value) from the dict.\n\n\n# uncomment and use the Inspector or ?\n#china_data.pop()\n\n\nExercise 10 Explain what happens to the value you popped.\nExperiment with calling pop twice.\n\n\n# your code here",
    "crumbs": [
      "Exercises",
      "Python Basics"
    ]
  },
  {
    "objectID": "exercises/python.html#control",
    "href": "exercises/python.html#control",
    "title": "Python Basics",
    "section": "Control",
    "text": "Control\n\nExercise 11 Run the following two variations on the code with only a single change in the indentation.\nAfter, modify the x to print 3 and then 2, 3 instead.\n\n\nx = 1\n\nif x &gt; 0:\n    print(\"1\")\n    print(\"2\")\nprint(\"3\")\n\n1\n2\n3\n\n\n\nx = 1\n\nif x &gt; 0:\n    print(\"1\")\nprint(\"2\") # changed the indentation\nprint(\"3\")\n\n1\n2\n3\n\n\n\nExercise 12 Write a for loop that uses the lists of cities and states below to print the same “{city} is in {state}” using a zip instead of an enumerate.\n\n\ncities = [\"Phoenix\", \"Austin\", \"San Diego\", \"New York\"]\nstates = [\"Arizona\", \"Texas\", \"California\", \"New York\"]\n\n\nfor i,c in enumerate(cities):\n    print(c, \" : \", states[i])\n\nPhoenix  :  Arizona\nAustin  :  Texas\nSan Diego  :  California\nNew York  :  New York\n\n\n\n# your code here",
    "crumbs": [
      "Exercises",
      "Python Basics"
    ]
  },
  {
    "objectID": "slides/pres_JHU/slides.html",
    "href": "slides/pres_JHU/slides.html",
    "title": "Quick Introduction to deep learning",
    "section": "",
    "text": "General discussion:\n\nmachine learning / artificial intelligence\ntechnology / technology\n\nIntroduction to deep learning\n\nStochastic Gradient Descent\nNeural Networks\n\nPractical Application\nApplication to an economic model\n\n\n\n\n\nLots of data (consumers, regulators, flights, …)\nTraditionnel models (econometrics for instance) fail\n\ndata is heterogenous\ndoesn’t fit in the memory\ndoesn’t match a model…\n\nMany machine learning algorithms\nHardware developments: (GPU, online computing)\nSoftware stack: linux/git/python/scikit/tensorflow…\n\n\n\n\n\nDeep learning: hugely successful in many different areas:\n\na non-linear structure which self-organizes itself to reach a goal\ncompare with artificial intelligence (achieve a goal without being told how)\n\nChallenges: transferability, explainability\n\n\n\n\n\nReinforcement learning:\n\nsolve a dynamic problem by experimenting with it\nactions have a cost: tradeoff (exploiting/exploring)\nclose to economic RE formulation: \\(\\max \\beta^t r_t\\)\n\nSuccessful applications to:\n\ndriving, trajectory optimizations\ntic-tac-toe, backgammon\nchess, go ! (combined with deep-learning)"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#outline",
    "href": "slides/pres_JHU/slides.html#outline",
    "title": "Quick Introduction to deep learning",
    "section": "",
    "text": "General discussion:\n\nmachine learning / artificial intelligence\ntechnology / technology\n\nIntroduction to deep learning\n\nStochastic Gradient Descent\nNeural Networks\n\nPractical Application\nApplication to an economic model"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#we-are-in-the-big-data-era",
    "href": "slides/pres_JHU/slides.html#we-are-in-the-big-data-era",
    "title": "Quick Introduction to deep learning",
    "section": "",
    "text": "Lots of data (consumers, regulators, flights, …)\nTraditionnel models (econometrics for instance) fail\n\ndata is heterogenous\ndoesn’t fit in the memory\ndoesn’t match a model…\n\nMany machine learning algorithms\nHardware developments: (GPU, online computing)\nSoftware stack: linux/git/python/scikit/tensorflow…"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#what-about-deep-learning",
    "href": "slides/pres_JHU/slides.html#what-about-deep-learning",
    "title": "Quick Introduction to deep learning",
    "section": "",
    "text": "Deep learning: hugely successful in many different areas:\n\na non-linear structure which self-organizes itself to reach a goal\ncompare with artificial intelligence (achieve a goal without being told how)\n\nChallenges: transferability, explainability"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#another-step-towards-ai-reinforcement-learning",
    "href": "slides/pres_JHU/slides.html#another-step-towards-ai-reinforcement-learning",
    "title": "Quick Introduction to deep learning",
    "section": "",
    "text": "Reinforcement learning:\n\nsolve a dynamic problem by experimenting with it\nactions have a cost: tradeoff (exploiting/exploring)\nclose to economic RE formulation: \\(\\max \\beta^t r_t\\)\n\nSuccessful applications to:\n\ndriving, trajectory optimizations\ntic-tac-toe, backgammon\nchess, go ! (combined with deep-learning)"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#optimization",
    "href": "slides/pres_JHU/slides.html#optimization",
    "title": "Quick Introduction to deep learning",
    "section": "Optimization",
    "text": "Optimization\nCheck http://ruder.io/optimizing-gradient-descent/ for more details"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#gradient-descent",
    "href": "slides/pres_JHU/slides.html#gradient-descent",
    "title": "Quick Introduction to deep learning",
    "section": "Gradient descent",
    "text": "Gradient descent\nConsider the scalar function \\(\\Xi(\\theta)\\) where \\(\\theta\\) is a vector.\nDefine \\(\\nabla\\_{\\theta}=   \\begin{bmatrix} \\frac{\\partial}{\\partial \\theta_1} \\\\\\\\...\\\\\\\\\\frac{\\partial}{\\partial \\theta_n} \\end{bmatrix}\\)\n\nGradient descent: go to steepest slope\n\\(\\theta \\leftarrow \\theta - \\gamma \\nabla\\_{\\theta}\\Xi(\\theta)\\)"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#variants-of-gradient-descent",
    "href": "slides/pres_JHU/slides.html#variants-of-gradient-descent",
    "title": "Quick Introduction to deep learning",
    "section": "Variants of Gradient Descent",
    "text": "Variants of Gradient Descent\n\nMomentum: (ball goes down the hill, \\(\\gamma\\) is air-resistence)\n\\[v\\_t = \\gamma v\\_{t-1} + \\eta \\nabla_{\\theta} J(\\theta)\\] \\[\\theta \\leftarrow \\theta - v_t\\]\nNesterov Momentum: (slow down before going up…)\n\\[v\\_t = \\gamma v\\_{t-1} + \\eta \\nabla\\_{\\theta} J\\left(\\theta-\\gamma v\\_{t-1}\\right)\\] \\[\\theta \\leftarrow \\theta - v_t\\] —-"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#variants-of-gradient-descent-2",
    "href": "slides/pres_JHU/slides.html#variants-of-gradient-descent-2",
    "title": "Quick Introduction to deep learning",
    "section": "Variants of Gradient Descent (2)",
    "text": "Variants of Gradient Descent (2)\n\nLearning rate annealing\n\\[\\eta_t = \\eta_0 / ({1+\\kappa t})\\]\nParameter specific updates (ADAM)\n\\[m_t = \\beta\\_1 m\\_{t-1} + (1-\\beta_1) g\\_t\\] \\[v\\_t = \\beta\\_2  v\\_{t-1} + (1-\\beta\\_2) g\\_t^2\\]\n\\[\\theta_\\{t+1} \\leftarrow \\theta_t-\\frac{\\eta}{\\sqrt{\\frac{v_t}{1-\\beta_2^t}+\\epsilon}}\\frac{m_t}{1-\\beta_1^t}\\]\nsee AdaGrad, AdaMax, Rmsprop"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#problem-1-overshooting",
    "href": "slides/pres_JHU/slides.html#problem-1-overshooting",
    "title": "Quick Introduction to deep learning",
    "section": "Problem 1: overshooting",
    "text": "Problem 1: overshooting"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#problem-2-saddle-points",
    "href": "slides/pres_JHU/slides.html#problem-2-saddle-points",
    "title": "Quick Introduction to deep learning",
    "section": "Problem 2: saddle points",
    "text": "Problem 2: saddle points"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#stochastic-gradient-descent",
    "href": "slides/pres_JHU/slides.html#stochastic-gradient-descent",
    "title": "Quick Introduction to deep learning",
    "section": "Stochastic gradient descent",
    "text": "Stochastic gradient descent\n\nGiven \\(\\epsilon \\sim \\mathcal{D}\\), minimize \\[\\Xi(\\theta)=E J(\\theta,\\epsilon)\\]\nIdea: draw a random \\(\\epsilon_t\\) at each step and do: \\[\\theta\\leftarrow \\theta + \\gamma J(\\theta,\\epsilon_t)\\]\nIt works !\n\nReason: \\(\\nabla\\_{\\theta}\\Xi = E\\left[ \\nabla\\_{\\theta} J(\\theta,\\epsilon) \\right]\\)\n\\(\\gamma\\) small, the cumulative last steps (\\(\\sum\\_k \\gamma^k \\nabla\\_{\\theta} J(\\theta\\_{t-k},\\epsilon\\_{t-k})\\) ) are close to unbiased\nlogic extends to other GD algorithms"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#stochastic-gradient-descent-2",
    "href": "slides/pres_JHU/slides.html#stochastic-gradient-descent-2",
    "title": "Quick Introduction to deep learning",
    "section": "Stochastic gradient descent (2)",
    "text": "Stochastic gradient descent (2)\n\nCan escape local minima (with annealing)\nGradient is estimated from a random mini-batch \\((\\epsilon\\_1, ... \\epsilon\\_{N_m})\\)\n\\[\\theta\\leftarrow \\theta + \\gamma \\sum_{i=1:N_m} \\nabla J(\\theta,\\epsilon^i)\\]\nCommon case: dataset set finite \\((\\epsilon_1, ..., \\epsilon_N)\\)\n\nbatch gradient: full dataset\nmini-batch gradient: random (shuffled) \\((\\epsilon\\_i)\\_{i \\in 1:N_m}\\)\nstochastic gradient: one point"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#neural-networks",
    "href": "slides/pres_JHU/slides.html#neural-networks",
    "title": "Quick Introduction to deep learning",
    "section": "Neural networks",
    "text": "Neural networks\nhttp://cs231n.github.io/neural-networks-1/"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#clarifications",
    "href": "slides/pres_JHU/slides.html#clarifications",
    "title": "Quick Introduction to deep learning",
    "section": "Clarifications:",
    "text": "Clarifications:\n\nneural networks and neurons in our brains are two distinct concepts\nbrains do things in different ways (e.g. long range connections)\nNN are fast and their organization is not always inspired by the brain"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#the-perceptron",
    "href": "slides/pres_JHU/slides.html#the-perceptron",
    "title": "Quick Introduction to deep learning",
    "section": "The Perceptron",
    "text": "The Perceptron\nFirst neural neuron, the perception, invented by a psychologist, Dr Rosenblatt (1952):"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#modern-neural-model",
    "href": "slides/pres_JHU/slides.html#modern-neural-model",
    "title": "Quick Introduction to deep learning",
    "section": "Modern neural model",
    "text": "Modern neural model\nEvolution of the model: - arbitrary activation function \\(f\\)\n\n\n\n\n\n\n\nActivation functions\n\nheavyside function: \\(h(x)=1_{x \\geq 0}\\)\nsigmoid (logistic): \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\)\n\ncool fact: \\(\\sigma^\\prime(x)=\\sigma(x)(1-\\sigma(x))\\)\n\narctan\nrelu: \\(r(x)=x*1_{x \\geq 0}\\)\nleaky relu: \\(r(x)=\\kappa x 1\\_{x &lt; 0} + 1\\_{x \\geq 0}\\)\n\n\n\nActivation functions\n\n\n\nTopologies (feed forward 1)\n\nMultilayer perceptron:\n\\[A_0(\\tau_1 (A_1 \\tau_2 (A_2 (.... ) + B_2)) )+ B_1\\]\n\nwhere the \\(\\tau_i\\) are activation functions, A the weights, B the biases.\n\n\n\nTopologies (feed forward 2)\n\nConvolutional networks:\n\nrecognize/classify images\nused for features extraction in other algos\n\nEncoder\n\n\n\n\nTopologies (others)\n\nRecurrent neural network\n\nhave a memory\nuseful for sequential data (speech, text)\n\n\n\n\n\nTraining a neural network (1)\nTwo elements: - choose a network structure - specify an objective - optimize objective w.r.t. deep parameters (weights and biases) - test out of sample\n\n\nTraining a neural network (2)\n\nChoose the right objective:\nregress data \\(y_i\\) on input \\(x_i\\): \\[\\sum_i (f(x_i;\\theta)-y_i)^2\\]\n\npossible regularization term to avoid overfitting\n\\(y_i\\) can be (0,1) for logistic regression\n\nencode data \\(\\sum_i (x_i - f(x_i;\\theta))^2\\)\n\n\n\nTraining a neural network (3)\nPractical challenges: - difficulties in computing derivatives in a numerically stable way - computational intensity grows fast with number of layers - finding good network structure and hyper-parameters is hard\n\n\nThe deep learning technological stack\n\nautomatic differentiation (reverse accumulation)\nvectorization (operates on small batches at a less than proportional cost)\n\nprocessors: SSE, AVX, …\nGPUs: cuda (1920 cores on gtx 1070)\n\nparallelization\n\nscales to very big architectures\n\nsoftware (+ scientific python):\n\ntensorflow, theano, …\nscikit.learn, keras\n\n\n\n\nMental pause\n“The Navy revealed the embryo of an electronic computer today that it expects will be able to walk, talk, see, write, reproduce itself an be conscious of its existence … Dr. Frank Rosenblatt, a research psychologist at the Cornell Aeronautical Laboratory, Buffalo, said Perceptrons might be fired to the planets as mechanical space explorers”\nhttps://www.youtube.com/watch?time_continue=83&v=aygSMgK3BEM\n\n\nMental Pause\nApplications of deeplearning:\nhttp://www.yaronhadad.com/deep-learning-most-amazing-applications/\n\n\nMental Pause\nGo out and play !\n\n\nDeep learning an economic model\nbased on Deep Learning for Solving Dynamic Economic Models with Lilia and Serguei Maliar.\n\nMotivation (1)\nMeta-question: - is RE (e.g. consumption savings) a complicated problem ? - must be simpler than go… - yet we (and computers) have a hard time solving RE problems - if a Neural network can solve it provided the right objective, it must be simple, right ?\n\n\nMotivation (2)\n\nusing machine learning technology should provide fast solution\n\nallows easy vectorization/parallelization\n\nalgorithm might be rather model independent\nNL could reduce intrinsic dimension of high-dimensional problems and make them tractable\n\n\n\nThe problem\n\nDeterministic neo-classical model:\nControlled States: - \\[a\\_t=\\left(1-\\rho\\right)a\\_{t-1}\\] - \\[k\\_t=\\left(1-\\delta\\right)k\\_{t-1} + i\\_{t-1}\\]\nObjective: - \\[\\max\\_{i_t(a_t,k_t)} \\sum\\_t \\beta^t U(c\\_t)\\] - where \\(c_t = k\\_t^{\\theta} - i\\_t\\)\n\n\n\nEuler equation\n\\[1 = \\beta \\frac{U^{\\prime}(c\\_{t+1})}{U^{\\prime}(c\\_{t})}\\left[\\left(1-\\delta \\right)+\\theta k^{\\theta-1}\\right]\\]\n\n\nLoss criterium\n\nSuppose: \\[i(a,k) = \\varphi(a,k;\\theta)\\]\n\\(\\varphi\\) can be any parameterized family of functions:\n\ncomplete polynomials\nneural networks\n\nRewrite Euler equation as: \\[R(a,k;\\theta) = 0\\]\nLoss criterium \\[\\Xi(\\theta) = \\int_{a,k\\in G} R(a,k;\\theta)^2\\]\n\n\n\nLoss criterium 2\n\nFor any random distribution of \\(a,k\\) consider:\n\n\\[\\Xi(\\theta) = E\\_{a,k} R(a,k;\\theta)^2\\]\n\nGiven \\(N_b\\) random values:\n\n\\[\\Omega\\_{N\\_b}(\\theta) = \\frac{1}{N\\_b} \\sum\\_{a_n,k_n} R(a,k;\\theta)^2\\]\n\n\nLoss criterium 3\n\nUsing tensorflow we get easily: \\[\\nabla\\_\\theta \\Omega\\_{N\\_b}(\\theta)\\]\nThe gradient is not biased: \\[E\\_{{a\\_n},k\\_{n}} \\nabla\\_\\theta \\Omega\\_{N\\_b}(\\theta)= \\nabla\\_\\theta \\Xi(\\theta)\\]\n\n\n\nBatch vs Mini-batch\n\n\n\nTraining\n - Algorithm is variant of SGD: ADAM\n\n\nConclusion\n\nConvergence obtained relatively fast:\n\n1000 iterations but \\(1000 N\\_m\\) points visited vs \\(1000 G\\) for time_iteration\n\nExtends to any number of dimensions\nNeural network can (in principle) account for non- differentiabilities\nCan be extended to stochastic case (see paper)"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#activation-functions",
    "href": "slides/pres_JHU/slides.html#activation-functions",
    "title": "Quick Introduction to deep learning",
    "section": "Activation functions",
    "text": "Activation functions\n\nheavyside function: \\(h(x)=1_{x \\geq 0}\\)\nsigmoid (logistic): \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\)\n\ncool fact: \\(\\sigma^\\prime(x)=\\sigma(x)(1-\\sigma(x))\\)\n\narctan\nrelu: \\(r(x)=x*1_{x \\geq 0}\\)\nleaky relu: \\(r(x)=\\kappa x 1\\_{x &lt; 0} + 1\\_{x \\geq 0}\\)"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#activation-functions-1",
    "href": "slides/pres_JHU/slides.html#activation-functions-1",
    "title": "Quick Introduction to deep learning",
    "section": "Activation functions",
    "text": "Activation functions"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#topologies-feed-forward-1",
    "href": "slides/pres_JHU/slides.html#topologies-feed-forward-1",
    "title": "Quick Introduction to deep learning",
    "section": "Topologies (feed forward 1)",
    "text": "Topologies (feed forward 1)\n\nMultilayer perceptron:\n\\[A_0(\\tau_1 (A_1 \\tau_2 (A_2 (.... ) + B_2)) )+ B_1\\]\n\nwhere the \\(\\tau_i\\) are activation functions, A the weights, B the biases."
  },
  {
    "objectID": "slides/pres_JHU/slides.html#topologies-feed-forward-2",
    "href": "slides/pres_JHU/slides.html#topologies-feed-forward-2",
    "title": "Quick Introduction to deep learning",
    "section": "Topologies (feed forward 2)",
    "text": "Topologies (feed forward 2)\n\nConvolutional networks:\n\nrecognize/classify images\nused for features extraction in other algos\n\nEncoder"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#topologies-others",
    "href": "slides/pres_JHU/slides.html#topologies-others",
    "title": "Quick Introduction to deep learning",
    "section": "Topologies (others)",
    "text": "Topologies (others)\n\nRecurrent neural network\n\nhave a memory\nuseful for sequential data (speech, text)"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#training-a-neural-network-1",
    "href": "slides/pres_JHU/slides.html#training-a-neural-network-1",
    "title": "Quick Introduction to deep learning",
    "section": "Training a neural network (1)",
    "text": "Training a neural network (1)\nTwo elements: - choose a network structure - specify an objective - optimize objective w.r.t. deep parameters (weights and biases) - test out of sample"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#training-a-neural-network-2",
    "href": "slides/pres_JHU/slides.html#training-a-neural-network-2",
    "title": "Quick Introduction to deep learning",
    "section": "Training a neural network (2)",
    "text": "Training a neural network (2)\n\nChoose the right objective:\nregress data \\(y_i\\) on input \\(x_i\\): \\[\\sum_i (f(x_i;\\theta)-y_i)^2\\]\n\npossible regularization term to avoid overfitting\n\\(y_i\\) can be (0,1) for logistic regression\n\nencode data \\(\\sum_i (x_i - f(x_i;\\theta))^2\\)"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#training-a-neural-network-3",
    "href": "slides/pres_JHU/slides.html#training-a-neural-network-3",
    "title": "Quick Introduction to deep learning",
    "section": "Training a neural network (3)",
    "text": "Training a neural network (3)\nPractical challenges: - difficulties in computing derivatives in a numerically stable way - computational intensity grows fast with number of layers - finding good network structure and hyper-parameters is hard"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#the-deep-learning-technological-stack",
    "href": "slides/pres_JHU/slides.html#the-deep-learning-technological-stack",
    "title": "Quick Introduction to deep learning",
    "section": "The deep learning technological stack",
    "text": "The deep learning technological stack\n\nautomatic differentiation (reverse accumulation)\nvectorization (operates on small batches at a less than proportional cost)\n\nprocessors: SSE, AVX, …\nGPUs: cuda (1920 cores on gtx 1070)\n\nparallelization\n\nscales to very big architectures\n\nsoftware (+ scientific python):\n\ntensorflow, theano, …\nscikit.learn, keras"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#mental-pause",
    "href": "slides/pres_JHU/slides.html#mental-pause",
    "title": "Quick Introduction to deep learning",
    "section": "Mental pause",
    "text": "Mental pause\n“The Navy revealed the embryo of an electronic computer today that it expects will be able to walk, talk, see, write, reproduce itself an be conscious of its existence … Dr. Frank Rosenblatt, a research psychologist at the Cornell Aeronautical Laboratory, Buffalo, said Perceptrons might be fired to the planets as mechanical space explorers”\nhttps://www.youtube.com/watch?time_continue=83&v=aygSMgK3BEM"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#mental-pause-1",
    "href": "slides/pres_JHU/slides.html#mental-pause-1",
    "title": "Quick Introduction to deep learning",
    "section": "Mental Pause",
    "text": "Mental Pause\nApplications of deeplearning:\nhttp://www.yaronhadad.com/deep-learning-most-amazing-applications/"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#mental-pause-2",
    "href": "slides/pres_JHU/slides.html#mental-pause-2",
    "title": "Quick Introduction to deep learning",
    "section": "Mental Pause",
    "text": "Mental Pause\nGo out and play !"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#motivation-1",
    "href": "slides/pres_JHU/slides.html#motivation-1",
    "title": "Quick Introduction to deep learning",
    "section": "Motivation (1)",
    "text": "Motivation (1)\nMeta-question: - is RE (e.g. consumption savings) a complicated problem ? - must be simpler than go… - yet we (and computers) have a hard time solving RE problems - if a Neural network can solve it provided the right objective, it must be simple, right ?"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#motivation-2",
    "href": "slides/pres_JHU/slides.html#motivation-2",
    "title": "Quick Introduction to deep learning",
    "section": "Motivation (2)",
    "text": "Motivation (2)\n\nusing machine learning technology should provide fast solution\n\nallows easy vectorization/parallelization\n\nalgorithm might be rather model independent\nNL could reduce intrinsic dimension of high-dimensional problems and make them tractable"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#the-problem",
    "href": "slides/pres_JHU/slides.html#the-problem",
    "title": "Quick Introduction to deep learning",
    "section": "The problem",
    "text": "The problem\n\nDeterministic neo-classical model:\nControlled States: - \\[a\\_t=\\left(1-\\rho\\right)a\\_{t-1}\\] - \\[k\\_t=\\left(1-\\delta\\right)k\\_{t-1} + i\\_{t-1}\\]\nObjective: - \\[\\max\\_{i_t(a_t,k_t)} \\sum\\_t \\beta^t U(c\\_t)\\] - where \\(c_t = k\\_t^{\\theta} - i\\_t\\)"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#euler-equation",
    "href": "slides/pres_JHU/slides.html#euler-equation",
    "title": "Quick Introduction to deep learning",
    "section": "Euler equation",
    "text": "Euler equation\n\\[1 = \\beta \\frac{U^{\\prime}(c\\_{t+1})}{U^{\\prime}(c\\_{t})}\\left[\\left(1-\\delta \\right)+\\theta k^{\\theta-1}\\right]\\]"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#loss-criterium",
    "href": "slides/pres_JHU/slides.html#loss-criterium",
    "title": "Quick Introduction to deep learning",
    "section": "Loss criterium",
    "text": "Loss criterium\n\nSuppose: \\[i(a,k) = \\varphi(a,k;\\theta)\\]\n\\(\\varphi\\) can be any parameterized family of functions:\n\ncomplete polynomials\nneural networks\n\nRewrite Euler equation as: \\[R(a,k;\\theta) = 0\\]\nLoss criterium \\[\\Xi(\\theta) = \\int_{a,k\\in G} R(a,k;\\theta)^2\\]"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#loss-criterium-2",
    "href": "slides/pres_JHU/slides.html#loss-criterium-2",
    "title": "Quick Introduction to deep learning",
    "section": "Loss criterium 2",
    "text": "Loss criterium 2\n\nFor any random distribution of \\(a,k\\) consider:\n\n\\[\\Xi(\\theta) = E\\_{a,k} R(a,k;\\theta)^2\\]\n\nGiven \\(N_b\\) random values:\n\n\\[\\Omega\\_{N\\_b}(\\theta) = \\frac{1}{N\\_b} \\sum\\_{a_n,k_n} R(a,k;\\theta)^2\\]"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#loss-criterium-3",
    "href": "slides/pres_JHU/slides.html#loss-criterium-3",
    "title": "Quick Introduction to deep learning",
    "section": "Loss criterium 3",
    "text": "Loss criterium 3\n\nUsing tensorflow we get easily: \\[\\nabla\\_\\theta \\Omega\\_{N\\_b}(\\theta)\\]\nThe gradient is not biased: \\[E\\_{{a\\_n},k\\_{n}} \\nabla\\_\\theta \\Omega\\_{N\\_b}(\\theta)= \\nabla\\_\\theta \\Xi(\\theta)\\]"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#batch-vs-mini-batch",
    "href": "slides/pres_JHU/slides.html#batch-vs-mini-batch",
    "title": "Quick Introduction to deep learning",
    "section": "Batch vs Mini-batch",
    "text": "Batch vs Mini-batch"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#training",
    "href": "slides/pres_JHU/slides.html#training",
    "title": "Quick Introduction to deep learning",
    "section": "Training",
    "text": "Training\n - Algorithm is variant of SGD: ADAM"
  },
  {
    "objectID": "slides/pres_JHU/slides.html#conclusion",
    "href": "slides/pres_JHU/slides.html#conclusion",
    "title": "Quick Introduction to deep learning",
    "section": "Conclusion",
    "text": "Conclusion\n\nConvergence obtained relatively fast:\n\n1000 iterations but \\(1000 N\\_m\\) points visited vs \\(1000 G\\) for time_iteration\n\nExtends to any number of dimensions\nNeural network can (in principle) account for non- differentiabilities\nCan be extended to stochastic case (see paper)"
  },
  {
    "objectID": "slides/index.html",
    "href": "slides/index.html",
    "title": "Ce_bb_2024",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "slides/slides.html#outline",
    "href": "slides/slides.html#outline",
    "title": "Quick Introduction to deep learning",
    "section": "Outline",
    "text": "Outline\n\nGeneral discussion:\n\nmachine learning / artificial intelligence\ntechnology / technology\n\nIntroduction to deep learning\n\nStochastic Gradient Descent\nNeural Networks\n\nPractical Application\nApplication to an economic model"
  },
  {
    "objectID": "slides/slides.html#we-are-in-the-big-data-era",
    "href": "slides/slides.html#we-are-in-the-big-data-era",
    "title": "Quick Introduction to deep learning",
    "section": "We are in the big-data era",
    "text": "We are in the big-data era\n\nLots of data (consumers, regulators, flights, …)\nTraditionnel models (econometrics for instance) fail\n\ndata is heterogenous\ndoesn’t fit in the memory\ndoesn’t match a model…\n\nMany machine learning algorithms\nHardware developments: (GPU, online computing)\nSoftware stack: linux/git/python/scikit/tensorflow…"
  },
  {
    "objectID": "slides/slides.html#what-about-deep-learning",
    "href": "slides/slides.html#what-about-deep-learning",
    "title": "Quick Introduction to deep learning",
    "section": "What about deep learning ?",
    "text": "What about deep learning ?\n\nDeep learning: hugely successful in many different areas:\n\na non-linear structure which self-organizes itself to reach a goal\ncompare with artificial intelligence (achieve a goal without being told how)\n\nChallenges: transferability, explainability"
  },
  {
    "objectID": "slides/slides.html#another-step-towards-ai-reinforcement-learning",
    "href": "slides/slides.html#another-step-towards-ai-reinforcement-learning",
    "title": "Quick Introduction to deep learning",
    "section": "Another step towards AI: reinforcement learning",
    "text": "Another step towards AI: reinforcement learning\n\nReinforcement learning:\n\nsolve a dynamic problem by experimenting with it\nactions have a cost: tradeoff (exploiting/exploring)\nclose to economic RE formulation: \\(\\max \\beta^t r_t\\)\n\nSuccessful applications to:\n\ndriving, trajectory optimizations\ntic-tac-toe, backgammon\nchess, go ! (combined with deep-learning)"
  },
  {
    "objectID": "slides/slides.html#optimization",
    "href": "slides/slides.html#optimization",
    "title": "Quick Introduction to deep learning",
    "section": "Optimization",
    "text": "Optimization\nCheck http://ruder.io/optimizing-gradient-descent/ for more details"
  },
  {
    "objectID": "slides/slides.html#gradient-descent",
    "href": "slides/slides.html#gradient-descent",
    "title": "Quick Introduction to deep learning",
    "section": "Gradient descent",
    "text": "Gradient descent\nConsider the scalar function \\(\\Xi(\\theta)\\) where \\(\\theta\\) is a vector.\nDefine \\(\\nabla_{\\theta}=   \\begin{bmatrix} \\frac{\\partial}{\\partial \\theta_1} \\\\\\\\...\\\\\\\\\\frac{\\partial}{\\partial \\theta_n} \\end{bmatrix}\\)\n\nGradient descent: go to steepest slope\n\\(\\theta \\leftarrow \\theta - \\gamma \\nabla_{\\theta}\\Xi(\\theta)\\)"
  },
  {
    "objectID": "slides/slides.html#variants-of-gradient-descent",
    "href": "slides/slides.html#variants-of-gradient-descent",
    "title": "Quick Introduction to deep learning",
    "section": "Variants of Gradient Descent",
    "text": "Variants of Gradient Descent\n\nMomentum: (ball goes down the hill, \\(\\gamma\\) is air-resistence)\n\\[v_t = \\gamma v_{t-1} + \\eta \\nabla_{\\theta} J(\\theta)\\] \\[\\theta \\leftarrow \\theta - v_t\\]\nNesterov Momentum: (slow down before going up…)\n\\[v_t = \\gamma v_{t-1} + \\eta \\nabla_{\\theta} J\\left(\\theta-\\gamma v_{t-1}\\right)\\] \\[\\theta \\leftarrow \\theta - v_t\\] —-"
  },
  {
    "objectID": "slides/slides.html#variants-of-gradient-descent-2",
    "href": "slides/slides.html#variants-of-gradient-descent-2",
    "title": "Quick Introduction to deep learning",
    "section": "Variants of Gradient Descent (2)",
    "text": "Variants of Gradient Descent (2)\n\nLearning rate annealing\n\\[\\eta_t = \\eta_0 / ({1+\\kappa t})\\]\nParameter specific updates (ADAM)\n\\[m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t\\] \\[v_t = \\beta_2  v_{t-1} + (1-\\beta_2) g_t^2\\]\n\\[\\theta_\\{t+1} \\leftarrow \\theta_t-\\frac{\\eta}{\\sqrt{\\frac{v_t}{1-\\beta_2^t}+\\epsilon}}\\frac{m_t}{1-\\beta_1^t}\\]\nsee AdaGrad, AdaMax, Rmsprop"
  },
  {
    "objectID": "slides/slides.html#problem-1-overshooting",
    "href": "slides/slides.html#problem-1-overshooting",
    "title": "Quick Introduction to deep learning",
    "section": "Problem 1: overshooting",
    "text": "Problem 1: overshooting"
  },
  {
    "objectID": "slides/slides.html#problem-2-saddle-points",
    "href": "slides/slides.html#problem-2-saddle-points",
    "title": "Quick Introduction to deep learning",
    "section": "Problem 2: saddle points",
    "text": "Problem 2: saddle points"
  },
  {
    "objectID": "slides/slides.html#stochastic-gradient-descent",
    "href": "slides/slides.html#stochastic-gradient-descent",
    "title": "Quick Introduction to deep learning",
    "section": "Stochastic gradient descent",
    "text": "Stochastic gradient descent\n\nGiven \\(\\epsilon \\sim \\mathcal{D}\\), minimize \\[\\Xi(\\theta)=E J(\\theta,\\epsilon)\\]\nIdea: draw a random \\(\\epsilon_t\\) at each step and do: \\[\\theta\\leftarrow \\theta + \\gamma J(\\theta,\\epsilon_t)\\]\nIt works !\n\nReason: \\(\\nabla_{\\theta}\\Xi = E\\left[ \\nabla_{\\theta} J(\\theta,\\epsilon) \\right]\\)\n\\(\\gamma\\) small, the cumulative last steps (\\(\\sum_k \\gamma^k \\nabla_{\\theta} J(\\theta_{t-k},\\epsilon_{t-k})\\) ) are close to unbiased\nlogic extends to other GD algorithms"
  },
  {
    "objectID": "slides/slides.html#stochastic-gradient-descent-2",
    "href": "slides/slides.html#stochastic-gradient-descent-2",
    "title": "Quick Introduction to deep learning",
    "section": "Stochastic gradient descent (2)",
    "text": "Stochastic gradient descent (2)\n\nCan escape local minima (with annealing)\nGradient is estimated from a random mini-batch \\((\\epsilon_1, ... \\epsilon_{N_m})\\)\n\\[\\theta\\leftarrow \\theta + \\gamma \\sum_{i=1:N_m} \\nabla J(\\theta,\\epsilon^i)\\]\nCommon case: dataset set finite \\((\\epsilon_1, ..., \\epsilon_N)\\)\n\nbatch gradient: full dataset\nmini-batch gradient: random (shuffled) \\((\\epsilon_i)_{i \\in 1:N_m}\\)\nstochastic gradient: one point"
  },
  {
    "objectID": "slides/slides.html#neural-networks",
    "href": "slides/slides.html#neural-networks",
    "title": "Quick Introduction to deep learning",
    "section": "Neural networks",
    "text": "Neural networks\nhttp://cs231n.github.io/neural-networks-1/"
  },
  {
    "objectID": "slides/slides.html#clarifications",
    "href": "slides/slides.html#clarifications",
    "title": "Quick Introduction to deep learning",
    "section": "Clarifications:",
    "text": "Clarifications:\n\nneural networks and neurons in our brains are two distinct concepts\nbrains do things in different ways (e.g. long range connections)\nNN are fast and their organization is not always inspired by the brain"
  },
  {
    "objectID": "slides/slides.html#the-perceptron",
    "href": "slides/slides.html#the-perceptron",
    "title": "Quick Introduction to deep learning",
    "section": "The Perceptron",
    "text": "The Perceptron\nFirst neural neuron, the perception, invented by a psychologist, Dr Rosenblatt (1952):"
  },
  {
    "objectID": "slides/slides.html#modern-neural-model",
    "href": "slides/slides.html#modern-neural-model",
    "title": "Quick Introduction to deep learning",
    "section": "Modern neural model",
    "text": "Modern neural model\nEvolution of the model: - arbitrary activation function \\(f\\)"
  },
  {
    "objectID": "slides/slides.html#activation-functions",
    "href": "slides/slides.html#activation-functions",
    "title": "Quick Introduction to deep learning",
    "section": "Activation functions",
    "text": "Activation functions\n\nheavyside function: \\(h(x)=1_{x \\geq 0}\\)\nsigmoid (logistic): \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\)\n\ncool fact: \\(\\sigma^\\prime(x)=\\sigma(x)(1-\\sigma(x))\\)\n\narctan\nrelu: \\(r(x)=x*1_{x \\geq 0}\\)\nleaky relu: \\(r(x)=\\kappa x 1_{x &lt; 0} + 1_{x \\geq 0}\\)"
  },
  {
    "objectID": "slides/slides.html#activation-functions-1",
    "href": "slides/slides.html#activation-functions-1",
    "title": "Quick Introduction to deep learning",
    "section": "Activation functions",
    "text": "Activation functions"
  },
  {
    "objectID": "slides/slides.html#topologies-feed-forward-1",
    "href": "slides/slides.html#topologies-feed-forward-1",
    "title": "Quick Introduction to deep learning",
    "section": "Topologies (feed forward 1)",
    "text": "Topologies (feed forward 1)\n\nMultilayer perceptron:\n\\[A_0(\\tau_1 (A_1 \\tau_2 (A_2 (.... ) + B_2)) )+ B_1\\]\n\nwhere the \\(\\tau_i\\) are activation functions, A the weights, B the biases."
  },
  {
    "objectID": "slides/slides.html#topologies-feed-forward-2",
    "href": "slides/slides.html#topologies-feed-forward-2",
    "title": "Quick Introduction to deep learning",
    "section": "Topologies (feed forward 2)",
    "text": "Topologies (feed forward 2)\n\nConvolutional networks:\n\nrecognize/classify images\nused for features extraction in other algos\n\nEncoder"
  },
  {
    "objectID": "slides/slides.html#topologies-others",
    "href": "slides/slides.html#topologies-others",
    "title": "Quick Introduction to deep learning",
    "section": "Topologies (others)",
    "text": "Topologies (others)\n\nRecurrent neural network\n\nhave a memory\nuseful for sequential data (speech, text)"
  },
  {
    "objectID": "slides/slides.html#training-a-neural-network-1",
    "href": "slides/slides.html#training-a-neural-network-1",
    "title": "Quick Introduction to deep learning",
    "section": "Training a neural network (1)",
    "text": "Training a neural network (1)\nTwo elements:\n\nchoose a network structure\nspecify an objective\noptimize objective w.r.t. deep parameters (weights and biases)\ntest out of sample"
  },
  {
    "objectID": "slides/slides.html#training-a-neural-network-2",
    "href": "slides/slides.html#training-a-neural-network-2",
    "title": "Quick Introduction to deep learning",
    "section": "Training a neural network (2)",
    "text": "Training a neural network (2)\n\nChoose the right objective:\nregress data \\(y_i\\) on input \\(x_i\\): \\[\\sum_i (f(x_i;\\theta)-y_i)^2\\]\n\npossible regularization term to avoid overfitting\n\\(y_i\\) can be (0,1) for logistic regression\n\nencode data \\(\\sum_i (x_i - f(x_i;\\theta))^2\\)"
  },
  {
    "objectID": "slides/slides.html#training-a-neural-network-3",
    "href": "slides/slides.html#training-a-neural-network-3",
    "title": "Quick Introduction to deep learning",
    "section": "Training a neural network (3)",
    "text": "Training a neural network (3)\nPractical challenges:\n\ndifficulties in computing derivatives in a numerically stable way\ncomputational intensity grows fast with number of layers\nfinding good network structure and hyper-parameters is hard"
  },
  {
    "objectID": "slides/slides.html#the-deep-learning-technological-stack",
    "href": "slides/slides.html#the-deep-learning-technological-stack",
    "title": "Quick Introduction to deep learning",
    "section": "The deep learning technological stack",
    "text": "The deep learning technological stack\n\nautomatic differentiation (reverse accumulation)\nvectorization (operates on small batches at a less than proportional cost)\n\nprocessors: SSE, AVX, …\nGPUs: cuda (1920 cores on gtx 1070)\n\nparallelization\n\nscales to very big architectures\n\nsoftware (+ scientific python):\n\ntensorflow, theano, …\nscikit.learn, keras"
  },
  {
    "objectID": "slides/slides.html#mental-pause",
    "href": "slides/slides.html#mental-pause",
    "title": "Quick Introduction to deep learning",
    "section": "Mental pause",
    "text": "Mental pause\n“The Navy revealed the embryo of an electronic computer today that it expects will be able to walk, talk, see, write, reproduce itself an be conscious of its existence … Dr. Frank Rosenblatt, a research psychologist at the Cornell Aeronautical Laboratory, Buffalo, said Perceptrons might be fired to the planets as mechanical space explorers”\nhttps://www.youtube.com/watch?time_continue=83&v=aygSMgK3BEM"
  },
  {
    "objectID": "slides/slides.html#mental-pause-1",
    "href": "slides/slides.html#mental-pause-1",
    "title": "Quick Introduction to deep learning",
    "section": "Mental Pause",
    "text": "Mental Pause\nApplications of deeplearning:\nhttp://www.yaronhadad.com/deep-learning-most-amazing-applications/"
  },
  {
    "objectID": "slides/slides.html#mental-pause-2",
    "href": "slides/slides.html#mental-pause-2",
    "title": "Quick Introduction to deep learning",
    "section": "Mental Pause",
    "text": "Mental Pause\nGo out and play !"
  },
  {
    "objectID": "slides/slides.html#motivation-1",
    "href": "slides/slides.html#motivation-1",
    "title": "Quick Introduction to deep learning",
    "section": "Motivation (1)",
    "text": "Motivation (1)\nMeta-question:\n\nis RE (e.g. consumption savings) a complicated problem ?\n\nmust be simpler than go…\nyet we (and computers) have a hard time solving RE problems\nif a Neural network can solve it provided the right objective, it must be simple, right ?"
  },
  {
    "objectID": "slides/slides.html#motivation-2",
    "href": "slides/slides.html#motivation-2",
    "title": "Quick Introduction to deep learning",
    "section": "Motivation (2)",
    "text": "Motivation (2)\n\nusing machine learning technology should provide fast solution\n\nallows easy vectorization/parallelization\n\nalgorithm might be rather model independent\nNL could reduce intrinsic dimension of high-dimensional problems and make them tractable"
  },
  {
    "objectID": "slides/slides.html#the-problem",
    "href": "slides/slides.html#the-problem",
    "title": "Quick Introduction to deep learning",
    "section": "The problem",
    "text": "The problem\nDeterministic neo-classical model:\nControlled States:\n\n\\[a_t=\\left(1-\\rho\\right)a_{t-1}\\]\n\\[k_t=\\left(1-\\delta\\right)k_{t-1} + i_{t-1}\\]\n\nObjective:\n\n\\[\\max_{i_t(a_t,k_t)} \\sum_t \\beta^t U(c_t)\\]\nwhere \\(c_t = k_t^{\\theta} - i_t\\)"
  },
  {
    "objectID": "slides/slides.html#euler-equation",
    "href": "slides/slides.html#euler-equation",
    "title": "Quick Introduction to deep learning",
    "section": "Euler equation",
    "text": "Euler equation\n\\[1 = \\beta \\frac{U^{\\prime}(c_{t+1})}{U^{\\prime}(c_{t})}\\left[\\left(1-\\delta \\right)+\\theta k^{\\theta-1}\\right]\\]"
  },
  {
    "objectID": "slides/slides.html#loss-criterium",
    "href": "slides/slides.html#loss-criterium",
    "title": "Quick Introduction to deep learning",
    "section": "Loss criterium",
    "text": "Loss criterium\n\nSuppose: \\[i(a,k) = \\varphi(a,k;\\theta)\\]\n\\(\\varphi\\) can be any parameterized family of functions:\n\ncomplete polynomials\nneural networks\n\nRewrite Euler equation as: \\[R(a,k;\\theta) = 0\\]\nLoss criterium \\[\\Xi(\\theta) = \\int_{a,k\\in G} R(a,k;\\theta)^2\\]"
  },
  {
    "objectID": "slides/slides.html#loss-criterium-2",
    "href": "slides/slides.html#loss-criterium-2",
    "title": "Quick Introduction to deep learning",
    "section": "Loss criterium 2",
    "text": "Loss criterium 2\n\nFor any random distribution of \\(a,k\\) consider:\n\n\\[\\Xi(\\theta) = E_{a,k} R(a,k;\\theta)^2\\]\n\nGiven \\(N_b\\) random values:\n\n\\[\\Omega_{N_b}(\\theta) = \\frac{1}{N_b} \\sum_{a_n,k_n} R(a,k;\\theta)^2\\]"
  },
  {
    "objectID": "slides/slides.html#loss-criterium-3",
    "href": "slides/slides.html#loss-criterium-3",
    "title": "Quick Introduction to deep learning",
    "section": "Loss criterium 3",
    "text": "Loss criterium 3\n\nUsing tensorflow we get easily: \\[\\nabla_\\theta \\Omega_{N_b}(\\theta)\\]\nThe gradient is not biased: \\[E_{{a_n},k_{n}} \\nabla_\\theta \\Omega_{N_b}(\\theta)= \\nabla_\\theta \\Xi(\\theta)\\]"
  },
  {
    "objectID": "slides/slides.html#batch-vs-mini-batch",
    "href": "slides/slides.html#batch-vs-mini-batch",
    "title": "Quick Introduction to deep learning",
    "section": "Batch vs Mini-batch",
    "text": "Batch vs Mini-batch"
  },
  {
    "objectID": "slides/slides.html#training",
    "href": "slides/slides.html#training",
    "title": "Quick Introduction to deep learning",
    "section": "Training",
    "text": "Training\n - Algorithm is variant of SGD: ADAM"
  },
  {
    "objectID": "slides/slides.html#conclusion",
    "href": "slides/slides.html#conclusion",
    "title": "Quick Introduction to deep learning",
    "section": "Conclusion",
    "text": "Conclusion\n\nConvergence obtained relatively fast:\n\n1000 iterations but \\(1000 N_m\\) points visited vs \\(1000 G\\) for time_iteration\n\nExtends to any number of dimensions\nNeural network can (in principle) account for non- differentiabilities\nCan be extended to stochastic case (see paper)"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#introduction-1",
    "href": "slides/deeplearning_models/slides.html#introduction-1",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Introduction (1)",
    "text": "Introduction (1)\n\nDeeplearning has many impressive applications\n\nreconstruct images/scenes, produce original Chopin music or BOE speeches, play Go…\n\nWorks in “you know more than you think applications”\n\nalgorithmically/mathematically complex\neasy to do by trained humans\n\nSolving a rational expectation model should be easy!\n\nright?"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#introduction-2",
    "href": "slides/deeplearning_models/slides.html#introduction-2",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Introduction (2)",
    "text": "Introduction (2)\n\nResearch presented today:\n\nsolve a simple economic model by deeplearning\nshow that neural networks are flexible and scale well\n\nNot today:\n\nmany impressive application\nreinforcement learning\nbehavioral interpretation"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#existing-approaches",
    "href": "slides/deeplearning_models/slides.html#existing-approaches",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Existing approaches",
    "text": "Existing approaches\n\nMachine learning as a statistical tool (see Susan Athey)\nApproximate policy rules in standard iteration algorithm:\n\nasset pricing with neural networks\nPEA + neural network + genetic algorithm (Duffy and McNelis, 1997!)\nPEA + neural network + backpropagation (Villa and Valaitis)\n\nDeep Reinforcement learning"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#method",
    "href": "slides/deeplearning_models/slides.html#method",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Method",
    "text": "Method\n\nsetup a neural network (aka parameterize policy rule)\nchoose a suitable (scalar) objective measuring how well model is solved\ntrain neural network by minimizing objective\n\nstochastic gradient descent"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#why-does-it-work-now",
    "href": "slides/deeplearning_models/slides.html#why-does-it-work-now",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Why does it work now?",
    "text": "Why does it work now?\n\ncomputational neural networks have been around for a while\n\nperceptron 1952\npopular in the 80s, less so in th 90s\nall the rage again (with deeper networks)\n\na new technological stack\n\nvectorization and parallel computing\n\nGPUS (1920 cores on gtx 1070!)\n\ncloud computing\nsoftware stack:\n\ngit, linux\ntheano, tensorflow"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#model",
    "href": "slides/deeplearning_models/slides.html#model",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Model",
    "text": "Model\n\nVariant of neoclassical model: \\[k_t = \\left( 1-\\delta \\right) k_{t-1} + i_{t-1} \\color{\\red}{\\chi_t}\\] \\[c_t = \\color{\\red}{\\psi_t} + e^{\\color{\\red}{a_t}} k_t^{\\alpha} - i_t\\]\nExogenous processes:\n\n\\(m_t = \\tau(m_{t-1},\\epsilon_t) \\in R^p\\) with \\((\\epsilon_t)\\) i.i.d.\n\n(or any markov process)\n\n\\(\\begin{bmatrix}\n  \\color{\\red}{\\psi_t} & \\color{\\red}{a_t}& \\color{\\red}{\\chi_t}\n  \\end{bmatrix} = p(m_t)\\)\n\nComments:\n\nFlexible \\(\\ni\\) consumption/savings model\nIncrease dimension with specific processes\n\ndefault: \\(\\chi_t=1, \\psi_t=0\\), \\(a_t\\) is an \\(AR1\\)"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#decision-rule",
    "href": "slides/deeplearning_models/slides.html#decision-rule",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Decision Rule",
    "text": "Decision Rule\n\nValue: \\[\\max_{i_t} E_0 \\beta^t U(c_t)\\] \\[0&lt;c_t\\leq\\color{\\red}{\\psi_t} + e^{\\color{\\red}{a_t}k_t^{\\alpha}}\\]\nTime-invariant policy: \\(i_t=\\varphi(m_t, k_t)\\)\nApproximate policy: \\(i_t=\\varphi(m_t, k_t;\\color{blue}{ \\theta})\\)\nParameterized family \\(\\varphi(..; \\color{blue}{ \\theta})\\):\n\ncomplete polynomials (\\(i_t\\approx\\sum_{|i|+j\\leq K}\\color{blue}{\\theta_{i,j}} m_t^i k_t^j\\))\nneural network"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#neural-network",
    "href": "slides/deeplearning_models/slides.html#neural-network",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Neural Network",
    "text": "Neural Network\n\nMultilayer Perceptron\nOne neuron \\(n\\) takes input \\(x_1, ... x_{k_n}\\)\n\noutputs \\(\\tau(a_1 x_1 + ... + a_{k_n} x_{k_n} + b_n)\\) with \\(\\tau(u)\\) an activation function\n\nOne layer \\(n\\) of multilayer perceptron\n\n\\(\\tau(A_n X_n + B_n)\\)\nnumber of rows of \\(B_n\\) is width of layer"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#neural-networks",
    "href": "slides/deeplearning_models/slides.html#neural-networks",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Neural Networks",
    "text": "Neural Networks\n\nWhole network:\n\n\\[i_t = A_3 \\tau(A_2 \\tau( A_1\n  \\begin{pmatrix} a_t \\\\ k_t  \\end{pmatrix} + B_1) + B_2) + B_3\\]\n\\(\\theta = ( (A_1, B_1), (A_2, B_2), ... )\\): to be trained\n\nNice properties:\n\nuniversal approximators\n\\(\\nabla_{\\theta} i_t\\) can be computed exactly.\nscales up linearly:\n\nreplace $\n\\[\\begin{pmatrix} a_t \\\\ k_t  \\end{pmatrix}\\]\n$ by \\(\\begin{pmatrix} a_t \\\\ \\chi_t, \\psi_t \\\\ k_t  \\end{pmatrix}\\), only \\(A_1, B_1\\) changes.\n\n\nWe use multilayer perceptron with 3 hidden layers with width 20 and relu activation function"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#set-up-objective",
    "href": "slides/deeplearning_models/slides.html#set-up-objective",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Set-up objective",
    "text": "Set-up objective\n\nAlternatives we consider\n\nfit decision rule (not in this presentation)\nmaximize lifetime reward dynamics starting from initial state\nminimize error on state-space\n\nCareful what you wish for!\n\ndifferent objectives, different criteria\ncomputational efficiency, asymptotic precision\n\nMore objectives (trade-offs…):\n\nregularity\nmoment matching"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#learning-lifetime-reward",
    "href": "slides/deeplearning_models/slides.html#learning-lifetime-reward",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Learning lifetime reward",
    "text": "Learning lifetime reward\n\nStochastic reward for \\(\\epsilon=(\\epsilon_0, \\cdots, \\epsilon_T)\\): \\[\\xi(\\epsilon; \\theta) = \\sum_{t \\geq 0}^T \\beta^t U(c_t)\\]\nObjective: \\(\\max_{\\theta}  \\Xi(\\theta) = E_{\\epsilon} \\xi\\left( \\epsilon; \\theta \\right)\\)\nCompute gradient: \\(\\nabla_{\\theta}V\\)\n\nback-in-time propagation\neasy with tensorflow:\n\nautomatic differentiation\nparallel computation is cheap (gpus, clusters)"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#stochastic-gradient",
    "href": "slides/deeplearning_models/slides.html#stochastic-gradient",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Stochastic Gradient",
    "text": "Stochastic Gradient\n\nGoal: minimize theoretical risk \\(\\Xi(\\theta) = E_{\\epsilon} \\left[ \\xi(\\epsilon; \\theta) \\right]\\)\nGradient Descent: (learning rate \\(\\lambda\\)) \\[\\theta_{n+1} \\leftarrow \\left( 1-\\lambda \\right) \\theta_{n} - \\lambda \\nabla_{\\theta} \\color{red}{E_{\\epsilon} \\left[ \\xi(\\epsilon; \\theta) \\right]}\\]\nStochastic Gradient Descent: \\[\\theta_{n+1} \\leftarrow \\left(1-\\lambda_n\\right) \\theta_{n} - \\lambda_n \\color{red}{\\nabla_{\\theta}\\xi(\\epsilon; \\theta)}\\]\n\nunbiased: \\(\\nabla_{\\theta} E_{\\epsilon} \\left[ \\xi(\\epsilon; \\theta) \\right] = E_{\\epsilon} \\left[ \\nabla_{\\theta}  \\xi(\\epsilon; \\theta) \\right]\\)\nconverges with \\(\\lambda_n\\rightarrow 0\\) and \\(\\sum \\frac{1}{\\lambda_n}=\\infty\\)\n\nBatch Stochastic Gradient Descent: \\[\\theta_{n+1} \\leftarrow \\left(1-\\lambda_n\\right) \\theta_{n} - \\lambda_n \\color{red}{\\sum_{i=1}^N \\nabla_{\\theta}\\xi(\\epsilon_n; \\theta)} \\]"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#maximizing-lifetime-expected-reward",
    "href": "slides/deeplearning_models/slides.html#maximizing-lifetime-expected-reward",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Maximizing lifetime expected reward",
    "text": "Maximizing lifetime expected reward\n\n\n\ncomplete polynomials (neoclassical)\n\nlearning rate \\(\\lambda=0.005\\), \\(N_{minibatches}=8\\)\ninitial capital \\(k_0 = \\frac{\\overline{k}}{2}\\)\ncomplete polynomials, order 3"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#maximizing-consumption-savings",
    "href": "slides/deeplearning_models/slides.html#maximizing-consumption-savings",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Maximizing consumption savings",
    "text": "Maximizing consumption savings\n.."
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#using-euler-equations",
    "href": "slides/deeplearning_models/slides.html#using-euler-equations",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Using Euler equations",
    "text": "Using Euler equations\n\nOptimality conditions on a domain for states \\(\\mathcal{G}\\): \\[\\forall s \\in \\mathcal{G},  E_{\\epsilon} \\left[ \\Phi(s,\\epsilon;\\theta)\\right] = 0\\]\nSingle objective: \\[\\min_{\\theta}\\Xi\\left( \\theta \\right) ={\\int}_{s \\in \\mathcal{G}} \\left( E_{\\epsilon} \\Phi\\left(s,\\epsilon;\\theta\\right) \\right)^2\\]\nWith \\(s\\) uniformly distributed on \\(\\mathcal{G}\\), and \\(\\epsilon_1,\\epsilon_2\\) distributed as \\(\\epsilon\\): \\[\\Xi\\left( \\theta \\right) = E_{s} \\left[\\left(E_{\\epsilon_1} \\Phi\\left(s,\\epsilon_1;\\theta\\right)\\right) \\left( E_{\\epsilon_2}\\Phi\\left(s,\\epsilon_2;\\theta\\right)\\right)\\right]\\] \\[\\Xi\\left( \\theta \\right) = E_{s,\\epsilon_1,\\epsilon_2}\\left[ \\underbrace{ \\Phi\\left(s,\\epsilon_1;\\theta\\right) \\Phi\\left(s,\\epsilon_2;\\theta\\right)}_{\\xi(s,\\epsilon_1,\\epsilon_2;\\theta)}\\right]\\]\nSGD training is possible"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#minimize-euler-equations-errors",
    "href": "slides/deeplearning_models/slides.html#minimize-euler-equations-errors",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Minimize euler equations errors",
    "text": "Minimize euler equations errors\n\n\nlearning rate \\(\\lambda=0.05\\), \\(N_{minibatches}=10\\)\ninitial capital \\(k_0 = \\frac{\\overline{k}}{2}\\)\ncomplete polynomials of order \\(3\\)"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#comparison-with-value-training-cp",
    "href": "slides/deeplearning_models/slides.html#comparison-with-value-training-cp",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Comparison with Value training (cp)",
    "text": "Comparison with Value training (cp)\n\n\ncomplete polynomial"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#minimize-euler-equations-neural-networks",
    "href": "slides/deeplearning_models/slides.html#minimize-euler-equations-neural-networks",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Minimize euler equations (neural networks)",
    "text": "Minimize euler equations (neural networks)\n\nADAM optimizer, \\(N_{minibatches}=64\\)\ninitial capital \\(k_0 = \\frac{\\overline{k}}{2}\\)\nneural network, three hidden layers, sigmoid, width 32"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#comparison-with-value-training-nl",
    "href": "slides/deeplearning_models/slides.html#comparison-with-value-training-nl",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Comparison with Value training (nl)",
    "text": "Comparison with Value training (nl)\n\nComparaison Euler/Value\nneural networks"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#scale-up",
    "href": "slides/deeplearning_models/slides.html#scale-up",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Scale-up",
    "text": "Scale-up\n\nhigher dimension world (for \\(l = a,\\chi,\\psi\\))\n\n\\(l_t = \\exp(\\hat{l}_t)\\exp(\\epsilon^l_t)\\), \\(\\hat{l}_t = \\rho_l \\hat{l}_{t-1}+ \\tau^l_t\\), \\((\\epsilon^l_t)\\) i.i.d.\n4 states \\(\\left(\\hat{a}_t,\\hat{\\chi}_t,\\hat{\\psi}_t,\\hat{k}_t\\right)\\)\n\ndoes dimension reduction work ?\n\ncompare learning with with full model and with \\(\\chi_t\\), \\(\\psi_t\\) muted: useless states should be eliminated\nsolve true 4 states model"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#scale-up-2",
    "href": "slides/deeplearning_models/slides.html#scale-up-2",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Scale-up (2)",
    "text": "Scale-up (2)\n\nit works!\n\ntraining properties don’t depend on number of shocks (computational time)"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#comments-of-the-method",
    "href": "slides/deeplearning_models/slides.html#comments-of-the-method",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Comments of the method",
    "text": "Comments of the method\n\nadvantages\n\nneural networks:\n\nflexible functional form (kinks)\nrobust to colinearity\nimplicit dimensionality reduction\n\ngeneric training method\nscales well\n\nlots of hyperparameters to be tuned:\n\nlearning method (SGD, ADAM, AdaGrad, RmsProp)\nneural network topology (activation functions, width)"
  },
  {
    "objectID": "slides/deeplearning_models/slides.html#conclusion",
    "href": "slides/deeplearning_models/slides.html#conclusion",
    "title": "Deep Learning for Solving Dynamic Economic Models",
    "section": "Conclusion",
    "text": "Conclusion\n\nwhat are we doing ?\n\ndeep learning\nreinforcement learning\nartificial intelligence\n\nare economists complicating the matter at will?\nfuture work:\n\nmore complex problems, understand trade-offs\nfocus on performance\nbehavioral interpretation (rational innatention, sparse programing)"
  },
  {
    "objectID": "slides/python.html#why-python-3",
    "href": "slides/python.html#why-python-3",
    "title": "Python",
    "section": "Why Python? (3)",
    "text": "Why Python? (3)\nHistorically, python was a glue language used to interoperate many low-level/system languages.\nIt has been increasingly used for web-development (cf django)\n\n\n\nNowadays it is the lingua franca of machine learning\nMost major machine learning / deep learning libraries have python bindings",
    "crumbs": [
      "Slides",
      "Python"
    ]
  },
  {
    "objectID": "slides/python.html#an-example",
    "href": "slides/python.html#an-example",
    "title": "Python",
    "section": "An example",
    "text": "An example\ndef say_hello(name):\n    \"\"\"This function prints morning greetings\"\"\"\n\n    print(f\"Good morning {name}!\\n\")\n\n    # we can import libraries\n    import datetime\n    t = datetime.datetime.now()\n\n    # blocks are defined by indentation and colons\n    if (t.hour,t.min) &lt;= (9,15):\n        print(\"All good?\\n\")\n    else:\n        print(\"Time to get started?\\n\")\n\n\nsay_hello(\"Pablo\")",
    "crumbs": [
      "Slides",
      "Python"
    ]
  },
  {
    "objectID": "slides/python.html#python-is-everywhere",
    "href": "slides/python.html#python-is-everywhere",
    "title": "Python",
    "section": "Python is everywhere",
    "text": "Python is everywhere\n\n\n\n\n\nCode Warriors\n\n\n\n\n\nWindows\nLinux\nWeb",
    "crumbs": [
      "Slides",
      "Python"
    ]
  },
  {
    "objectID": "slides/python.html#the-python-family",
    "href": "slides/python.html#the-python-family",
    "title": "Python",
    "section": "The Python family",
    "text": "The Python family\nThere are several flavours of Python:\n\n\n\nFull Syntax\n\nCPython, PyPy, Pyston\n\nSubset-Syntax\n\nmicropython\nnumba, pythran\n\n\n\n\nSuperset-Syntax\n\nmypy (*)\ncython\nmojo\n\nNear-Syntax\n\nboo\n\n\n\n\nsubset-syntax: restrict functionalities (no classes, simpler objects) for easier compilation\nsuperset-syntax: add type/memory information\nnear-syntax: different language that looks familiar",
    "crumbs": [
      "Slides",
      "Python"
    ]
  },
  {
    "objectID": "slides/python.html#examples",
    "href": "slides/python.html#examples",
    "title": "Python",
    "section": "Examples",
    "text": "Examples\n\nmojo:\n\nfn greet2(name: String) -&gt; String:\n    return \"Hello, \" + name + \"!\"\n\ncython\n\nfrom libcpp.vector cimport vector\n\ndef primes(unsigned int nb_primes):\n\n    cdef int n, i\n    cdef vector[int] p\n    p.reserve(nb_primes)  # allocate memory for 'nb_primes' elements.\n\n    n = 2\n    while p.size() &lt; nb_primes:  # size() for vectors is similar to len()\n        for i in p:\n            if n % i == 0:\n                break",
    "crumbs": [
      "Slides",
      "Python"
    ]
  },
  {
    "objectID": "slides/python.html#python-is-interpreted",
    "href": "slides/python.html#python-is-interpreted",
    "title": "Python",
    "section": "Python is interpreted",
    "text": "Python is interpreted\n\n\n\n\n\n\n\nInterpreted language\n\n\nIn an interpreted language, instructions are read and translated into processor instructions, one after another.\n\n\n\n\nAs consequence, it is:\n\nflexible\n\ninteractive development\nimmediate feedback\n\nslooooww 1\n\nactualy not so much because python modules are converted into bytecode and because common objects are well optimized",
    "crumbs": [
      "Slides",
      "Python"
    ]
  },
  {
    "objectID": "slides/python.html#intepreters",
    "href": "slides/python.html#intepreters",
    "title": "Python",
    "section": "Intepreters",
    "text": "Intepreters\n\nPython\nipython a.k.a. jupyter\n\nsend instructions to a kernel\nreceive back MIME objects (with nice html representation)\n\nVSCode\n\nhas its own python kernel implementation\n\nC API python.h\n\njulia\nyour own…",
    "crumbs": [
      "Slides",
      "Python"
    ]
  },
  {
    "objectID": "slides/python.html#python-modules",
    "href": "slides/python.html#python-modules",
    "title": "Python",
    "section": "Python modules",
    "text": "Python modules\nA file ending with .py is a python module\n\nprogram.py\n\nkey = \"low\"\ndef something():\n    return \"hey\"\nThe content from a module can be imported\nfrom program import something\nTo import all objects in a module (functions, strings, …)\nfrom program import *",
    "crumbs": [
      "Slides",
      "Python"
    ]
  },
  {
    "objectID": "slides/python.html#submodules",
    "href": "slides/python.html#submodules",
    "title": "Python",
    "section": "Submodules",
    "text": "Submodules\n\nA folder containing modules and an __init.py__ is a package.\nimport a package or a submodule:\n\nimport package\nfrom package.submodule import something\n\nThe content of modules and submodules is evaluated only once.1\nIt is actually precompiled.\nThis is perfect for distributing a package.\nNot so much to develop code interactively.\n\nsince python 3.4 you can actually reload a module with importlib.reload()",
    "crumbs": [
      "Slides",
      "Python"
    ]
  },
  {
    "objectID": "slides/python.html#package-managers",
    "href": "slides/python.html#package-managers",
    "title": "Python",
    "section": "Package managers",
    "text": "Package managers\nSeveral ways to create / distribute python packages have been developped over the years.\n\nsetup.py, pip\nsetuptools, distutils, …\npipenv, poetry, …\nconda\n\nThere are essentially two kinds of packages:\n\npip packages\nconda packages",
    "crumbs": [
      "Slides",
      "Python"
    ]
  },
  {
    "objectID": "slides/python.html#pip-packages",
    "href": "slides/python.html#pip-packages",
    "title": "Python",
    "section": "Pip packages",
    "text": "Pip packages\n\npip files (what are eggs btw)\n\npure python\nbinary\n\ncan be installed with pip install package\nno dependency solving ! no proper uninstallation !\npip files a virtual evnironment created with venv\nreproducible setup can be described in\n\nrequirements.txt (old)\npyproject.toml (new)\n\ndirectory specific environments can be managed with poetry or venv:\n\npython -m venv directory",
    "crumbs": [
      "Slides",
      "Python"
    ]
  },
  {
    "objectID": "slides/python.html#conda-environment",
    "href": "slides/python.html#conda-environment",
    "title": "Python",
    "section": "Conda environment",
    "text": "Conda environment\n\nconda files\ninstalled in a conda environment\nwith proper / reversible dependency solving\n\nvery quick using mamba or micromamba\n\nreproducible environment can be described in:\n\nenvironment.yml (dependencies)\nmanifest (…)\n\ndirectory specific environments can be managed with pixi",
    "crumbs": [
      "Slides",
      "Python"
    ]
  },
  {
    "objectID": "slides/python.html#section",
    "href": "slides/python.html#section",
    "title": "Python",
    "section": "",
    "text": "Let’s setup the environment specified in requirements.txt\n\n\nMove to python syntax tutorial",
    "crumbs": [
      "Slides",
      "Python"
    ]
  },
  {
    "objectID": "handson/jax_intro.html",
    "href": "handson/jax_intro.html",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "This notebook (adapted Quantecon) provides a short introduction to Google JAX.\n\n\nOne way to use JAX is as a plug-in NumPy replacement. Let’s look at the similarities and differences.\n\n\nThe following import is standard, replacing import numpy as np:\n\nimport jax\nimport jax.numpy as jnp\n\nNow we can use jnp in place of np for the usual array operations:\n\na = jnp.asarray((1.0, 3.2, -1.5))\n\n\nprint(a)\n\n[ 1.   3.2 -1.5]\n\n\n\nprint(jnp.sum(a))\n\n2.7\n\n\n\nprint(jnp.mean(a))\n\n0.90000004\n\n\n\nprint(jnp.dot(a, a))\n\n13.490001\n\n\nHowever, the array object a is not a NumPy array:\n\na\n\nArray([ 1. ,  3.2, -1.5], dtype=float32)\n\n\n\ntype(a)\n\njaxlib.xla_extension.ArrayImpl\n\n\nEven scalar-valued maps on arrays return JAX arrays.\n\njnp.sum(a)\n\nArray(2.7, dtype=float32)\n\n\nJAX arrays are also called “device arrays,” where term “device” refers to a hardware accelerator (GPU or TPU).\n(In the terminology of GPUs, the “host” is the machine that launches GPU operations, while the “device” is the GPU itself.)\nOperations on higher dimensional arrays are also similar to NumPy:\n\nA = jnp.ones((2, 2))\nB = jnp.identity(2)\nA @ B\n\nArray([[1., 1.],\n       [1., 1.]], dtype=float32)\n\n\n\nfrom jax.numpy import linalg\n\n\nlinalg.inv(B)   # Inverse of identity is identity\n\nArray([[1., 0.],\n       [0., 1.]], dtype=float32)\n\n\n\nlinalg.eigh(B)  # Computes eigenvalues and eigenvectors\n\nEighResult(eigenvalues=Array([1., 1.], dtype=float32), eigenvectors=Array([[1., 0.],\n       [0., 1.]], dtype=float32))\n\n\n\n\n\nOne difference between NumPy and JAX is that JAX currently uses 32 bit floats by default.\nThis is standard for GPU computing and can lead to significant speed gains with small loss of precision.\nHowever, for some calculations precision matters. In these cases 64 bit floats can be enforced via the command\n\njax.config.update(\"jax_enable_x64\", True)\n\nLet’s check this works:\n\njnp.ones(3)\n\nArray([1., 1., 1.], dtype=float64)\n\n\nAs a NumPy replacement, a more significant difference is that arrays are treated as immutable.\nFor example, with NumPy we can write\n\nimport numpy as np\na = np.linspace(0, 1, 3)\na\n\narray([0. , 0.5, 1. ])\n\n\nand then mutate the data in memory:\n\na[0] = 1\na\n\narray([1. , 0.5, 1. ])\n\n\nIn JAX this fails:\n\na = jnp.linspace(0, 1, 3)\na\n\nArray([0. , 0.5, 1. ], dtype=float64)\n\n\n\n# a[0] = 1\n\nIn line with immutability, JAX does not support inplace operations:\n\na = np.array((2, 1))\na.sort()\na\n\narray([1, 2])\n\n\n\na = jnp.array((2, 1))\na_new = a.sort()\na, a_new\n\n(Array([2, 1], dtype=int64), Array([1, 2], dtype=int64))\n\n\nThe designers of JAX chose to make arrays immutable because JAX uses a functional programming style. More on this below.\nNote that, while mutation is discouraged, it is in fact possible with at, as in\n\na = jnp.linspace(0, 1, 3)\nid(a)\n\n110315613819424\n\n\n\na\n\nArray([0. , 0.5, 1. ], dtype=float64)\n\n\n\na.at[0].set(1)\n\nArray([1. , 0.5, 1. ], dtype=float64)\n\n\nWe can check that the array is mutated by verifying its identity is unchanged:\n\nid(a)\n\n110315613819424\n\n\n\n\n\n\nRandom numbers are also a bit different in JAX, relative to NumPy. Typically, in JAX, the state of the random number generator needs to be controlled explicitly.\n\nimport jax.random as random\n\nFirst we produce a key, which seeds the random number generator.\n\nkey = random.PRNGKey(1)\n\n\ntype(key)\n\njaxlib.xla_extension.ArrayImpl\n\n\n\nprint(key)\n\n[0 1]\n\n\nNow we can use the key to generate some random numbers:\n\nx = random.normal(key, (3, 3))\nx\n\nArray([[-1.35247421, -0.2712502 , -0.02920518],\n       [ 0.34706456,  0.5464053 , -1.52325812],\n       [ 0.41677264, -0.59710138, -0.5678208 ]], dtype=float64)\n\n\nIf we use the same key again, we initialize at the same seed, so the random numbers are the same:\n\nrandom.normal(key, (3, 3))\n\nArray([[-1.35247421, -0.2712502 , -0.02920518],\n       [ 0.34706456,  0.5464053 , -1.52325812],\n       [ 0.41677264, -0.59710138, -0.5678208 ]], dtype=float64)\n\n\nTo produce a (quasi-) independent draw, best practice is to “split” the existing key:\n\nkey, subkey = random.split(key)\n\n\nrandom.normal(key, (3, 3))\n\nArray([[ 1.85374374, -0.37683949, -0.61276867],\n       [-1.91829718,  0.27219409,  0.54922246],\n       [ 0.40451442, -0.58726839, -0.63967753]], dtype=float64)\n\n\n\nrandom.normal(subkey, (3, 3))\n\nArray([[-0.4300635 ,  0.22778552,  0.57241269],\n       [-0.15969178,  0.46719192,  0.21165091],\n       [ 0.84118631,  1.18671326, -0.16607783]], dtype=float64)\n\n\nThe function below produces k (quasi-) independent random n x n matrices using this procedure.\n\ndef gen_random_matrices(key, n, k):\n    matrices = []\n    for _ in range(k):\n        key, subkey = random.split(key)\n        matrices.append(random.uniform(subkey, (n, n)))\n    return matrices\n\n\nmatrices = gen_random_matrices(key, 2, 2)\nfor A in matrices:\n    print(A)\n\n[[0.97440813 0.3838544 ]\n [0.9790686  0.99981046]]\n[[0.3473302  0.17157842]\n [0.89346686 0.01403153]]\n\n\nOne point to remember is that JAX expects tuples to describe array shapes, even for flat arrays. Hence, to get a one-dimensional array of normal random draws we use (len, ) for the shape, as in\n\nrandom.normal(key, (5, ))\n\nArray([-0.64377279,  0.76961857, -0.29809604,  0.47858776, -2.00591299],      dtype=float64)\n\n\n\n\n\nThe JAX just-in-time (JIT) compiler accelerates logic within functions by fusing linear algebra operations into a single optimized kernel that the host can launch on the GPU / TPU (or CPU if no accelerator is detected).\n\n\nTo see the JIT compiler in action, consider the following function.\n\ndef f(x):\n    a = 3*x + jnp.sin(x) + jnp.cos(x**2) - jnp.cos(2*x) - x**2 * 0.4 * x**1.5\n    return jnp.sum(a)\n\nLet’s build an array to call the function on.\n\nn = 50_000_000\nx = jnp.ones(n)\n\nHow long does the function take to execute?\n\n%time f(x).block_until_ready()\n\nCPU times: user 5.86 s, sys: 5.51 s, total: 11.4 s\nWall time: 3.47 s\n\n\nArray(2.19896006e+08, dtype=float64)\n\n\nHere, in order to measure actual speed, we use the `block_until_ready()` method \nto hold the interpreter until the results of the computation are returned from\nthe device. This is necessary because JAX uses asynchronous dispatch, which\nallows the Python interpreter to run ahead of GPU computations.\n\nThe code doesn’t run as fast as we might hope, given that it’s running on a GPU.\nBut if we run it a second time it becomes much faster:\n\n%time f(x).block_until_ready()\n\nCPU times: user 6.29 s, sys: 5.53 s, total: 11.8 s\nWall time: 3.16 s\n\n\nArray(2.19896006e+08, dtype=float64)\n\n\nThis is because the built in functions like jnp.cos are JIT compiled and the first run includes compile time.\nWhy would JAX want to JIT-compile built in functions like jnp.cos instead of just providing pre-compiled versions, like NumPy?\nThe reason is that the JIT compiler can specialize on the size of the array being used, which is helpful for parallelization.\nFor example, in running the code above, the JIT compiler produced a version of jnp.cos that is specialized to floating point arrays of size n = 50_000_000.\nWe can check this by calling f with a new array of different size.\n\nm = 50_000_001\ny = jnp.ones(m)\n\n\n%time f(y).block_until_ready()\n\nCPU times: user 6.03 s, sys: 5.18 s, total: 11.2 s\nWall time: 3.43 s\n\n\nArray(2.19896011e+08, dtype=float64)\n\n\nNotice that the execution time increases, because now new versions of the built-ins like jnp.cos are being compiled, specialized to the new array size.\nIf we run again, the code is dispatched to the correct compiled version and we get faster execution.\n\n%time f(y).block_until_ready()\n\nCPU times: user 6.5 s, sys: 5.74 s, total: 12.2 s\nWall time: 3.24 s\n\n\nArray(2.19896011e+08, dtype=float64)\n\n\nThe compiled versions for the previous array size are still available in memory too, and the following call is dispatched to the correct compiled code.\n\n%time f(x).block_until_ready()\n\nCPU times: user 5.1 s, sys: 4.84 s, total: 9.93 s\nWall time: 2.83 s\n\n\nArray(2.19896006e+08, dtype=float64)\n\n\n\n\n\nWe can do even better if we manually JIT-compile the outer function.\n\nf_jit = jax.jit(f)   # target for JIT compilation\n\nLet’s run once to compile it:\n\nf_jit(x)\n\nArray(2.19896006e+08, dtype=float64)\n\n\nAnd now let’s time it.\n\n%time f_jit(x).block_until_ready()\n\nCPU times: user 5.91 s, sys: 497 ms, total: 6.41 s\nWall time: 1.48 s\n\n\nArray(2.19896006e+08, dtype=float64)\n\n\nNote the speed gain.\nThis is because the array operations are fused and no intermediate arrays are created.\nIncidentally, a more common syntax when targetting a function for the JIT compiler is\n\n@jax.jit\ndef f(x):\n    a = 3*x + jnp.sin(x) + jnp.cos(x**2) - jnp.cos(2*x) - x**2 * 0.4 * x**1.5\n    return jnp.sum(a)\n\n\n\n\n\nFrom JAX’s documentation:\nWhen walking about the countryside of Italy, the people will not hesitate to tell you that JAX has “una anima di pura programmazione funzionale”.\nIn other words, JAX assumes a functional programming style.\nThe major implication is that JAX functions should be pure.\nA pure function will always return the same result if invoked with the same inputs.\nIn particular, a pure function has\n\nno dependence on global variables and\nno side effects\n\nJAX will not usually throw errors when compiling impure functions but execution becomes unpredictable.\nHere’s an illustration of this fact, using global variables:\n\na = 1  # global\n\n@jax.jit\ndef f(x):\n    return a + x\n\n\nx = jnp.ones(2)\n\n\nf(x)\n\nArray([2., 2.], dtype=float64)\n\n\nIn the code above, the global value a=1 is fused into the jitted function.\nEven if we change a, the output of f will not be affected — as long as the same compiled version is called.\n\na = 42\n\n\nf(x)\n\nArray([2., 2.], dtype=float64)\n\n\nChanging the dimension of the input triggers a fresh compilation of the function, at which time the change in the value of a takes effect:\n\nx = jnp.ones(3)\n\n\nf(x)\n\nArray([43., 43., 43.], dtype=float64)\n\n\nMoral of the story: write pure functions when using JAX!\n\n\n\nJAX can use automatic differentiation to compute gradients.\nThis can be extremely useful for optimization and solving nonlinear systems.\nWe will see significant applications later in this lecture series.\nFor now, here’s a very simple illustration involving the function\n\ndef f(x):\n    return (x**2) / 2\n\nLet’s take the derivative:\n\nf_prime = jax.grad(f)\n\n\nf_prime(10.0)\n\nArray(10., dtype=float64, weak_type=True)\n\n\nLet’s plot the function and derivative, noting that \\(f'(x) = x\\).\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nx_grid = jnp.linspace(-4, 4, 200)\nax.plot(x_grid, f(x_grid), label=\"$f$\")\nax.plot(x_grid, [f_prime(x) for x in x_grid], label=\"$f'$\")\nax.legend(loc='upper center')\nplt.show()\n\n\n\n\n\n\n\n\nWe defer further exploration of automatic differentiation with JAX until {doc}autodiff.\n\n\n\nWriting fast JAX code requires shifting repetitive tasks from loops to array processing operations, so that the JAX compiler can easily understand the whole operation and generate more efficient machine code.\nThis procedure is called vectorization or array programming, and will be familiar to anyone who has used NumPy or MATLAB.\nIn most ways, vectorization is the same in JAX as it is in NumPy.\nBut there are also some differences, which we highlight here.\nAs a running example, consider the function\n\\[\n    f(x,y) = \\frac{\\cos(x^2 + y^2)}{1 + x^2 + y^2}\n\\]\nSuppose that we want to evaluate this function on a square grid of \\(x\\) and \\(y\\) points and then plot it.\nTo clarify, here is the slow for loop version.\n\n@jax.jit\ndef f(x, y):\n    return jnp.cos(x**2 + y**2) / (1 + x**2 + y**2)\n\nn = 80\nx = jnp.linspace(-2, 2, n)\ny = x\n\nz_loops = np.empty((n, n))\n\n\n%%time\nfor i in range(n):\n    for j in range(n):\n        z_loops[i, j] = f(x[i], y[j])\n\nCPU times: user 1.48 s, sys: 11.3 ms, total: 1.49 s\nWall time: 1.49 s\n\n\nEven for this very small grid, the run time is extremely slow.\n(Notice that we used a NumPy array for z_loops because we wanted to write to it.)\n\n\nOK, so how can we do the same operation in vectorized form?\nIf you are new to vectorization, you might guess that we can simply write\n\nz_bad = f(x, y)\n\nBut this gives us the wrong result because JAX doesn’t understand the nested for loop.\n\nz_bad.shape\n\n(80,)\n\n\nHere is what we actually wanted:\n\nz_loops.shape\n\n(80, 80)\n\n\nTo get the right shape and the correct nested for loop calculation, we can use a meshgrid operation designed for this purpose:\n\nx_mesh, y_mesh = jnp.meshgrid(x, y)\n\nNow we get what we want and the execution time is very fast.\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nCPU times: user 33.8 ms, sys: 1.47 ms, total: 35.3 ms\nWall time: 34.4 ms\n\n\nLet’s run again to eliminate compile time.\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nCPU times: user 1.08 ms, sys: 71 μs, total: 1.15 ms\nWall time: 691 μs\n\n\nLet’s confirm that we got the right answer.\n\njnp.allclose(z_mesh, z_loops)\n\nArray(True, dtype=bool)\n\n\nNow we can set up a serious grid and run the same calculation (on the larger grid) in a short amount of time.\n\nn = 6000\nx = jnp.linspace(-2, 2, n)\ny = x\nx_mesh, y_mesh = jnp.meshgrid(x, y)\n\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nCPU times: user 707 ms, sys: 165 ms, total: 872 ms\nWall time: 219 ms\n\n\nLet’s run again to get rid of compile time.\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nCPU times: user 862 ms, sys: 216 ms, total: 1.08 s\nWall time: 326 ms\n\n\nBut there is one problem here: the mesh grids use a lot of memory.\n\nx_mesh.nbytes + y_mesh.nbytes\n\n576000000\n\n\nBy comparison, the flat array x is just\n\nx.nbytes  # and y is just a pointer to x\n\n48000\n\n\nThis extra memory usage can be a big problem in actual research calculations.\nSo let’s try a different approach using jax.vmap\n\n\nFirst we vectorize f in y.\n\nf_vec_y = jax.vmap(f, in_axes=(None, 0))  \n\nIn the line above, (None, 0) indicates that we are vectorizing in the second argument, which is y.\nNext, we vectorize in the first argument, which is x.\n\nf_vec = jax.vmap(f_vec_y, in_axes=(0, None))\n\nWith this construction, we can now call the function \\(f\\) on flat (low memory) arrays.\n\n%%time\nz_vmap = f_vec(x, y).block_until_ready()\n\nCPU times: user 917 ms, sys: 203 ms, total: 1.12 s\nWall time: 339 ms\n\n\nWe run it again to eliminate compile time.\n\n%%time\nz_vmap = f_vec(x, y).block_until_ready()\n\nCPU times: user 759 ms, sys: 252 ms, total: 1.01 s\nWall time: 284 ms\n\n\nThe execution time is essentially the same as the mesh operation but we are using much less memory.\nAnd we produce the correct answer:\n\njnp.allclose(z_vmap, z_mesh)\n\nArray(True, dtype=bool)",
    "crumbs": [
      "Hands-on",
      "An Introduction to JAX"
    ]
  },
  {
    "objectID": "handson/jax_intro.html#jax-as-a-numpy-replacement",
    "href": "handson/jax_intro.html#jax-as-a-numpy-replacement",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "One way to use JAX is as a plug-in NumPy replacement. Let’s look at the similarities and differences.\n\n\nThe following import is standard, replacing import numpy as np:\n\nimport jax\nimport jax.numpy as jnp\n\nNow we can use jnp in place of np for the usual array operations:\n\na = jnp.asarray((1.0, 3.2, -1.5))\n\n\nprint(a)\n\n[ 1.   3.2 -1.5]\n\n\n\nprint(jnp.sum(a))\n\n2.7\n\n\n\nprint(jnp.mean(a))\n\n0.90000004\n\n\n\nprint(jnp.dot(a, a))\n\n13.490001\n\n\nHowever, the array object a is not a NumPy array:\n\na\n\nArray([ 1. ,  3.2, -1.5], dtype=float32)\n\n\n\ntype(a)\n\njaxlib.xla_extension.ArrayImpl\n\n\nEven scalar-valued maps on arrays return JAX arrays.\n\njnp.sum(a)\n\nArray(2.7, dtype=float32)\n\n\nJAX arrays are also called “device arrays,” where term “device” refers to a hardware accelerator (GPU or TPU).\n(In the terminology of GPUs, the “host” is the machine that launches GPU operations, while the “device” is the GPU itself.)\nOperations on higher dimensional arrays are also similar to NumPy:\n\nA = jnp.ones((2, 2))\nB = jnp.identity(2)\nA @ B\n\nArray([[1., 1.],\n       [1., 1.]], dtype=float32)\n\n\n\nfrom jax.numpy import linalg\n\n\nlinalg.inv(B)   # Inverse of identity is identity\n\nArray([[1., 0.],\n       [0., 1.]], dtype=float32)\n\n\n\nlinalg.eigh(B)  # Computes eigenvalues and eigenvectors\n\nEighResult(eigenvalues=Array([1., 1.], dtype=float32), eigenvectors=Array([[1., 0.],\n       [0., 1.]], dtype=float32))\n\n\n\n\n\nOne difference between NumPy and JAX is that JAX currently uses 32 bit floats by default.\nThis is standard for GPU computing and can lead to significant speed gains with small loss of precision.\nHowever, for some calculations precision matters. In these cases 64 bit floats can be enforced via the command\n\njax.config.update(\"jax_enable_x64\", True)\n\nLet’s check this works:\n\njnp.ones(3)\n\nArray([1., 1., 1.], dtype=float64)\n\n\nAs a NumPy replacement, a more significant difference is that arrays are treated as immutable.\nFor example, with NumPy we can write\n\nimport numpy as np\na = np.linspace(0, 1, 3)\na\n\narray([0. , 0.5, 1. ])\n\n\nand then mutate the data in memory:\n\na[0] = 1\na\n\narray([1. , 0.5, 1. ])\n\n\nIn JAX this fails:\n\na = jnp.linspace(0, 1, 3)\na\n\nArray([0. , 0.5, 1. ], dtype=float64)\n\n\n\n# a[0] = 1\n\nIn line with immutability, JAX does not support inplace operations:\n\na = np.array((2, 1))\na.sort()\na\n\narray([1, 2])\n\n\n\na = jnp.array((2, 1))\na_new = a.sort()\na, a_new\n\n(Array([2, 1], dtype=int64), Array([1, 2], dtype=int64))\n\n\nThe designers of JAX chose to make arrays immutable because JAX uses a functional programming style. More on this below.\nNote that, while mutation is discouraged, it is in fact possible with at, as in\n\na = jnp.linspace(0, 1, 3)\nid(a)\n\n110315613819424\n\n\n\na\n\nArray([0. , 0.5, 1. ], dtype=float64)\n\n\n\na.at[0].set(1)\n\nArray([1. , 0.5, 1. ], dtype=float64)\n\n\nWe can check that the array is mutated by verifying its identity is unchanged:\n\nid(a)\n\n110315613819424",
    "crumbs": [
      "Hands-on",
      "An Introduction to JAX"
    ]
  },
  {
    "objectID": "handson/jax_intro.html#random-numbers",
    "href": "handson/jax_intro.html#random-numbers",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "Random numbers are also a bit different in JAX, relative to NumPy. Typically, in JAX, the state of the random number generator needs to be controlled explicitly.\n\nimport jax.random as random\n\nFirst we produce a key, which seeds the random number generator.\n\nkey = random.PRNGKey(1)\n\n\ntype(key)\n\njaxlib.xla_extension.ArrayImpl\n\n\n\nprint(key)\n\n[0 1]\n\n\nNow we can use the key to generate some random numbers:\n\nx = random.normal(key, (3, 3))\nx\n\nArray([[-1.35247421, -0.2712502 , -0.02920518],\n       [ 0.34706456,  0.5464053 , -1.52325812],\n       [ 0.41677264, -0.59710138, -0.5678208 ]], dtype=float64)\n\n\nIf we use the same key again, we initialize at the same seed, so the random numbers are the same:\n\nrandom.normal(key, (3, 3))\n\nArray([[-1.35247421, -0.2712502 , -0.02920518],\n       [ 0.34706456,  0.5464053 , -1.52325812],\n       [ 0.41677264, -0.59710138, -0.5678208 ]], dtype=float64)\n\n\nTo produce a (quasi-) independent draw, best practice is to “split” the existing key:\n\nkey, subkey = random.split(key)\n\n\nrandom.normal(key, (3, 3))\n\nArray([[ 1.85374374, -0.37683949, -0.61276867],\n       [-1.91829718,  0.27219409,  0.54922246],\n       [ 0.40451442, -0.58726839, -0.63967753]], dtype=float64)\n\n\n\nrandom.normal(subkey, (3, 3))\n\nArray([[-0.4300635 ,  0.22778552,  0.57241269],\n       [-0.15969178,  0.46719192,  0.21165091],\n       [ 0.84118631,  1.18671326, -0.16607783]], dtype=float64)\n\n\nThe function below produces k (quasi-) independent random n x n matrices using this procedure.\n\ndef gen_random_matrices(key, n, k):\n    matrices = []\n    for _ in range(k):\n        key, subkey = random.split(key)\n        matrices.append(random.uniform(subkey, (n, n)))\n    return matrices\n\n\nmatrices = gen_random_matrices(key, 2, 2)\nfor A in matrices:\n    print(A)\n\n[[0.97440813 0.3838544 ]\n [0.9790686  0.99981046]]\n[[0.3473302  0.17157842]\n [0.89346686 0.01403153]]\n\n\nOne point to remember is that JAX expects tuples to describe array shapes, even for flat arrays. Hence, to get a one-dimensional array of normal random draws we use (len, ) for the shape, as in\n\nrandom.normal(key, (5, ))\n\nArray([-0.64377279,  0.76961857, -0.29809604,  0.47858776, -2.00591299],      dtype=float64)",
    "crumbs": [
      "Hands-on",
      "An Introduction to JAX"
    ]
  },
  {
    "objectID": "handson/jax_intro.html#jit-compilation",
    "href": "handson/jax_intro.html#jit-compilation",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "The JAX just-in-time (JIT) compiler accelerates logic within functions by fusing linear algebra operations into a single optimized kernel that the host can launch on the GPU / TPU (or CPU if no accelerator is detected).\n\n\nTo see the JIT compiler in action, consider the following function.\n\ndef f(x):\n    a = 3*x + jnp.sin(x) + jnp.cos(x**2) - jnp.cos(2*x) - x**2 * 0.4 * x**1.5\n    return jnp.sum(a)\n\nLet’s build an array to call the function on.\n\nn = 50_000_000\nx = jnp.ones(n)\n\nHow long does the function take to execute?\n\n%time f(x).block_until_ready()\n\nCPU times: user 5.86 s, sys: 5.51 s, total: 11.4 s\nWall time: 3.47 s\n\n\nArray(2.19896006e+08, dtype=float64)\n\n\nHere, in order to measure actual speed, we use the `block_until_ready()` method \nto hold the interpreter until the results of the computation are returned from\nthe device. This is necessary because JAX uses asynchronous dispatch, which\nallows the Python interpreter to run ahead of GPU computations.\n\nThe code doesn’t run as fast as we might hope, given that it’s running on a GPU.\nBut if we run it a second time it becomes much faster:\n\n%time f(x).block_until_ready()\n\nCPU times: user 6.29 s, sys: 5.53 s, total: 11.8 s\nWall time: 3.16 s\n\n\nArray(2.19896006e+08, dtype=float64)\n\n\nThis is because the built in functions like jnp.cos are JIT compiled and the first run includes compile time.\nWhy would JAX want to JIT-compile built in functions like jnp.cos instead of just providing pre-compiled versions, like NumPy?\nThe reason is that the JIT compiler can specialize on the size of the array being used, which is helpful for parallelization.\nFor example, in running the code above, the JIT compiler produced a version of jnp.cos that is specialized to floating point arrays of size n = 50_000_000.\nWe can check this by calling f with a new array of different size.\n\nm = 50_000_001\ny = jnp.ones(m)\n\n\n%time f(y).block_until_ready()\n\nCPU times: user 6.03 s, sys: 5.18 s, total: 11.2 s\nWall time: 3.43 s\n\n\nArray(2.19896011e+08, dtype=float64)\n\n\nNotice that the execution time increases, because now new versions of the built-ins like jnp.cos are being compiled, specialized to the new array size.\nIf we run again, the code is dispatched to the correct compiled version and we get faster execution.\n\n%time f(y).block_until_ready()\n\nCPU times: user 6.5 s, sys: 5.74 s, total: 12.2 s\nWall time: 3.24 s\n\n\nArray(2.19896011e+08, dtype=float64)\n\n\nThe compiled versions for the previous array size are still available in memory too, and the following call is dispatched to the correct compiled code.\n\n%time f(x).block_until_ready()\n\nCPU times: user 5.1 s, sys: 4.84 s, total: 9.93 s\nWall time: 2.83 s\n\n\nArray(2.19896006e+08, dtype=float64)\n\n\n\n\n\nWe can do even better if we manually JIT-compile the outer function.\n\nf_jit = jax.jit(f)   # target for JIT compilation\n\nLet’s run once to compile it:\n\nf_jit(x)\n\nArray(2.19896006e+08, dtype=float64)\n\n\nAnd now let’s time it.\n\n%time f_jit(x).block_until_ready()\n\nCPU times: user 5.91 s, sys: 497 ms, total: 6.41 s\nWall time: 1.48 s\n\n\nArray(2.19896006e+08, dtype=float64)\n\n\nNote the speed gain.\nThis is because the array operations are fused and no intermediate arrays are created.\nIncidentally, a more common syntax when targetting a function for the JIT compiler is\n\n@jax.jit\ndef f(x):\n    a = 3*x + jnp.sin(x) + jnp.cos(x**2) - jnp.cos(2*x) - x**2 * 0.4 * x**1.5\n    return jnp.sum(a)",
    "crumbs": [
      "Hands-on",
      "An Introduction to JAX"
    ]
  },
  {
    "objectID": "handson/jax_intro.html#functional-programming",
    "href": "handson/jax_intro.html#functional-programming",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "From JAX’s documentation:\nWhen walking about the countryside of Italy, the people will not hesitate to tell you that JAX has “una anima di pura programmazione funzionale”.\nIn other words, JAX assumes a functional programming style.\nThe major implication is that JAX functions should be pure.\nA pure function will always return the same result if invoked with the same inputs.\nIn particular, a pure function has\n\nno dependence on global variables and\nno side effects\n\nJAX will not usually throw errors when compiling impure functions but execution becomes unpredictable.\nHere’s an illustration of this fact, using global variables:\n\na = 1  # global\n\n@jax.jit\ndef f(x):\n    return a + x\n\n\nx = jnp.ones(2)\n\n\nf(x)\n\nArray([2., 2.], dtype=float64)\n\n\nIn the code above, the global value a=1 is fused into the jitted function.\nEven if we change a, the output of f will not be affected — as long as the same compiled version is called.\n\na = 42\n\n\nf(x)\n\nArray([2., 2.], dtype=float64)\n\n\nChanging the dimension of the input triggers a fresh compilation of the function, at which time the change in the value of a takes effect:\n\nx = jnp.ones(3)\n\n\nf(x)\n\nArray([43., 43., 43.], dtype=float64)\n\n\nMoral of the story: write pure functions when using JAX!",
    "crumbs": [
      "Hands-on",
      "An Introduction to JAX"
    ]
  },
  {
    "objectID": "handson/jax_intro.html#gradients",
    "href": "handson/jax_intro.html#gradients",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "JAX can use automatic differentiation to compute gradients.\nThis can be extremely useful for optimization and solving nonlinear systems.\nWe will see significant applications later in this lecture series.\nFor now, here’s a very simple illustration involving the function\n\ndef f(x):\n    return (x**2) / 2\n\nLet’s take the derivative:\n\nf_prime = jax.grad(f)\n\n\nf_prime(10.0)\n\nArray(10., dtype=float64, weak_type=True)\n\n\nLet’s plot the function and derivative, noting that \\(f'(x) = x\\).\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nx_grid = jnp.linspace(-4, 4, 200)\nax.plot(x_grid, f(x_grid), label=\"$f$\")\nax.plot(x_grid, [f_prime(x) for x in x_grid], label=\"$f'$\")\nax.legend(loc='upper center')\nplt.show()\n\n\n\n\n\n\n\n\nWe defer further exploration of automatic differentiation with JAX until {doc}autodiff.",
    "crumbs": [
      "Hands-on",
      "An Introduction to JAX"
    ]
  },
  {
    "objectID": "handson/jax_intro.html#writing-vectorized-code",
    "href": "handson/jax_intro.html#writing-vectorized-code",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "Writing fast JAX code requires shifting repetitive tasks from loops to array processing operations, so that the JAX compiler can easily understand the whole operation and generate more efficient machine code.\nThis procedure is called vectorization or array programming, and will be familiar to anyone who has used NumPy or MATLAB.\nIn most ways, vectorization is the same in JAX as it is in NumPy.\nBut there are also some differences, which we highlight here.\nAs a running example, consider the function\n\\[\n    f(x,y) = \\frac{\\cos(x^2 + y^2)}{1 + x^2 + y^2}\n\\]\nSuppose that we want to evaluate this function on a square grid of \\(x\\) and \\(y\\) points and then plot it.\nTo clarify, here is the slow for loop version.\n\n@jax.jit\ndef f(x, y):\n    return jnp.cos(x**2 + y**2) / (1 + x**2 + y**2)\n\nn = 80\nx = jnp.linspace(-2, 2, n)\ny = x\n\nz_loops = np.empty((n, n))\n\n\n%%time\nfor i in range(n):\n    for j in range(n):\n        z_loops[i, j] = f(x[i], y[j])\n\nCPU times: user 1.48 s, sys: 11.3 ms, total: 1.49 s\nWall time: 1.49 s\n\n\nEven for this very small grid, the run time is extremely slow.\n(Notice that we used a NumPy array for z_loops because we wanted to write to it.)\n\n\nOK, so how can we do the same operation in vectorized form?\nIf you are new to vectorization, you might guess that we can simply write\n\nz_bad = f(x, y)\n\nBut this gives us the wrong result because JAX doesn’t understand the nested for loop.\n\nz_bad.shape\n\n(80,)\n\n\nHere is what we actually wanted:\n\nz_loops.shape\n\n(80, 80)\n\n\nTo get the right shape and the correct nested for loop calculation, we can use a meshgrid operation designed for this purpose:\n\nx_mesh, y_mesh = jnp.meshgrid(x, y)\n\nNow we get what we want and the execution time is very fast.\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nCPU times: user 33.8 ms, sys: 1.47 ms, total: 35.3 ms\nWall time: 34.4 ms\n\n\nLet’s run again to eliminate compile time.\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nCPU times: user 1.08 ms, sys: 71 μs, total: 1.15 ms\nWall time: 691 μs\n\n\nLet’s confirm that we got the right answer.\n\njnp.allclose(z_mesh, z_loops)\n\nArray(True, dtype=bool)\n\n\nNow we can set up a serious grid and run the same calculation (on the larger grid) in a short amount of time.\n\nn = 6000\nx = jnp.linspace(-2, 2, n)\ny = x\nx_mesh, y_mesh = jnp.meshgrid(x, y)\n\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nCPU times: user 707 ms, sys: 165 ms, total: 872 ms\nWall time: 219 ms\n\n\nLet’s run again to get rid of compile time.\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nCPU times: user 862 ms, sys: 216 ms, total: 1.08 s\nWall time: 326 ms\n\n\nBut there is one problem here: the mesh grids use a lot of memory.\n\nx_mesh.nbytes + y_mesh.nbytes\n\n576000000\n\n\nBy comparison, the flat array x is just\n\nx.nbytes  # and y is just a pointer to x\n\n48000\n\n\nThis extra memory usage can be a big problem in actual research calculations.\nSo let’s try a different approach using jax.vmap\n\n\nFirst we vectorize f in y.\n\nf_vec_y = jax.vmap(f, in_axes=(None, 0))  \n\nIn the line above, (None, 0) indicates that we are vectorizing in the second argument, which is y.\nNext, we vectorize in the first argument, which is x.\n\nf_vec = jax.vmap(f_vec_y, in_axes=(0, None))\n\nWith this construction, we can now call the function \\(f\\) on flat (low memory) arrays.\n\n%%time\nz_vmap = f_vec(x, y).block_until_ready()\n\nCPU times: user 917 ms, sys: 203 ms, total: 1.12 s\nWall time: 339 ms\n\n\nWe run it again to eliminate compile time.\n\n%%time\nz_vmap = f_vec(x, y).block_until_ready()\n\nCPU times: user 759 ms, sys: 252 ms, total: 1.01 s\nWall time: 284 ms\n\n\nThe execution time is essentially the same as the mesh operation but we are using much less memory.\nAnd we produce the correct answer:\n\njnp.allclose(z_vmap, z_mesh)\n\nArray(True, dtype=bool)",
    "crumbs": [
      "Hands-on",
      "An Introduction to JAX"
    ]
  },
  {
    "objectID": "handson/numeric_python.html",
    "href": "handson/numeric_python.html",
    "title": "Numeric Python",
    "section": "",
    "text": "Most python scientists, use the following libraries:\n\nnumpy: performant array library (vectors, matrices, tensors)\nmatplotlib: plotting library\nscipy: all kinds of mathematical routines\n\nIn the rest of the course, we’ll make some use of numpy and matplotlib\nThey are included in all python distributions like Anaconda Python\nAll additional libraries use numpy and matplotlib: pandas, statsmodels, sklearn",
    "crumbs": [
      "Hands-on",
      "Numeric Python"
    ]
  },
  {
    "objectID": "handson/numeric_python.html#numpy",
    "href": "handson/numeric_python.html#numpy",
    "title": "Numeric Python",
    "section": "Numpy",
    "text": "Numpy\n\nWhat is Numpy\nNumpy is an array type (python object) meant to store efficiently homogenous, square, arrays (like \\((a_{i})_{i\\in [1,N]}\\) or \\((b_{i,j,k})_{i\\in [1,N],j\\in[1,J],k \\in [1,K]}\\))\nBy default its stores data in contiguous C-order (last index varies faster), but also supports Fortran order and strided arrays (non-contiguous).\nNumpy has introduced well thought conventions, that have been reused by many other libraries (tensorflow, pytorch, jax), or even programming languages (julia)\n\n\nVector Creation\n\nVectors and matrices are created with the np.array(...) function.\nSpecial vectors can be created with np.zeros, np.ones, np.linspace\n\n\n# an array can be created from a list of numbers\nnp.array( [1.0, 2.0, 3.0] )\n\n\n# or initialized by specifying the length of the array\nnp.zeros(5)\n\n\n# 10 regularly spaced points between 0 and 1\nnp.linspace(0, 1, 11)\n\n\n\nMatrix Creation\n\nA matrix is a 2-dimensional array and is created with np.array\nFunction np.matrix() has been deprecated: do not use it.\nThere are functions to create specific matrices: np.eye, np.diag, …\n\n\n# an array can be created from a list of (equal size) lists\nnp.array([\n    [1.0, 2.0, 3.0],\n    [4  ,   5,   6] \n])\n\n\n# initialize an empty matrix with the dimensions as a tuple\nA = np.zeros( (2, 3) )\nA\n\n\n# matrix dimensions are contained in the shape attribute\nA.shape\n\n\n\nTensors\nThe construction generalizes to higher dimension arrays (a.k.a. tensors)\n\n# an array can be created from a list of list of lists\nnp.array([\n    [\n        [1.0, 2.0, 3.0],\n        [4  ,   5,   6] \n    ],\n        [\n        [7.0, 8.0, 9.0],\n        [10 ,  11,   12] \n    ]\n])\n\n\n# initialize an empty matrix with the dimensions as a tuple\nA = np.zeros( (2, 3) )\nA\n\n\n# matrix dimensions are contained in the shape attribute\nA.shape\n\n\n\nLinear Algebra\nVector multiplications and Matrix multiplications can be performed using special sign @\n\nA = np.array([[1.0, 2.0], [2,4]])\nA\n\n\nB = np.array([1.0, 2.0])\nB\n\n\nA@B\n\n\nA@A\n\nNote how multiplication reduces total number of dimensions by 2. It is a tensor reduction.\n\nprint(A.shape, A.shape, (A@A).shape)\n\n\n\nScalar types\nNumpy arrays can contain data of several scalar types.\n\n[True, False, True]\n\n\n# vector of boolean\nboolean_vector = np.array( [True, False, True] )\nprint(f\"type of scalar '{boolean_vector.dtype}'\")\nboolean_vector\n\n\n# vector of integers\nint_vector = np.array([1, 2, 0])\nprint(f\"type of scalar '{int_vector.dtype}'\")\nint_vector\n\nBy default, numerical arrays contain float64 numbers (like matlab). But GPUs typically process 16 bits or 32 bits numbers.\nCan you create a 32 bits array?\n\n# your code here\n\n\n\nSubscripting Vectors\n\nElements and subarrays, can be retrieved using the same syntax as lists and strings.\n\nRemember that indexing starts at 0.\n\n\n\nV = np.array([0., 1., 2., 3., 4.])\ndisplay(V[1])  # second element\n\n\nV = np.array([0., 1., 2., 3., 4.])\ndisplay(V[1:3])  # second, third and fourth element\n\n\n\nModifying Vector Content\n\nElements and suvectors, can be assigned to new values, as long as they have the right dimensions.\n\n\nV = np.array([1., 1., 2., 4., 5., 8., 13.])\nV[3] = 3.0\nV\n\n\nV = np.array([1., 1., 2., 4., 5., 8., 13.])\n# V[1:4] = [1,2,3,4] # this doesn't work\nV[1:4] = [2,3,4] # this works\n\n\n\nSubscripting Matrices\n\nIndexing generalizes to matrices: there are two indices istead of one: M[i,j]\nOne can extract a row, or a column (a slice) with M[i,:] or M[:,i]\nA submatrix is defining with two intervals: M[i:j, k:l] or M[i:j, :], …\n\n\nM = np.array([[1,2,3],[4,5,6],[7,8,9]])\nM\n\n\nM[0,1] # access element (1,2)\n\n\nM[2,:] # third row\n\n\nM[:,1] # second column     # M[i,1] for any i\n\n\nM[1:3, :] # lines from 1 (included) to 3 (excluded) ; all columns\n\n\n\nModifying matrix content\n\nM = np.array([[1,2,3],[4,5,6],[7,8,9]])\nM\n\n\nM[0,0] = 0\nM\n\n\nM[1:3, 1:3] = np.array([[0,1],[1,0]]) # dimensions must match\nM\n\n\n\nElement-wise algebraic operations\n\nThe following algebraic operations are defined on arrays: +, -, *, /, **.\nComparisons operators (&lt;,&lt;=, &gt;, &gt;=, ==) are defined are return boolean arrays.\nThey operate element by element.\n\n\nA = np.array([1,2,3,4])\nB = np.array([4,3,2,1])\nA+B\n\n\nA*B    # note the difference with A@B\n\n\nA&gt;B\n\nAt first, one might be surprised that the default multiplication operator is element-wise multiplication rather than matrix multiplication.\nThere are at least two good reasons:\n\nconsistency: all operators can be broadcasted with the exact same rules (like *, +, &gt;)\nfor many workflows, elementwise operations are more common than matrix multiplication\n\n\n\nElement-wise logical operations\n\nThe following logical operations are defined element-wise on arrays: & (and), | (or), ~ (not)\n\n\nA = np.array([False, False, True, True])\nB = np.array([False, True, False, True])\n\n\n~A\n\n\nA | B\n\n\nA & B\n\n\n\nVector indexing\n\nArrays can be indexed by boolean arrays instead of ranges.\nOnly elements corresponding to true are retrieved\n\n\nx = np.linspace(0,1,6)\nx\n\n\n# indexes such that (x^2) &gt; (x/2)\nx**2 &gt; (x/2)\n\n\ncond = x**2 &gt; (x/2)\nx[ cond ] \n\n\n\nGoing further: broadcasting rules\n\nNumpy library has defined very consistent conventions, to match inconsistent dimensions.\nIgnore them for now…\n\n\nM = np.eye(4)\nM\n\n\nM[2:4, 2:4] = 0.5 # float\nM\n\n\nM[:,:2] = np.array([[0.1, 0.2]])  # 1x2 array\nM\n\n\n\nGoing Further\n\nOther useful functions (easy to google):\n\nnp.arange() regularly spaced integers\nnp.where() find elements in\n…",
    "crumbs": [
      "Hands-on",
      "Numeric Python"
    ]
  },
  {
    "objectID": "handson/numeric_python.html#matplotlib",
    "href": "handson/numeric_python.html#matplotlib",
    "title": "Numeric Python",
    "section": "Matplotlib",
    "text": "Matplotlib\n\nMatplotlib\n\nmatplotlib is …\nobject oriented api optional Matlab-like syntax\nmain function is plt.plot(x,y) where x and y are vectors (or iterables like lists)\n\nlots of optional arguments\n\n\n\nfrom matplotlib import pyplot as plt\n\n\n\nExample\n\nx = np.linspace(-1,1,6)\n\n\ny = np.sin(x)/x # sinus cardinal\n\n\nplt.plot(x,y,'o')\nplt.plot(x,y)\n\n\n\nExample (2)\n\nx = np.linspace(-5,5,100)\n\nfig = plt.figure() # keep a figure open to draw on it\nfor k in range(1,5):\n    y = np.sin(x*k)/(x*k)\n    plt.plot(x, y, label=f\"$sinc({k} x)$\") # label each line\nplt.plot(x, x*0, color='black', linestyle='--')\nplt.grid(True) # add a grid\nplt.title(\"Looking for the right hat.\")\nplt.legend(loc=\"upper right\")\n\n\n\nExample (3)\n\nx = np.linspace(-5,5,100)\n\nplt.figure()\nplt.subplot(2,2,1) # create a 2x2 subplot and draw in first quadrant\nplt.plot(x,x)\nplt.subplot(2,2,2) # create a 2x2 subplot and draw in second quadrant\nplt.plot(x,-x)\nplt.subplot(2,2,3) # create a 2x2 subplot and draw in third quadrant\nplt.plot(x,-x)\nplt.subplot(2,2,4) # create a 2x2 subplot and draw in fourth quadrant\nplt.plot(x,x)\n\nplt.tight_layout() # save some space\n\n\n\nAlternatives to matplotlib\n\nplotly (nice javascript graphs)\nbqplot (native integration with jupyter)\naltair\n\nexcellent for dataviz/interactivity\npython wrapper to Vega-lite\nvery efficient to visualize pandas data (i.e. a dataframe)",
    "crumbs": [
      "Hands-on",
      "Numeric Python"
    ]
  },
  {
    "objectID": "handson/python_syntax.html",
    "href": "handson/python_syntax.html",
    "title": "Python: syntax review",
    "section": "",
    "text": "# integers and floats\n\n\n1\n\n\n1.0\n\n\n# conversion with int() and float()\nfloat( 1 )\n\n\nint(2.9) # floor\n\n\n# no difference between various types of floats (16 bits, 32 bits, 64 bits, ...)\n\n\ntype( 2.2**50 ) # this doesn't fit in 32 bits\n\n\n# usual operations + - *\nprint( 2 + 3 )\nprint( 9 -6 )\nprint( 3 / 2 )\nprint(2304310958*41324)\n\n\n# divisions / and //\nprint(3/4)\nprint(13//4)\n\n\n# exponentiation ** (not ^!)\n# (1.04)^10\n(1.04)**10\n\n\n# comparison operators: &gt;, &lt;, &gt;=, &lt;=, ==\n\nprint((1.0453432)*(0.96)  &gt; 1.001 )\n\nprint(1.001 &gt;= 1.001)\n\n\n# comparison operators can be chained:\nprint(0.2&lt;0.4&lt;0.5)\nprint(0.5&lt;=0.4&lt;=0.5) # equivalent to ((0.5&lt;=0.4) and(0.4&lt;=0.5))\n\n\n\n\nThere are only two booleans: True and False (note uppercase). None is a dummy type, which is used when no other type fits.\n\nprint( False )\nTrue\n\n\n(True, False, None)\n\nDouble equal sign tests for equality. Result should always be a boolean.\n\nTrue==False\n\nLogical operators are not, and and or:\n\n(True or False)\n\n\nnot (True or False)\n\n\n(1.3**1.04 &gt; 1.9) | (1000**1143&gt;1001**1142)\n\nOperators or and and can be replaced by | and & respectively. They are non-greedy, that is terms are not evaluated if the result of the comparison is already known.\n\nFalse and (print(\"Hello\"))\n\n\nprint( (print(\"Hello\")) and False )\n\n\n\n\n\n\nStrings are defined by enclosing characters either by ' (single quotes) or \" (double quote). Single quotes strings can contain double quotes strings and vice-versa.\n\n\"name\"\n\n\n'name'\n\n\n'I say \"hello\"'\n\n\n\"You can 'quote' me\"\n\nStrings spanning over sever lines can be defined with triple quotes (single or double).\n\ns = \"\"\"¿Qué es la vida? Un frenesí.\n¿Qué es la vida? Una ilusión,\nuna sombra, una ficción,\ny el mayor bien es pequeño;\nque toda la vida es sueño,\ny los sueños, sueños son.\n\"\"\"\n\nIt is also possible to use the newline character \\n.\n\n\"La vida es sueño,\\ny los sueños, sueños son.\"\n\n\nprint(\"La vida es sueño,\\ny los sueños, sueños son.\")\n\n\n\n\nStrings can contain any unicode character:\n\ns = \"🎻⽻༽\"\n\nRefresher: ASCII vs unicode\nASCII (or ASCII-US) is an old standard which codes a character with 7 bits (or 8 bits for extended ASCII). This allows to code 128 different characters (256 for ex-ASCII).\nOnly a subset of these characters can be printed regularly.\n\nchr(44)\n\n\n# ASCII: \nfor i in range(32,127):\n    print( chr(i), end=' ')\n\nThe other characters include delete, newline and carriage return among others.\n\ns = 'This is\\na\\nmultiline string.' # note the newline character '\\n'\n\n\n# print(s)\nlen(s)\n\nSome antiquated platforms still use newline + carriage return at the end of each line. This is absolutely not required and causes incompatibilities.\n\ns2 = 'This is\\n\\ra\\n\\rmultiline string.' # note the newline character '\\n' and carriager return '\\r'\n\n\nprint(s2)\nprint(len(s2))\n\nUnicode contains a repertoire of over 137,000 characters with all ASCII characters as subcases\nTo type: copy/paste, ctrl+shift+hexadecimal, latex + tab\nVariable names aka identifiers can contain unicode characters with some restrictions: - they cannot start with a digit - they can’t contain special variables (‘!,#,@,%,$’ and other unicode specials ???) - they can contain underscore\n\n\n\nconcatenation\n\n'abc' + 'def'\n\n\n'abc'*3\n\n\n'abc' + 'abc' + 'abc'\n\n\n\n\n\n# strings can be accessed as arrays (0 based indexing)\ns = \"a b c\"\ns[0]\n\n\n# slice notation (  [min,max[ )\ns = \"a b c d\"\ns[2:5] # 0-based; 2 included, 5 excluded\n\n\n# substrings are easy to check\n\"a\" in s\n\n\n\"b c\" in \"a b c d\"\n\nIt is impossible to modify a substring.\n\n# but are immutable\ns = \"a b c\"\n#s[1] = 0 error\n\nInstead, one can replace a substring:\n\ns\n\n\ns.replace(' ', '🎻')\n\nOr use string interpolation\n\n# string interpolation (old school)\n\"ny name is {name}\".format(name=\"nobody\")\n\n\n\"calculation took {time}s\".format(time=10000)\n\n\n# number format can be tweaked\n\"I am {age:.0f} years old\".format(age=5.65)\n\n\n# formatted strings\nelapsed = 15914884.300292\n\nf\"computations took {elapsed/3600:.2f} hours\"\n\n\nname = \"arnaldur\"\n\n\n\"dasnfnaksujhn {name}\".format(name=\"whatever\")\n\n\n# basic string operations: str.split, str.join, etc...\n# fast regular expressions\n# more on it, with text processing lesson\n\n\nstr.split(\"me,you,others,them\",',')\n\n\nstr.join( \" | \",\n    str.split(\"me,you,others,them\",','),\n)\n\n\n\n\nThe example above used several special characters: \\n which corresponds to only one ascii character and {/} which disappears after the string formatting. If one desires to print these characters precisely one needs to escape them using \\ and { }.\n\nprint(\"This is a one \\\\nline string\")\nprint(\"This string keeps some {{curly}} brackets{}\".format('.'))\n\n\n\n\n(check help(str) or help?)\n\nlen() : length\nstrip() : removes characters at the ends\nsplit() : split strings into several substrings separated by separator\njoin() : opposite of split\n\n\n'others,'\n\n\n',me,others,'.strip(',')\n\n\ns.count(',')\n\n\nhelp(str)",
    "crumbs": [
      "Hands-on",
      "Python: syntax review"
    ]
  },
  {
    "objectID": "handson/python_syntax.html#basic-types",
    "href": "handson/python_syntax.html#basic-types",
    "title": "Python: syntax review",
    "section": "",
    "text": "# integers and floats\n\n\n1\n\n\n1.0\n\n\n# conversion with int() and float()\nfloat( 1 )\n\n\nint(2.9) # floor\n\n\n# no difference between various types of floats (16 bits, 32 bits, 64 bits, ...)\n\n\ntype( 2.2**50 ) # this doesn't fit in 32 bits\n\n\n# usual operations + - *\nprint( 2 + 3 )\nprint( 9 -6 )\nprint( 3 / 2 )\nprint(2304310958*41324)\n\n\n# divisions / and //\nprint(3/4)\nprint(13//4)\n\n\n# exponentiation ** (not ^!)\n# (1.04)^10\n(1.04)**10\n\n\n# comparison operators: &gt;, &lt;, &gt;=, &lt;=, ==\n\nprint((1.0453432)*(0.96)  &gt; 1.001 )\n\nprint(1.001 &gt;= 1.001)\n\n\n# comparison operators can be chained:\nprint(0.2&lt;0.4&lt;0.5)\nprint(0.5&lt;=0.4&lt;=0.5) # equivalent to ((0.5&lt;=0.4) and(0.4&lt;=0.5))\n\n\n\n\nThere are only two booleans: True and False (note uppercase). None is a dummy type, which is used when no other type fits.\n\nprint( False )\nTrue\n\n\n(True, False, None)\n\nDouble equal sign tests for equality. Result should always be a boolean.\n\nTrue==False\n\nLogical operators are not, and and or:\n\n(True or False)\n\n\nnot (True or False)\n\n\n(1.3**1.04 &gt; 1.9) | (1000**1143&gt;1001**1142)\n\nOperators or and and can be replaced by | and & respectively. They are non-greedy, that is terms are not evaluated if the result of the comparison is already known.\n\nFalse and (print(\"Hello\"))\n\n\nprint( (print(\"Hello\")) and False )\n\n\n\n\n\n\nStrings are defined by enclosing characters either by ' (single quotes) or \" (double quote). Single quotes strings can contain double quotes strings and vice-versa.\n\n\"name\"\n\n\n'name'\n\n\n'I say \"hello\"'\n\n\n\"You can 'quote' me\"\n\nStrings spanning over sever lines can be defined with triple quotes (single or double).\n\ns = \"\"\"¿Qué es la vida? Un frenesí.\n¿Qué es la vida? Una ilusión,\nuna sombra, una ficción,\ny el mayor bien es pequeño;\nque toda la vida es sueño,\ny los sueños, sueños son.\n\"\"\"\n\nIt is also possible to use the newline character \\n.\n\n\"La vida es sueño,\\ny los sueños, sueños son.\"\n\n\nprint(\"La vida es sueño,\\ny los sueños, sueños son.\")\n\n\n\n\nStrings can contain any unicode character:\n\ns = \"🎻⽻༽\"\n\nRefresher: ASCII vs unicode\nASCII (or ASCII-US) is an old standard which codes a character with 7 bits (or 8 bits for extended ASCII). This allows to code 128 different characters (256 for ex-ASCII).\nOnly a subset of these characters can be printed regularly.\n\nchr(44)\n\n\n# ASCII: \nfor i in range(32,127):\n    print( chr(i), end=' ')\n\nThe other characters include delete, newline and carriage return among others.\n\ns = 'This is\\na\\nmultiline string.' # note the newline character '\\n'\n\n\n# print(s)\nlen(s)\n\nSome antiquated platforms still use newline + carriage return at the end of each line. This is absolutely not required and causes incompatibilities.\n\ns2 = 'This is\\n\\ra\\n\\rmultiline string.' # note the newline character '\\n' and carriager return '\\r'\n\n\nprint(s2)\nprint(len(s2))\n\nUnicode contains a repertoire of over 137,000 characters with all ASCII characters as subcases\nTo type: copy/paste, ctrl+shift+hexadecimal, latex + tab\nVariable names aka identifiers can contain unicode characters with some restrictions: - they cannot start with a digit - they can’t contain special variables (‘!,#,@,%,$’ and other unicode specials ???) - they can contain underscore\n\n\n\nconcatenation\n\n'abc' + 'def'\n\n\n'abc'*3\n\n\n'abc' + 'abc' + 'abc'\n\n\n\n\n\n# strings can be accessed as arrays (0 based indexing)\ns = \"a b c\"\ns[0]\n\n\n# slice notation (  [min,max[ )\ns = \"a b c d\"\ns[2:5] # 0-based; 2 included, 5 excluded\n\n\n# substrings are easy to check\n\"a\" in s\n\n\n\"b c\" in \"a b c d\"\n\nIt is impossible to modify a substring.\n\n# but are immutable\ns = \"a b c\"\n#s[1] = 0 error\n\nInstead, one can replace a substring:\n\ns\n\n\ns.replace(' ', '🎻')\n\nOr use string interpolation\n\n# string interpolation (old school)\n\"ny name is {name}\".format(name=\"nobody\")\n\n\n\"calculation took {time}s\".format(time=10000)\n\n\n# number format can be tweaked\n\"I am {age:.0f} years old\".format(age=5.65)\n\n\n# formatted strings\nelapsed = 15914884.300292\n\nf\"computations took {elapsed/3600:.2f} hours\"\n\n\nname = \"arnaldur\"\n\n\n\"dasnfnaksujhn {name}\".format(name=\"whatever\")\n\n\n# basic string operations: str.split, str.join, etc...\n# fast regular expressions\n# more on it, with text processing lesson\n\n\nstr.split(\"me,you,others,them\",',')\n\n\nstr.join( \" | \",\n    str.split(\"me,you,others,them\",','),\n)\n\n\n\n\nThe example above used several special characters: \\n which corresponds to only one ascii character and {/} which disappears after the string formatting. If one desires to print these characters precisely one needs to escape them using \\ and { }.\n\nprint(\"This is a one \\\\nline string\")\nprint(\"This string keeps some {{curly}} brackets{}\".format('.'))\n\n\n\n\n(check help(str) or help?)\n\nlen() : length\nstrip() : removes characters at the ends\nsplit() : split strings into several substrings separated by separator\njoin() : opposite of split\n\n\n'others,'\n\n\n',me,others,'.strip(',')\n\n\ns.count(',')\n\n\nhelp(str)",
    "crumbs": [
      "Hands-on",
      "Python: syntax review"
    ]
  },
  {
    "objectID": "handson/python_syntax.html#assignment",
    "href": "handson/python_syntax.html#assignment",
    "title": "Python: syntax review",
    "section": "Assignment",
    "text": "Assignment\nAny object can be reused by assigning an identifier to it. This is done with assignment operator =.\n\na = 3\na\n\nNote that assignment operator = is different from comparison operator ==. Comparison operator is always True or False, while assignment operator has no value.\n\n(2==2) == True",
    "crumbs": [
      "Hands-on",
      "Python: syntax review"
    ]
  },
  {
    "objectID": "handson/python_syntax.html#containers",
    "href": "handson/python_syntax.html#containers",
    "title": "Python: syntax review",
    "section": "Containers",
    "text": "Containers\nAny object created in Python is identified by a unique id. One can think of it approximately as its reference. Object collections, contain arbitrary other python objects, that is they contain references to them.\n\nid(s)\n\n\ntuples\n\nconstruction\n\n(1,2,\"a\" )\n\nSince tuples are immutable, two identical tuples, will always contain the same data.\n\nt1  = (2,23)\nt2  = (2,23)\n\n\n# can contain any data\nt = (1,2,3,4,5,6)\nt1 = (t, \"a\", (1,2))\nt2 = (0,)  # note trailing coma for one element tuple\nt3 = (t, \"a\", (1,2))\n\n\nt[0] = 78\n\nSince tuples never change, they can be compared by hash values (if the data they hold can be hashed). Two tuples are identical if they contain the same data.\nRemark: hash function is any function that can be used to map data of arbitrary size to data of a fixed size. It is such that the probability of two data points of having the same hash is very small even if they are close to each other.\n\nt3 == t1\n\n\nprint(hash(t3))\nprint(hash(t1))\n\n\nid(t3), id(t1)\n\n\n\naccess elements\n\n# elements are accessed with brackets (0-based)\nt[0]\n\n\n# slice notation works too (  [min,max[ )\nt[1:3]\n\n\n# repeat with *\n(3,2)*5\n\n\n(0)*5\n\n\n(0,)*5\n\n\nt2*5\n\n\n# concatenate with +\nt+t1+t2\n\n\n# test for membership\n\n(1 in t)\n\n\n\n\nlists\nlists are enclosed by brackets are mutable ordered collections of elements\n\nl = [1,\"a\",4,5]\n\n\nl[1]\n\n\nl[1:] # if we omit the upper-bound it goes until the last element\n\n\nl[:2]\n\n\n# lists are concatenated with +\nl[:2] + l[2:] == l\n\n\n# test for membership\n(5 in l)\n\n\n# lists can be extended inplace\nll = [1,2,3]\nll.extend([4,5]) # several elements\nll.append(6)\nll\n\nSince lists are mutable, it makes no sense to compute them by hash value (or the hash needs to be recomputed every time the values change).\n\nhash(ll)\n\nSorted lists can be created with sorted (if elements can be ranked)\n\nll = [4,3,5]\n\n\nsorted(ll)\n\n\nll\n\nIt is also possible to sort in place.\n\nll.sort()\nll\n\n\nsorted(ll) # creates a new list\nll.sort()  # does it in place\n\n\n# in python internals:    ll.sort() equivalent sort(ll)\n\n\n\nset\nSets are unordered collections of unique elements.\n\ns1 = set([1,2,3,3,4,3,4])\ns2 = set([3,4,4,6,8])\nprint(s1, s2)\nprint(s1.intersection(s2))\n\n\n{3,4} == {4,3}\n\n\n\ndictionaries\nDictionaries are ordered associative collections of elements. They store values associated to keys.\n\n# construction with curly brackets\nd = {'a':0, 'b':1}\n\n\nd\n\n\n# values can be recovered by indexing the dict with a key\nd['b']\n\n\nd = dict()\n# d['a'] = 42\n# d['b'] = 78\nd\n\n\nd['a'] = 42\n\n\nd['b']\n\nKeys can be any hashable value:\n\nd[('a','b')] = 100\n\n\nd[ ['a','b'] ] = 100 # that won't work\n\nNote: until python 3.5 dictionaries were not ordered. Now the are guaranteed to keep the insertion order",
    "crumbs": [
      "Hands-on",
      "Python: syntax review"
    ]
  },
  {
    "objectID": "handson/python_syntax.html#control-flows",
    "href": "handson/python_syntax.html#control-flows",
    "title": "Python: syntax review",
    "section": "Control flows",
    "text": "Control flows\n\nConditional blocks\nConditional blocks are preceeded by if and followed by an indented block. Note that it is advised to indent a block by a fixed set of space (usually 4) rather than use tabs.\n\nif 'sun'&gt;'moon':\n    print('warm')\n\nThey can also be followed by elif and else statements:\n\nx = 0.5\nif (x&lt;0):\n    y = 0.0\nelif (x&lt;1.0):\n    y = x\nelse:\n    y = 1+(x-1)*0.5\n\nRemark that in the conditions, any variable can be used. The following evaluate to False: - 0 - empty collection\n\nif 0: print(\"I won't print this.\")\nif 1: print(\"Maybe I will.\")\nif {}: print(\"Sir, your dictionary is empty\")\nif \"\": print(\"Sir, there is no string to speak of.\")\n\n\n\nWhile\nThe content of the while loop is repeated as long as a certain condition is met. Don’t forget to change that condition or the loop might run forever.\n\npoint_made = False\ni = 0\nwhile not point_made:\n    print(\"A fanatic is one who can't change his mind and won't change the subject.\")\n    i += 1 # this is a quasi-synonym of i = i + 1\n    if i&gt;=20:\n          point_made = True\n\n\n\nLoops\n\n# while loops\ni = 0\nwhile i&lt;=10:\n    print(str(i)+\" \",  end='')\n    i+=1\n\n\n# for loop\nfor i in [0,1,2,3,4,5,6,7,8,9,10]:\n    print(str(i)+\" \",  end='')\n\n\n# this works for any kind of iterable\n# for loop\nfor i in (0,1,2,3,4,5,6,7,8,9,10):\n    print(str(i)+\" \",  end='')\n\n\n# including range generator (note last value)\nfor i in range(11): \n    print(str(i)+\" \",  end='')\n\n\nrange(11)\n\n\n# one can also enumerate elements\ncountries = (\"france\", \"uk\", \"germany\")\nfor i,c in enumerate(countries): \n    print(f\"{i}: {c}\")\n\n\ns = set(c)\n\n\n# conditional blocks are constructed with if, elif, else\nfor i,c in enumerate(countries):\n    if len(set(c).intersection(set(\"brexit\"))):\n        print(c)\n    else:\n        print(c + \" 😢\")\n\nIt is possible to iterate over any iterable. This is true for a list or a generator:\n\nfor i in range(10): # range(10) is a generator\n    print(i)\n\n\nfor i in [0,1,2,3,4,5,6,7,8,9]:\n    print(i)\n\nWe can iterate of dictionary keys or values\n\nd = {1:2, 3:'i'}\nfor k in d.keys():\n    print(k, d[k])\nfor k in d.values():\n    print(k)\n\nor both at the same time:\n\nfor t in d.items():\n    print(t)\n\n# look at automatic unpacking\nfor (k,v) in d.items():\n    print(f\"key: {k}, value: {v}\")\n\n\n\nComprehension and generators\nThere is an easy syntax to construct lists/tuples/dicts: comprehension. Syntax is remminiscent of a for loop.\n\n[i**2 for i in range(10)]\n\n\nset(i-(i//2*2) for i in range(10))\n\n\n{i: i**2 for i in range(10)}\n\nComprehension can be combined with conditions:\n\n[i**2 for i in range(10) if i//3&gt;2]\n\nBehind the comprehension syntax, there is a special object called generator. Its role is to supply objects one by one like any other iterable.\n\n# note the bracket\ngen = (i**2 for i in range(10))\ngen # does nothing\n\n\ngen = (i**2 for i in range(10))\nfor e in gen:\n    print(e)\n\n\ngen = (i**2 for i in range(10))\nprint([e for e in gen])\n\nThere is a shortcut to converte a generator into a list: it’s called unpacking:\n\ngen = (i**2 for i in range(10))\n[*gen]",
    "crumbs": [
      "Hands-on",
      "Python: syntax review"
    ]
  },
  {
    "objectID": "handson/python_syntax.html#functions",
    "href": "handson/python_syntax.html#functions",
    "title": "Python: syntax review",
    "section": "Functions",
    "text": "Functions\nWrong approach\n\na1 = 34\nb1 = (1+a1*a1)\nc1 = (a1+b1*b1)\n\na2 = 36\nb2 = (1+a2*a2)\nc2 = (a2+b2*b2)\n\nprint(c1,c2)\n\nBetter approach\n\ndef calc(a):\n    b = 1+a*a\n    c = a+b*b\n    return c\n\n(calc(34), calc(36))\n\nit is equivalent to replace the content of the function by:\n\na = 32\n_a = a          # def calc(a):\n_b = 1+_a*_a    #    b = 1+a*a\n_c = _a+_b*_b   #    c = a+b*b\nres = _c        #    return c\n\nNote that variable names within the function have different names. This is to avoid name conflicts as in:\n\ny = 1\ndef f(x):\n    y = x**2\n    return y+1\ndef g(x):\n    y = x**2+0.1\n    return y+1\nr1 = f(1.4)\nr2 = g(1.4)\nr3 = y\n(r1,r2,r3)\n\n\nl = ['france', 'germany']\ndef fun(i):\n    print(f\"Country: {l[i]}\")\nfun(0)\n\n\nl = ['france', 'germany']\ndef fun(i):\n    l = ['usa', 'japan']\n    l.append('spain')\n    print(f\"Country: {l[i]}\")\nfun(0)\n\n\nl\n\nIn the preceding code block, value of y has not been changed by calling the two functions. Check pythontutor.\n\nCalling conventions\nFunction definitions start with def and a colon indentation. Value are returned by return keyword. Otherwise the return value is None. Functions can have several arguments: def f(x,y) but always one return argument. It is however to return a tuple, and “unpack” it.\n\ndef f(x,y):\n    z1 = x+y\n    z2 = x-y\n    return (z1,z2)      # here brackets are optional:  `return z1,z2` works too\n\nres = f(0.1, 0.2)\nt1, t2 = f(0.2, 0.2)     # t1,t2=res works too\n\n\nres\n\nNamed arguments can be passed in any order and receive default values.\n\ndef problem(why=\"The moon shines.\", what=\"Curiosity killed the cat.\", where=\"Paris\"):\n    print(f\"Is it because {why.lower().strip('.')} that {what.lower().strip('.')}, in {where.strip('.')}?\")\n\n\nproblem(where='Paris')\n\n\nproblem(where=\"ESCP\", why=\"Square root of two is irrational\", what=\"Some regressions never work.\")\n\nPositional arguments and keyword arguments can be combined\n\ndef f(x, y, β=0.9, γ=4.0, δ=0.1):\n    return x*β+y**γ*δ\n\n\nf(0.1, 0.2)\n\n\n\nDocstrings\nFunctions are documented with a special string. Documentation It must follow the function signature immediately and explain what arguments are expected and what the function does\n\ndef f(x, y, β=0.9, γ=4.0, δ=0.1):   # kjhkugku\n    \"\"\"Compute the model residuals\n    \n    Parameters\n    ----------\n    x: (float) marginal propensity to do complicated stuff\n    y: (float) inverse of the elasticity of bifractional risk-neutral substitution\n    β: (float) time discount (default 0.9)\n    γ: (float) time discount (default 4.0)\n    δ: (float) time discount (default 0.1)\n    \n    Result\n    ------\n    res: beta-Hadamard measure of cohesiveness\n    \n    \"\"\"\n    res = x*β+y**γ*δ\n    return res\n\nRemark: Python 3.6 has introduced type indication for functions. They are useful as an element of indication and potentially for type checking. We do not cover them in this tutorial but this is what they look like:\n\ndef f(a: int, b:int)-&gt;int:\n    if a&lt;=1:\n        return 1\n    else:\n        return f(a-1,b) + f(a-2,b)*b\n\n\n\n\nPacking and unpacking\nA common case is when one wants to pass the elements of an iterable as positional argument and/or the elements of a dictionary as keyword arguments. This is espacially the case, when one wants to determine functions that act on a given calibration. Without unpacking all arguments would need to be passed separately.\n\nv = (0.1, 0.2)\np = dict(β=0.9, γ=4.0, δ=0.1)\n\nf(v[0], v[1], β=p['β'], γ=p['γ'], δ=p['δ'])\n\nThere is a special syntax for that: * unpacks positional arguments and ** unpacks keyword arguments. Here is an example:\n\nf(*v, **p)\n\nThe same characters * and ** can actually be used for the reverse operation, that is packing. This is useful to determine functions of a variable number of arguments.\n\ndef fun(**p):\n    β = p['β']\n    return β+1\nfun(β=1.0)\nfun(β=1.0, γ=2.0) # γ is just ignored\n\nInside the function, unpacked objects are lists and dictionaries respectively.\n\ndef fun(*args, **kwargs):\n    print(f\"Positional arguments: {len(args)}\")\n    for a in args:\n        print(f\"- {a}\")\n    print(f\"Keyword arguments: {len(args)}\")\n    for key,value in kwargs.items():\n        print(f\"- {key}: {value}\")\n\n\nfun(0.1, 0.2, a=2, b=3, c=4)\n\n\n\nFunctions are first class objects\nThis means they can be assigned and passed around.\n\ndef f(x): return 2*x*(1-x)\ng = f # now `g` and `f` point to the same function\ng(0.4)\n\n\ndef sumsfun(l, f):\n    return [f(e) for e in l]\n\n\nsumsfun([0.0, 0.1, 0.2], f)\n\n\ndef compute_recursive_series(x0, fun, T=50):\n    a = [x0]\n    for t in range(T):\n        x0 = a[-1]\n        x = fun(x0)\n        a.append(x)\n    return a\n\ncompute_recursive_series(0.3, f, T=5)\n\nThere is another syntax to define a function, without giving it a name first: lambda functions. It is useful when passing a function as argument.\n\nsorted(range(6), key=lambda x: (-2)**x)\n\nLambda functions are also useful to reduce quickly the number of arguments of a function (aka curryfication)\n\ndef logistic(μ,x): return μ*x*(1-x)\n# def chaotic(x): return logistic(3.7, x)\n# def convergent(x): return logistic(2.5, x)\nchaotic = lambda x: logistic(3.7, x)\nconvergent = lambda x: logistic(2.5, x)\n\n\nl = [compute_recursive_series(0.3,fun, T=20) for fun in [convergent, chaotic]]\n[*zip(*l)]\n\n\nfrom matplotlib import pyplot as plt\nimport numpy as np\ntab = np.array(l)\nplt.plot(tab[0,:-1],tab[0,1:])\ntab = np.array(l)\nplt.plot(tab[1,:-1],tab[1,1:])\nplt.plot(np.linspace(0,1),np.linspace(0,1))\nplt.xlabel(\"$x_n$\")\nplt.ylabel(\"$x_{n+1}$\")\nplt.grid()\n\n\n\nFunctions pass arguments by reference\nMost of the time, variable affectation just create a reference.\n\na = [1,2,3]\nb = a\na[1] = 0\n(a, b)\n\nTo get a copy instead, one needs to specify it explicitly.\n\nimport copy\na = [1,2,3]\nb = copy.copy(a)\na[1] = 0\n(a, b)\n\nNot that copy follows only one level of references. Use deepcopy for more safety.\n\na0 = ['a','b']\na = [a0, 1, 2]\nb = copy.copy(a)\na[0][0] = 'ξ'\na, b\n\n\na0 = ['a','b']\na = [a0, 1, 2]\nb = copy.deepcopy(a)\na[0][0] = 'ξ'\na, b\n\nArguments in a function are references towards the original object. No data is copied. It is then easy to construct functions with side-effects.\n\ndef append_inplace(l1, obs):\n    l1.append(obs)\n    return l1\nl1, obs = ([1,2,3], 1.5)\nl2 = append_inplace(l1,obs)\nprint(l2, l1)\n# note that l1 and l2 point to the same object\nl1[0] = 'hey'\nprint(l2, l1)\n\nThis behaviour might feel unnatural but is very sensible. For instance if the argument is a database of several gigabytes and one wants to write a function which will modify a few of its elements, it is not reasonable to copy the db in full.",
    "crumbs": [
      "Hands-on",
      "Python: syntax review"
    ]
  },
  {
    "objectID": "handson/python_syntax.html#objects",
    "href": "handson/python_syntax.html#objects",
    "title": "Python: syntax review",
    "section": "Objects",
    "text": "Objects\nObjects ?\n\ncan be passed around / referred too\nhave properties (data) and methods (functions) attached to them\ninherit properties/methods from other objects\n\nObjects are defined by a class definition. By convention, classes names start with uppercase . To create an object, one calls the class name, possibly with additional arguments.\n\nclass Dog:\n    name = \"May\" # class property\n\nd1 = Dog()\nd2 = Dog()\n\nprint(f\"Class: d1-&gt;{type(d1)}, d2-&gt;{type(d2)}\")\nprint(f\"Instance address: d2-&gt;{d1},{d2}\")\n\nNow, d1 and d2 are two different instances of the same class Dog. Since properties are mutable, instances can have different data attached to it.\n\nd1.name = \"Boris\"\nprint([e.name for e in [d1,d2]])\n\nMethods are functions attached to a class / an instance. Their first argument is always an instance. The first argument can be used to acess data held by the instance.\n\nclass Dog:\n    name = None # default value\n    def bark(self):\n        print(\"Wouf\")\n    def converse(self):\n        n = self.name\n        print(f\"Hi, my name is {n}. I'm committed to a strong and stable government.\")\n        \nd = Dog()\nd.bark()   # bark(d)\nd.converse()\n\n\nConstructor\nThere is also a special method __init__ called the constructor. When an object is created, it is called on the instance. This is useful in order to initialize parameters of the instance.\n\nclass Calibration:\n    \n    def __init__(self, x=0.1, y=0.1, β=0.0):\n        if not (β&gt;0) and (β&lt;1):\n            raise Exception(\"Incorrect calibration\"})\n        self.x = x\n        self.y = y\n        self.β = β\n\n\nc1 = Calibration()\nc2 = Calibration(x=3, y=4)\n\nTwo instances of the same class have the same method, but can hold different data. This can change the behaviour of these methods.\n\n# class Dog:\n    \n#     state = 'ok'\n    \n#     def bark(self):\n#         if self.state == 'ok':\n#             print(\"Wouf!\")\n#         else:\n#             print(\"Ahouuu!\")\n        \n# d = Dog()\n# d1 = Dog()\n# d1.state = 'hungry'\n\n# d.bark()\n# d1.bark()\n\nTo write a function which will manipulate properties and methods of an object, it is not required to know its type in advance. The function will succeed as long as the required method exist, fail other wise. This is called “Duck Typing”: if it walks like a duck, it must be a duck…\n\nclass Duck:\n    def walk(self): print(\"/-\\_/-\\_/\")\n        \nclass Dog:\n    def walk(self): print(\"/-\\_/*\\_/\")\n    def bark(self): print(\"Wouf\")\n\n\nanimals = [C() for C in (Duck,Dog)]\ndef go_in_the_park(animal):\n    for i in range(3): animal.walk()\nfor a in animals:\n    go_in_the_park(a)\n\n\nInheritance\nThe whole point of classes, is that one can construct hierarchies of classes to avoid redefining the same methods many times. This is done by using inheritance.\n\nclass Animal:\n    \n    def run(self): print(\"👣\"*4)\n\nclass Dog(Animal):\n    def bark(self): print(\"Wouf\")\n        \nclass Rabbit(Animal):\n    def run(self):\n        super().run() ; print( \"🐇\" )\n\n\nAnimal().run()\ndog = Dog()\ndog.run()\ndog.bark()\nRabbit().run()\n\nIn the above example, the Dog class inherits from inherits the method run from the Animal class: it doesn’t need to be redefined again. Essentially, when run(dog) is called, since the method is not defined for a dog, python looks for the first ancestor of dog and applies the method of the ancestor.\n\n\nSpecial methods\nBy conventions methods starting with double lowercase __ are hidden. They don’t appear in tab completion. Several special methods can be reimplemented that way.\n\nclass Calibration:\n    \n    def __init__(self, x=0.1, y=0.1, β=0.1):\n        if not (β&gt;0) and (β&lt;1):\n            raise Exception(\"Incorrect calibration\")\n        self.x = x\n        self.y = y\n        self.β = β\n    \n    def __str__(self):\n        return f\"Calibration(x={self.x},y={self.y}, β={self.β})\"\n\n\nstr(Calibration() )\n\n\n\ncomplement\nPython is not 100% object oriented. - some objects cannot be subclassed - basic types behave sometimes funny (interning strings)\nmindfuck: Something that destabilizes, confuses, or manipulates a person’s mind.\n\na = 'a'*4192\nb = 'a'*4192\na is b\n\n\na = 'a'*512\nb = 'a'*512\na is b",
    "crumbs": [
      "Hands-on",
      "Python: syntax review"
    ]
  },
  {
    "objectID": "handson/neoclassical.html",
    "href": "handson/neoclassical.html",
    "title": "Neoclassical model with time iteration",
    "section": "",
    "text": "Our goal consists in this tutorial will be to solve numerically the neoclassical model using the time-iteration algorithms in two ways: - with a naive iterative algorithm - with a vectorized one (using numpy)\nRemark: this tutorial uses typehints as a way to help structure the code. They can safely be ignored.\n\nfrom dataclasses import dataclass\nfrom math import exp, sqrt\nimport numpy as np\nfrom typing import Any, Tuple\nimport numpy.typing as npt\nVector = npt.NDArray[1]\nMatrix = npt.NDArray[2]\n\n\nThe neoclassical model\nThe representative agent maximizes intertemporal discounted utility of consumption \\[\\sum_{t\\geq0} \\beta^t U(c_t)\\] where \\(U(c_t)=\\frac{(c_t)^{1-\\gamma}}{1-\\gamma}\\).\nProduction is \\[y_t=exp(z_t) k_t^{\\alpha}\\] where \\(k_t\\) is the amount of capital and \\(z_t=\\rho z_{t-1} + \\epsilon_t\\) and AR1 process with \\((\\epsilon_t)\\) a normal innovation of standard deviation \\(\\sigma\\).\nThe law of motion for the capital depends on investment \\(i_t\\) and capital depreciation \\(\\delta\\):\n\\[k_t = (1-\\delta) k_{t-1} + i_{t-1}\\]\nThe first order condition corresponding to the optimization problem is:\n\\[\\beta E_t \\left[ \\frac{U^{\\prime}(c_{t+1}}{U^{\\prime}(c_t)})\\left( 1- \\delta + \\alpha exp(z_{t+1}) k_{t+1}^{\\alpha-1} \\right) \\right] =1\\]\n\nExercise 1 What are the states of the problems? the controls? the exogenous shocks?\n\n\n# states: (z,k)\n# controls: (i,)  \n\n# everything else can be computed from it\n# auxiliary: (y,c)\n\n# shocks: (epsilon,)\n\n# paramaters: alpha,beta,gamma,delta,sigma,rho\n\n\nExercise 2 Define an object to represent the model calibration (you can use a dataclass).\n\n\n@dataclass\nclass Neoclassical:\n    \n    alpha = 0.3\n    beta = 0.96\n    gamma = 4.0\n    delta = 0.1\n    rho = 0.9\n    sigma = 0.01\n\nm = Neoclassical()\n\n\nExercise 3 Define a function to compute the steady-state controls and states.\n\n\ndef steady_state(m: Neoclassical) -&gt; Tuple[ Tuple[float, float], Tuple[float]]:\n    \n    z:float = 0.0\n    k:float = ((1/m.beta-(1-m.delta))/m.alpha)**(1/(m.alpha-1))\n    i = k*m.delta\n    s = (z,k) # tuple of states\n    x = (i,) #tuple of controls\n    return (s,x)\n\n\n\nNaive solution\n\nExercise 4 Define a cartesian grid on productivity and capital:\n\n\ndef get_grid(m: Neoclassical, size: Tuple[int, int]) -&gt; Tuple[ Vector, Vector]:\n    \n    s,x = steady_state(m)\n\n    sigma_e = m.sigma/sqrt(1-m.rho**2)\n    kbar = s[1] # steady state value of capital\n\n    zvec = np.linspace( -2*sigma_e, 2*sigma_e, size[0])\n    kvec = np.linspace(0.5*kbar,kbar*1.5,size[1])\n    return (zvec, kvec)\n\ngrid  = get_grid(m, (10,10))\n\n\nExercise 5 Define an initial guess representing the values of the controls on the grid\n\n\nN_1, N_2 = (10,10)\n\nx0 = np.zeros( (N_1, N_2, 1) )\nx0[:, :, 0] = x\nx0;\n\n\ndef initial_guess(m: Neoclassical, grid)-&gt;npt.NDArray[3]\n\n    # x0 = 3-dimensional array of size\n\nx0 = initial_guess(m, grid)\n\n\nExercise 6 Define a decision rule which interpolates the initial guess on any state\n\n\ndef phi(m: Neoclassical, s:: Tuple[float, float], x0::npt.NDArray[3])-&gt; Tuple[float]\n    pass\n\n\nExercise 7 Compute the euler residual, for a given realization of the exogenous shocks.\n\n\ndef f(m: RBC, s: Tuple[float,float], x:Tuple[float], E: Tuple[float], grid, theta):\n    ## grid is the discretized grid from before\n    ## theta contains the values of the controls on the grid\n    pass\n\n\nExercise 8 Compute the expected euler residuals, integrating over all possible realizations of the exogenous shocks.\n\n\ndef F(m: RBC, s: Tuple[float,float], x:Tuple[float], grid, theta, discr:Tuple[Vector, Vector]):\n    ## grid is the discretized grid from before\n    ## theta contains the values of the controls on the grid\n    ## discr contains the weights w,x of the gaussian quadrature\n    pass\n\n\nExercise 9 At the steady-state, find the optimal control, assuming future decisions are taken according to the initial guess.\n\n\n# find x such that F(m,s,x,grid,theta_0,discr) = 0\n\n\nExercise 10 Solve for the optimal controls over the whole grid, still assuming future decisions are taken according to the initial guess.\n\n\n# find x such that F(m,s,x,grid,theta_0,discr) = 0\n\n\nExercise 11 Implement the time iteration algorithm.\n\n\ndef time_iteration_0(m: Neoclassical, grid, discr, x0):\n    pass\n\n\nExercise 12 Time the result (and profile).\n\n\ndef time_iteration_0(m: Neoclassical, grid, discr, x0):\n    pass\n\n\n\nVectorization\nThere are at least two approaches to speed up the code, with the same algorithm: - avoid the interpretation cost by compiling the code (for instance using numba) - vectorize the operations over the whole grid\n\nExercise 13 Given \\(N\\) the number of points of the grid, create a matrix, representing the vector of all grid points. It should be an \\(N \\times 2\\) matrix.\n\n\n# grid_v = \n\n\nExercise 14 Rewrite the decision rule so that it can operate on a vector of states.\n\n\ndef phi_v(m: Neoclassical, s:: Matrix, x0::npt.NDArray[3])-&gt; Matrix\n    pass\n\n\nExercise 15 Rewrite the euler residual function so that it can operate on a vector of states with the corresponding vector of controls.\n\n\ndef f_v(m: RBC, s: Matrix, x:Matrix, E: Tuple[float], grid, theta)-&gt;Matrix:\n    ## grid is the discretized grid from before\n    ## theta contains the values of the controls on the grid\n    pass\n\n\nExercise 16 Rewrite the integrated euler residual function so that it can operate on a vector of states with the corresponding vector of controls.\n\n\ndef F_v(m: RBC, s: Matrix, x:Matrix, grid, theta)-&gt;Matrix:\n    ## grid is the discretized grid from before\n    ## theta contains the values of the controls on the grid\n    pass\n\n\nExercise 17 Compute the jacobian of \\(F_v\\) w.r.t \\(x\\).\n\n\n#\n\n\nExercise 18 Solve for the matrix x such that F_v(m, s, x:Matrix, grid, theta)=0\n\n\n#\n\n\nExercise 19 Implement the time iteration algorithm.\n\n\n#",
    "crumbs": [
      "Hands-on",
      "Neoclassical model with time iteration"
    ]
  },
  {
    "objectID": "handson/jax_intro copy.html",
    "href": "handson/jax_intro copy.html",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "This notebook (adapted Quantecon) provides a short introduction to Google JAX.\n\n\nOne way to use JAX is as a plug-in NumPy replacement. Let’s look at the similarities and differences.\n\n\nThe following import is standard, replacing import numpy as np:\n\nimport jax\nimport jax.numpy as jnp\n\nNow we can use jnp in place of np for the usual array operations:\n\na = jnp.asarray((1.0, 3.2, -1.5))\n\n\nprint(a)\n\n\nprint(jnp.sum(a))\n\n\nprint(jnp.mean(a))\n\n\nprint(jnp.dot(a, a))\n\nHowever, the array object a is not a NumPy array:\n\na\n\n\ntype(a)\n\nEven scalar-valued maps on arrays return JAX arrays.\n\njnp.sum(a)\n\nJAX arrays are also called “device arrays,” where term “device” refers to a hardware accelerator (GPU or TPU).\n(In the terminology of GPUs, the “host” is the machine that launches GPU operations, while the “device” is the GPU itself.)\nOperations on higher dimensional arrays are also similar to NumPy:\n\nA = jnp.ones((2, 2))\nB = jnp.identity(2)\nA @ B\n\n\nfrom jax.numpy import linalg\n\n\nlinalg.inv(B)   # Inverse of identity is identity\n\n\nlinalg.eigh(B)  # Computes eigenvalues and eigenvectors\n\n\n\n\nOne difference between NumPy and JAX is that JAX currently uses 32 bit floats by default.\nThis is standard for GPU computing and can lead to significant speed gains with small loss of precision.\nHowever, for some calculations precision matters. In these cases 64 bit floats can be enforced via the command\n\njax.config.update(\"jax_enable_x64\", True)\n\nLet’s check this works:\n\njnp.ones(3)\n\nAs a NumPy replacement, a more significant difference is that arrays are treated as immutable.\nFor example, with NumPy we can write\n\nimport numpy as np\na = np.linspace(0, 1, 3)\na\n\nand then mutate the data in memory:\n\na[0] = 1\na\n\nIn JAX this fails:\n\na = jnp.linspace(0, 1, 3)\na\n\n\n# a[0] = 1\n\nIn line with immutability, JAX does not support inplace operations:\n\na = np.array((2, 1))\na.sort()\na\n\n\na = jnp.array((2, 1))\na_new = a.sort()\na, a_new\n\nThe designers of JAX chose to make arrays immutable because JAX uses a functional programming style. More on this below.\nNote that, while mutation is discouraged, it is in fact possible with at, as in\n\na = jnp.linspace(0, 1, 3)\nid(a)\n\n\na\n\n\na.at[0].set(1)\n\nWe can check that the array is mutated by verifying its identity is unchanged:\n\nid(a)\n\n\n\n\n\nRandom numbers are also a bit different in JAX, relative to NumPy. Typically, in JAX, the state of the random number generator needs to be controlled explicitly.\n\nimport jax.random as random\n\nFirst we produce a key, which seeds the random number generator.\n\nkey = random.PRNGKey(1)\n\n\ntype(key)\n\n\nprint(key)\n\nNow we can use the key to generate some random numbers:\n\nx = random.normal(key, (3, 3))\nx\n\nIf we use the same key again, we initialize at the same seed, so the random numbers are the same:\n\nrandom.normal(key, (3, 3))\n\nTo produce a (quasi-) independent draw, best practice is to “split” the existing key:\n\nkey, subkey = random.split(key)\n\n\nrandom.normal(key, (3, 3))\n\n\nrandom.normal(subkey, (3, 3))\n\nThe function below produces k (quasi-) independent random n x n matrices using this procedure.\n\ndef gen_random_matrices(key, n, k):\n    matrices = []\n    for _ in range(k):\n        key, subkey = random.split(key)\n        matrices.append(random.uniform(subkey, (n, n)))\n    return matrices\n\n\nmatrices = gen_random_matrices(key, 2, 2)\nfor A in matrices:\n    print(A)\n\nOne point to remember is that JAX expects tuples to describe array shapes, even for flat arrays. Hence, to get a one-dimensional array of normal random draws we use (len, ) for the shape, as in\n\nrandom.normal(key, (5, ))\n\n\n\n\nThe JAX just-in-time (JIT) compiler accelerates logic within functions by fusing linear algebra operations into a single optimized kernel that the host can launch on the GPU / TPU (or CPU if no accelerator is detected).\n\n\nTo see the JIT compiler in action, consider the following function.\n\ndef f(x):\n    a = 3*x + jnp.sin(x) + jnp.cos(x**2) - jnp.cos(2*x) - x**2 * 0.4 * x**1.5\n    return jnp.sum(a)\n\nLet’s build an array to call the function on.\n\nn = 50_000_000\nx = jnp.ones(n)\n\nHow long does the function take to execute?\n\n%time f(x).block_until_ready()\n\nHere, in order to measure actual speed, we use the `block_until_ready()` method \nto hold the interpreter until the results of the computation are returned from\nthe device. This is necessary because JAX uses asynchronous dispatch, which\nallows the Python interpreter to run ahead of GPU computations.\n\nThe code doesn’t run as fast as we might hope, given that it’s running on a GPU.\nBut if we run it a second time it becomes much faster:\n\n%time f(x).block_until_ready()\n\nThis is because the built in functions like jnp.cos are JIT compiled and the first run includes compile time.\nWhy would JAX want to JIT-compile built in functions like jnp.cos instead of just providing pre-compiled versions, like NumPy?\nThe reason is that the JIT compiler can specialize on the size of the array being used, which is helpful for parallelization.\nFor example, in running the code above, the JIT compiler produced a version of jnp.cos that is specialized to floating point arrays of size n = 50_000_000.\nWe can check this by calling f with a new array of different size.\n\nm = 50_000_001\ny = jnp.ones(m)\n\n\n%time f(y).block_until_ready()\n\nNotice that the execution time increases, because now new versions of the built-ins like jnp.cos are being compiled, specialized to the new array size.\nIf we run again, the code is dispatched to the correct compiled version and we get faster execution.\n\n%time f(y).block_until_ready()\n\nThe compiled versions for the previous array size are still available in memory too, and the following call is dispatched to the correct compiled code.\n\n%time f(x).block_until_ready()\n\n\n\n\nWe can do even better if we manually JIT-compile the outer function.\n\nf_jit = jax.jit(f)   # target for JIT compilation\n\nLet’s run once to compile it:\n\nf_jit(x)\n\nAnd now let’s time it.\n\n%time f_jit(x).block_until_ready()\n\nNote the speed gain.\nThis is because the array operations are fused and no intermediate arrays are created.\nIncidentally, a more common syntax when targetting a function for the JIT compiler is\n\n@jax.jit\ndef f(x):\n    a = 3*x + jnp.sin(x) + jnp.cos(x**2) - jnp.cos(2*x) - x**2 * 0.4 * x**1.5\n    return jnp.sum(a)\n\n\n\n\n\nFrom JAX’s documentation:\nWhen walking about the countryside of Italy, the people will not hesitate to tell you that JAX has “una anima di pura programmazione funzionale”.\nIn other words, JAX assumes a functional programming style.\nThe major implication is that JAX functions should be pure.\nA pure function will always return the same result if invoked with the same inputs.\nIn particular, a pure function has\n\nno dependence on global variables and\nno side effects\n\nJAX will not usually throw errors when compiling impure functions but execution becomes unpredictable.\nHere’s an illustration of this fact, using global variables:\n\na = 1  # global\n\n@jax.jit\ndef f(x):\n    return a + x\n\n\nx = jnp.ones(2)\n\n\nf(x)\n\nIn the code above, the global value a=1 is fused into the jitted function.\nEven if we change a, the output of f will not be affected — as long as the same compiled version is called.\n\na = 42\n\n\nf(x)\n\nChanging the dimension of the input triggers a fresh compilation of the function, at which time the change in the value of a takes effect:\n\nx = jnp.ones(3)\n\n\nf(x)\n\nMoral of the story: write pure functions when using JAX!\n\n\n\nJAX can use automatic differentiation to compute gradients.\nThis can be extremely useful for optimization and solving nonlinear systems.\nWe will see significant applications later in this lecture series.\nFor now, here’s a very simple illustration involving the function\n\ndef f(x):\n    return (x**2) / 2\n\nLet’s take the derivative:\n\nf_prime = jax.grad(f)\n\n\nf_prime(10.0)\n\nLet’s plot the function and derivative, noting that \\(f'(x) = x\\).\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nx_grid = jnp.linspace(-4, 4, 200)\nax.plot(x_grid, f(x_grid), label=\"$f$\")\nax.plot(x_grid, [f_prime(x) for x in x_grid], label=\"$f'$\")\nax.legend(loc='upper center')\nplt.show()\n\nWe defer further exploration of automatic differentiation with JAX until {doc}autodiff.\n\n\n\nWriting fast JAX code requires shifting repetitive tasks from loops to array processing operations, so that the JAX compiler can easily understand the whole operation and generate more efficient machine code.\nThis procedure is called vectorization or array programming, and will be familiar to anyone who has used NumPy or MATLAB.\nIn most ways, vectorization is the same in JAX as it is in NumPy.\nBut there are also some differences, which we highlight here.\nAs a running example, consider the function\n\\[\n    f(x,y) = \\frac{\\cos(x^2 + y^2)}{1 + x^2 + y^2}\n\\]\nSuppose that we want to evaluate this function on a square grid of \\(x\\) and \\(y\\) points and then plot it.\nTo clarify, here is the slow for loop version.\n\n@jax.jit\ndef f(x, y):\n    return jnp.cos(x**2 + y**2) / (1 + x**2 + y**2)\n\nn = 80\nx = jnp.linspace(-2, 2, n)\ny = x\n\nz_loops = np.empty((n, n))\n\n\n%%time\nfor i in range(n):\n    for j in range(n):\n        z_loops[i, j] = f(x[i], y[j])\n\nEven for this very small grid, the run time is extremely slow.\n(Notice that we used a NumPy array for z_loops because we wanted to write to it.)\n\n\nOK, so how can we do the same operation in vectorized form?\nIf you are new to vectorization, you might guess that we can simply write\n\nz_bad = f(x, y)\n\nBut this gives us the wrong result because JAX doesn’t understand the nested for loop.\n\nz_bad.shape\n\nHere is what we actually wanted:\n\nz_loops.shape\n\nTo get the right shape and the correct nested for loop calculation, we can use a meshgrid operation designed for this purpose:\n\nx_mesh, y_mesh = jnp.meshgrid(x, y)\n\nNow we get what we want and the execution time is very fast.\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nLet’s run again to eliminate compile time.\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nLet’s confirm that we got the right answer.\n\njnp.allclose(z_mesh, z_loops)\n\nNow we can set up a serious grid and run the same calculation (on the larger grid) in a short amount of time.\n\nn = 6000\nx = jnp.linspace(-2, 2, n)\ny = x\nx_mesh, y_mesh = jnp.meshgrid(x, y)\n\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nLet’s run again to get rid of compile time.\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nBut there is one problem here: the mesh grids use a lot of memory.\n\nx_mesh.nbytes + y_mesh.nbytes\n\nBy comparison, the flat array x is just\n\nx.nbytes  # and y is just a pointer to x\n\nThis extra memory usage can be a big problem in actual research calculations.\nSo let’s try a different approach using jax.vmap\n\n\nFirst we vectorize f in y.\n\nf_vec_y = jax.vmap(f, in_axes=(None, 0))  \n\nIn the line above, (None, 0) indicates that we are vectorizing in the second argument, which is y.\nNext, we vectorize in the first argument, which is x.\n\nf_vec = jax.vmap(f_vec_y, in_axes=(0, None))\n\nWith this construction, we can now call the function \\(f\\) on flat (low memory) arrays.\n\n%%time\nz_vmap = f_vec(x, y).block_until_ready()\n\nWe run it again to eliminate compile time.\n\n%%time\nz_vmap = f_vec(x, y).block_until_ready()\n\nThe execution time is essentially the same as the mesh operation but we are using much less memory.\nAnd we produce the correct answer:\n\njnp.allclose(z_vmap, z_mesh)"
  },
  {
    "objectID": "handson/jax_intro copy.html#jax-as-a-numpy-replacement",
    "href": "handson/jax_intro copy.html#jax-as-a-numpy-replacement",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "One way to use JAX is as a plug-in NumPy replacement. Let’s look at the similarities and differences.\n\n\nThe following import is standard, replacing import numpy as np:\n\nimport jax\nimport jax.numpy as jnp\n\nNow we can use jnp in place of np for the usual array operations:\n\na = jnp.asarray((1.0, 3.2, -1.5))\n\n\nprint(a)\n\n\nprint(jnp.sum(a))\n\n\nprint(jnp.mean(a))\n\n\nprint(jnp.dot(a, a))\n\nHowever, the array object a is not a NumPy array:\n\na\n\n\ntype(a)\n\nEven scalar-valued maps on arrays return JAX arrays.\n\njnp.sum(a)\n\nJAX arrays are also called “device arrays,” where term “device” refers to a hardware accelerator (GPU or TPU).\n(In the terminology of GPUs, the “host” is the machine that launches GPU operations, while the “device” is the GPU itself.)\nOperations on higher dimensional arrays are also similar to NumPy:\n\nA = jnp.ones((2, 2))\nB = jnp.identity(2)\nA @ B\n\n\nfrom jax.numpy import linalg\n\n\nlinalg.inv(B)   # Inverse of identity is identity\n\n\nlinalg.eigh(B)  # Computes eigenvalues and eigenvectors\n\n\n\n\nOne difference between NumPy and JAX is that JAX currently uses 32 bit floats by default.\nThis is standard for GPU computing and can lead to significant speed gains with small loss of precision.\nHowever, for some calculations precision matters. In these cases 64 bit floats can be enforced via the command\n\njax.config.update(\"jax_enable_x64\", True)\n\nLet’s check this works:\n\njnp.ones(3)\n\nAs a NumPy replacement, a more significant difference is that arrays are treated as immutable.\nFor example, with NumPy we can write\n\nimport numpy as np\na = np.linspace(0, 1, 3)\na\n\nand then mutate the data in memory:\n\na[0] = 1\na\n\nIn JAX this fails:\n\na = jnp.linspace(0, 1, 3)\na\n\n\n# a[0] = 1\n\nIn line with immutability, JAX does not support inplace operations:\n\na = np.array((2, 1))\na.sort()\na\n\n\na = jnp.array((2, 1))\na_new = a.sort()\na, a_new\n\nThe designers of JAX chose to make arrays immutable because JAX uses a functional programming style. More on this below.\nNote that, while mutation is discouraged, it is in fact possible with at, as in\n\na = jnp.linspace(0, 1, 3)\nid(a)\n\n\na\n\n\na.at[0].set(1)\n\nWe can check that the array is mutated by verifying its identity is unchanged:\n\nid(a)"
  },
  {
    "objectID": "handson/jax_intro copy.html#random-numbers",
    "href": "handson/jax_intro copy.html#random-numbers",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "Random numbers are also a bit different in JAX, relative to NumPy. Typically, in JAX, the state of the random number generator needs to be controlled explicitly.\n\nimport jax.random as random\n\nFirst we produce a key, which seeds the random number generator.\n\nkey = random.PRNGKey(1)\n\n\ntype(key)\n\n\nprint(key)\n\nNow we can use the key to generate some random numbers:\n\nx = random.normal(key, (3, 3))\nx\n\nIf we use the same key again, we initialize at the same seed, so the random numbers are the same:\n\nrandom.normal(key, (3, 3))\n\nTo produce a (quasi-) independent draw, best practice is to “split” the existing key:\n\nkey, subkey = random.split(key)\n\n\nrandom.normal(key, (3, 3))\n\n\nrandom.normal(subkey, (3, 3))\n\nThe function below produces k (quasi-) independent random n x n matrices using this procedure.\n\ndef gen_random_matrices(key, n, k):\n    matrices = []\n    for _ in range(k):\n        key, subkey = random.split(key)\n        matrices.append(random.uniform(subkey, (n, n)))\n    return matrices\n\n\nmatrices = gen_random_matrices(key, 2, 2)\nfor A in matrices:\n    print(A)\n\nOne point to remember is that JAX expects tuples to describe array shapes, even for flat arrays. Hence, to get a one-dimensional array of normal random draws we use (len, ) for the shape, as in\n\nrandom.normal(key, (5, ))"
  },
  {
    "objectID": "handson/jax_intro copy.html#jit-compilation",
    "href": "handson/jax_intro copy.html#jit-compilation",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "The JAX just-in-time (JIT) compiler accelerates logic within functions by fusing linear algebra operations into a single optimized kernel that the host can launch on the GPU / TPU (or CPU if no accelerator is detected).\n\n\nTo see the JIT compiler in action, consider the following function.\n\ndef f(x):\n    a = 3*x + jnp.sin(x) + jnp.cos(x**2) - jnp.cos(2*x) - x**2 * 0.4 * x**1.5\n    return jnp.sum(a)\n\nLet’s build an array to call the function on.\n\nn = 50_000_000\nx = jnp.ones(n)\n\nHow long does the function take to execute?\n\n%time f(x).block_until_ready()\n\nHere, in order to measure actual speed, we use the `block_until_ready()` method \nto hold the interpreter until the results of the computation are returned from\nthe device. This is necessary because JAX uses asynchronous dispatch, which\nallows the Python interpreter to run ahead of GPU computations.\n\nThe code doesn’t run as fast as we might hope, given that it’s running on a GPU.\nBut if we run it a second time it becomes much faster:\n\n%time f(x).block_until_ready()\n\nThis is because the built in functions like jnp.cos are JIT compiled and the first run includes compile time.\nWhy would JAX want to JIT-compile built in functions like jnp.cos instead of just providing pre-compiled versions, like NumPy?\nThe reason is that the JIT compiler can specialize on the size of the array being used, which is helpful for parallelization.\nFor example, in running the code above, the JIT compiler produced a version of jnp.cos that is specialized to floating point arrays of size n = 50_000_000.\nWe can check this by calling f with a new array of different size.\n\nm = 50_000_001\ny = jnp.ones(m)\n\n\n%time f(y).block_until_ready()\n\nNotice that the execution time increases, because now new versions of the built-ins like jnp.cos are being compiled, specialized to the new array size.\nIf we run again, the code is dispatched to the correct compiled version and we get faster execution.\n\n%time f(y).block_until_ready()\n\nThe compiled versions for the previous array size are still available in memory too, and the following call is dispatched to the correct compiled code.\n\n%time f(x).block_until_ready()\n\n\n\n\nWe can do even better if we manually JIT-compile the outer function.\n\nf_jit = jax.jit(f)   # target for JIT compilation\n\nLet’s run once to compile it:\n\nf_jit(x)\n\nAnd now let’s time it.\n\n%time f_jit(x).block_until_ready()\n\nNote the speed gain.\nThis is because the array operations are fused and no intermediate arrays are created.\nIncidentally, a more common syntax when targetting a function for the JIT compiler is\n\n@jax.jit\ndef f(x):\n    a = 3*x + jnp.sin(x) + jnp.cos(x**2) - jnp.cos(2*x) - x**2 * 0.4 * x**1.5\n    return jnp.sum(a)"
  },
  {
    "objectID": "handson/jax_intro copy.html#functional-programming",
    "href": "handson/jax_intro copy.html#functional-programming",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "From JAX’s documentation:\nWhen walking about the countryside of Italy, the people will not hesitate to tell you that JAX has “una anima di pura programmazione funzionale”.\nIn other words, JAX assumes a functional programming style.\nThe major implication is that JAX functions should be pure.\nA pure function will always return the same result if invoked with the same inputs.\nIn particular, a pure function has\n\nno dependence on global variables and\nno side effects\n\nJAX will not usually throw errors when compiling impure functions but execution becomes unpredictable.\nHere’s an illustration of this fact, using global variables:\n\na = 1  # global\n\n@jax.jit\ndef f(x):\n    return a + x\n\n\nx = jnp.ones(2)\n\n\nf(x)\n\nIn the code above, the global value a=1 is fused into the jitted function.\nEven if we change a, the output of f will not be affected — as long as the same compiled version is called.\n\na = 42\n\n\nf(x)\n\nChanging the dimension of the input triggers a fresh compilation of the function, at which time the change in the value of a takes effect:\n\nx = jnp.ones(3)\n\n\nf(x)\n\nMoral of the story: write pure functions when using JAX!"
  },
  {
    "objectID": "handson/jax_intro copy.html#gradients",
    "href": "handson/jax_intro copy.html#gradients",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "JAX can use automatic differentiation to compute gradients.\nThis can be extremely useful for optimization and solving nonlinear systems.\nWe will see significant applications later in this lecture series.\nFor now, here’s a very simple illustration involving the function\n\ndef f(x):\n    return (x**2) / 2\n\nLet’s take the derivative:\n\nf_prime = jax.grad(f)\n\n\nf_prime(10.0)\n\nLet’s plot the function and derivative, noting that \\(f'(x) = x\\).\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nx_grid = jnp.linspace(-4, 4, 200)\nax.plot(x_grid, f(x_grid), label=\"$f$\")\nax.plot(x_grid, [f_prime(x) for x in x_grid], label=\"$f'$\")\nax.legend(loc='upper center')\nplt.show()\n\nWe defer further exploration of automatic differentiation with JAX until {doc}autodiff."
  },
  {
    "objectID": "handson/jax_intro copy.html#writing-vectorized-code",
    "href": "handson/jax_intro copy.html#writing-vectorized-code",
    "title": "An Introduction to JAX",
    "section": "",
    "text": "Writing fast JAX code requires shifting repetitive tasks from loops to array processing operations, so that the JAX compiler can easily understand the whole operation and generate more efficient machine code.\nThis procedure is called vectorization or array programming, and will be familiar to anyone who has used NumPy or MATLAB.\nIn most ways, vectorization is the same in JAX as it is in NumPy.\nBut there are also some differences, which we highlight here.\nAs a running example, consider the function\n\\[\n    f(x,y) = \\frac{\\cos(x^2 + y^2)}{1 + x^2 + y^2}\n\\]\nSuppose that we want to evaluate this function on a square grid of \\(x\\) and \\(y\\) points and then plot it.\nTo clarify, here is the slow for loop version.\n\n@jax.jit\ndef f(x, y):\n    return jnp.cos(x**2 + y**2) / (1 + x**2 + y**2)\n\nn = 80\nx = jnp.linspace(-2, 2, n)\ny = x\n\nz_loops = np.empty((n, n))\n\n\n%%time\nfor i in range(n):\n    for j in range(n):\n        z_loops[i, j] = f(x[i], y[j])\n\nEven for this very small grid, the run time is extremely slow.\n(Notice that we used a NumPy array for z_loops because we wanted to write to it.)\n\n\nOK, so how can we do the same operation in vectorized form?\nIf you are new to vectorization, you might guess that we can simply write\n\nz_bad = f(x, y)\n\nBut this gives us the wrong result because JAX doesn’t understand the nested for loop.\n\nz_bad.shape\n\nHere is what we actually wanted:\n\nz_loops.shape\n\nTo get the right shape and the correct nested for loop calculation, we can use a meshgrid operation designed for this purpose:\n\nx_mesh, y_mesh = jnp.meshgrid(x, y)\n\nNow we get what we want and the execution time is very fast.\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nLet’s run again to eliminate compile time.\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nLet’s confirm that we got the right answer.\n\njnp.allclose(z_mesh, z_loops)\n\nNow we can set up a serious grid and run the same calculation (on the larger grid) in a short amount of time.\n\nn = 6000\nx = jnp.linspace(-2, 2, n)\ny = x\nx_mesh, y_mesh = jnp.meshgrid(x, y)\n\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nLet’s run again to get rid of compile time.\n\n%%time\nz_mesh = f(x_mesh, y_mesh).block_until_ready()\n\nBut there is one problem here: the mesh grids use a lot of memory.\n\nx_mesh.nbytes + y_mesh.nbytes\n\nBy comparison, the flat array x is just\n\nx.nbytes  # and y is just a pointer to x\n\nThis extra memory usage can be a big problem in actual research calculations.\nSo let’s try a different approach using jax.vmap\n\n\nFirst we vectorize f in y.\n\nf_vec_y = jax.vmap(f, in_axes=(None, 0))  \n\nIn the line above, (None, 0) indicates that we are vectorizing in the second argument, which is y.\nNext, we vectorize in the first argument, which is x.\n\nf_vec = jax.vmap(f_vec_y, in_axes=(0, None))\n\nWith this construction, we can now call the function \\(f\\) on flat (low memory) arrays.\n\n%%time\nz_vmap = f_vec(x, y).block_until_ready()\n\nWe run it again to eliminate compile time.\n\n%%time\nz_vmap = f_vec(x, y).block_until_ready()\n\nThe execution time is essentially the same as the mesh operation but we are using much less memory.\nAnd we produce the correct answer:\n\njnp.allclose(z_vmap, z_mesh)"
  },
  {
    "objectID": "handson/qe_notebook_jax.html",
    "href": "handson/qe_notebook_jax.html",
    "title": "Deep learning solution method with all-in-one expectation operator",
    "section": "",
    "text": "This is a JAX version using FLAX for neural networks and Optax for the optimization.\nSimilar code can be found for tensorflow and torch",
    "crumbs": [
      "Hands-on",
      "Deep learning solution method with all-in-one expectation operator"
    ]
  },
  {
    "objectID": "handson/qe_notebook_jax.html#jax-and-libraries",
    "href": "handson/qe_notebook_jax.html#jax-and-libraries",
    "title": "Deep learning solution method with all-in-one expectation operator",
    "section": "JAX and libraries",
    "text": "JAX and libraries\nJAX\n\nimport jax\nfrom jax import numpy as jnp\nfrom typing import Any, Callable, Sequence\n\nThis notebook uses several libraries. A missing library x can be installed using pip install x\n\nimport numpy as np\n# from math import sqrt\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm as tqdm         # tqdm is a nice library to visualize ongoing loops\nimport datetime\n# followint lines are used for indicative typing\nfrom typing import Tuple\nclass Vector: pass",
    "crumbs": [
      "Hands-on",
      "Deep learning solution method with all-in-one expectation operator"
    ]
  },
  {
    "objectID": "handson/qe_notebook_jax.html#the-model",
    "href": "handson/qe_notebook_jax.html#the-model",
    "title": "Deep learning solution method with all-in-one expectation operator",
    "section": "The model",
    "text": "The model\nWe consider the following consumption-saving problem:\n\\[\\begin{gather*}\n\\underset{\\left\\{ c_{t},w_{t+1}\\right\\}_{t=0}^{\\infty }}{\\max }E_{0}\\left[\n\\sum_{t=0}^{\\infty }\\exp (\\delta_{t})\\beta ^{t}u\\left( {c_{t}}\\right)\\right]  \\\\\n\\text{s.t. }w_{t+1}=\\left( w_{t}-c_{t}\\right) \\overline{r}\\exp (r_{t})+\\exp\n(y_{t}), \\\\\nc_{t}\\leq w_{t},\n\\end{gather*}\\]\nwhere \\(c_{t}\\) is consumption; \\(w_{t}\\) is the beginning-of-period cash-on-hand; \\(\\beta \\in \\left[ 0,1\\right)\\) is a subjective discount factor; \\(\\overline{r}\\in \\left( 0,\\frac{1}{\\beta }\\right)\\) is a (gross) constant interest rate; and initial condition \\(\\left( z,w\\right)\\) is given. There is an occasionally binding inequality constraint: consumption \\(c_{t}\\) cannot exceed cash-on-hand \\(w_{t}\\). There are four different exogenous state variables, namely, shocks to the interest rate (\\(r_{t}\\)), discount factor (\\(\\delta_t\\)), transitory component of income \\(q_{t}\\) and permanent component of income \\(p_{t}\\). The total income is \\(y_{t}=p_{t}q_{t}\\). All exogenous variables follows AR(1) processes:\n\\[\\begin{gather*}\ny_{t+1} &=&\\rho_{y}y_{t}+\\sigma_{y}\\epsilon_{t}, \\\\\np_{t+1} &=&\\rho_{p}p_{t}+\\sigma_{p}\\epsilon_{t}, \\\\\nr_{t+1} &=&\\rho_{r}r_{t}+\\sigma_{r}\\epsilon_{t}, \\\\\n\\delta_{t+1} &=&\\rho_{\\delta }\\delta_{t}+\\sigma_{\\delta }\\epsilon_{t},\n\\end{gather*}\\]\nwhere \\(\\epsilon_t \\sim \\mathcal{N}\\left( 0,1\\right)\\). We assume the Cobb-Douglas utility function \\(u\\left( {c_{t}}\\right) =\\frac{1}{1-\\gamma }\\left( c_{t}^{1-\\gamma }-1\\right)\\). The model’s parameters are specified below.\n\n# Model parameters\n\nβ = 0.9 \nγ = 2.0 \n# σ = 0.1  \n# ρ = 0.9\nσ_r = 0.001\nρ_r = 0.2\nσ_p = 0.0001\nρ_p = 0.999\nσ_q = 0.001\nρ_q = 0.9\nσ_δ = 0.001\nρ_δ = 0.2\nrbar = 1.04",
    "crumbs": [
      "Hands-on",
      "Deep learning solution method with all-in-one expectation operator"
    ]
  },
  {
    "objectID": "handson/qe_notebook_jax.html#stochastic-solution-domain",
    "href": "handson/qe_notebook_jax.html#stochastic-solution-domain",
    "title": "Deep learning solution method with all-in-one expectation operator",
    "section": "Stochastic solution domain",
    "text": "Stochastic solution domain\nWe solve the model on a random grid which is drawn from the following domain:\n\nfor AR1 processes, we take the ergodic distribution (recall that for an AR(1) process \\(z\\) with autocorrelation \\(\\rho\\) and conditional standard deviation \\(\\sigma\\), the ergodic distribution is normal with zero mean and standard deviation \\(\\sigma_z= \\frac{\\sigma}{\\sqrt{1-\\rho^2}}\\).\nfor available income we choose a uniform distribution between two finite bounds: \\(w\\in[w_{\\min}, w_{\\max}]\\).\n\n\n# Standard deviations for ergodic distributions of exogenous state variables\nσ_e_r = σ_r/(1-ρ_r**2)**0.5\nσ_e_p = σ_p/(1-ρ_p**2)**0.5\nσ_e_q = σ_q/(1-ρ_q**2)**0.5\nσ_e_δ = σ_δ/(1-ρ_δ**2)**0.5\n\n# bounds for available income\nwmin = 0.1\nwmax = 4.0",
    "crumbs": [
      "Hands-on",
      "Deep learning solution method with all-in-one expectation operator"
    ]
  },
  {
    "objectID": "handson/qe_notebook_jax.html#kuhn-tucker-conditions",
    "href": "handson/qe_notebook_jax.html#kuhn-tucker-conditions",
    "title": "Deep learning solution method with all-in-one expectation operator",
    "section": "Kuhn-Tucker conditions",
    "text": "Kuhn-Tucker conditions\nIn the recursive form, the solution can be characterized by the Kuhn-Tucker (KT) conditions \\[\\begin{equation*}\na\\geq 0,\\quad b\\geq 0\\quad and\\quad ab=0,\n\\end{equation*}\\] where \\(a\\) is the share of income that goes to savings and \\(b\\) is the Lagrange multiplier \\[\\begin{gather*}\na &\\equiv &w-c , \\\\\nb &\\equiv &u^{\\prime }(c)-\\beta \\overline{r}E_{\\epsilon }\\left[ \\left.\nu^{\\prime }\\left( c^{\\prime }\\right) \\exp \\left( \\delta ^{\\prime }-\\delta\n+r^{\\prime }\\right) \\right\\vert \\epsilon \\right] .\n\\end{gather*}\\] (In the absence of borrowing constraint \\(b=0\\), the KT conditions lead to the familiar Euler equation).\nInequality constraints are not directly compatible with the deep learning framework developed in the paper, so we reformulate the KT conditions as a set of equations that hold with equality. We use a smooth representation of the KT conditions, called the Fischer-Burmeister (FB) function, which is differentiable \\[\\begin{equation*}\nFB\\left( a,b\\right) =a+b-\\sqrt{a^{2}+b^{2}}=0.\n\\end{equation*}\\] The restriction \\(FB\\left( a,b\\right) =0\\) is also equivalent to the KT conditions.\nFor numerical treatment, we rewrite the FB function in the following unit-free form \\[\\begin{equation*}\nFB\\left( 1-\\zeta ,1-h\\right) =(1-\\zeta)+(1-h)-\\sqrt{(1-\\zeta)^{2}+(1-h)^{2}}=0,\n\\end{equation*}\\] where \\(\\zeta\\) and \\(h\\) are respectively the consumption share and normalized Lagrange multiplier \\[\\begin{gather*}\n\\zeta  &\\equiv &\\frac{c}{w}, \\\\\nh &\\equiv &\\beta \\overline{r}E_{\\epsilon }\\left[ \\left. \\frac{u^{\\prime\n}\\left( c^{\\prime }\\right) }{u^{\\prime }(c)}\\exp \\left( \\delta ^{\\prime\n}-\\delta +r^{\\prime }\\right) \\right\\vert \\epsilon \\right] .\n\\end{gather*}\\] In particular, \\(\\zeta\\) belongs to the interval \\(\\left[0,1\\right]\\) which is a convenient domain for defining neural network. In turn, \\(h\\) is normalized to be around one: we will parameterize it with neural network in the way that ensures that it is nonnegative.\n\n# here are the Fisher Burmeister functions with JAX\nmin_FB = lambda a,b: a+b-jnp.sqrt(a**2+b**2)\nmax_FB = lambda a,b: -min_FB(-a,-b)",
    "crumbs": [
      "Hands-on",
      "Deep learning solution method with all-in-one expectation operator"
    ]
  },
  {
    "objectID": "handson/qe_notebook_jax.html#parameterizing-decision-functions-with-neural-network",
    "href": "handson/qe_notebook_jax.html#parameterizing-decision-functions-with-neural-network",
    "title": "Deep learning solution method with all-in-one expectation operator",
    "section": "Parameterizing decision functions with neural network",
    "text": "Parameterizing decision functions with neural network\nThere are many different decision functions that we can approximate for characterizing the solution, including consumption, next-period income, etc. We chose to approximate the two functions that we defined earlier: the share of consumption, \\(\\zeta \\equiv \\frac{c}{w}\\), and the normalized Lagrange multiplier \\(h\\). Since the model is stationary, we look for a decision rule \\[\\begin{equation*}\n\\left(\n\\begin{matrix}\n\\zeta  \\\\\nh%\n\\end{matrix}%\n\\right) =\\varphi (s;\\theta ),\n\\end{equation*}\\] where \\(s=(r, \\delta, q, p, w)\\) is the 5-dimensional state space, and \\(\\varphi\\) is a function to be determined.\nA common approach in computational economics is to approximate an unknown function \\(\\varphi\\) using some flexible function family \\(\\varphi(...;\\theta)\\) parameterized by a vector of coefficients \\(\\theta\\), e.g., a polynomial family. Neural networks are just a special family of approximating functions. A distinctive feature of neural networks is that they have a nonlinear dependence of the approximation function on the coefficients \\(\\theta\\). TensorFlow contains a submodule keras, which makes it easy to build such a network. Below, we build the multilayer perceptrion: a 2 hidden layers 32x32x32x2 network with relu activation functions and linear outputs.\n\nimport flax\nfrom flax import nnx # old API\nfrom flax import linen as nn # new stateless API\n\n\nclass MLP(nn.Module):\n  \n  def __init__(self):\n    self.linear1 = nn.Dense(32)\n    self.linear2 = nn.Dense(32)\n    self.linear3 = nn.Dense(32)\n    self.linear4 = nn.Dense(2)\n\n  def __call__(self, x: jax.Array):\n    x = nnx.relu(self.linear1(x))\n    x = nnx.relu(self.linear2(x))\n    x = nnx.relu(self.linear3(x))\n    x = self.linear4(x)\n    return x\n  \n\n\nclass ExplicitMLP(nn.Module):\n  features: Sequence[int]\n\n  def setup(self):\n    # we automatically know what to do with lists, dicts of submodules\n    self.layers = [nn.Dense(feat) for feat in self.features]\n    # for single submodules, we would just write:\n    # self.layer1 = nn.Dense(feat1)\n\n  def __call__(self, inputs):\n    x = inputs\n    for i, lyr in enumerate(self.layers):\n      x = lyr(x)\n      if i != len(self.layers) - 1:\n        x = nn.relu(x)\n    return x\n\n\n# this creates a 3 layer perceptron with 32 neurons on each.\nmodel = ExplicitMLP(features=[32,32,32,2])\n\n\n# the following code initializes the neural network with random values\nkey1, key2 = jax.random.split(jax.random.PRNGKey(0), 2)\nx = jax.random.uniform(key1, (5,))\ntheta_0 = model.init(key2, x)\n# all the trainable parameters of the NN are stored in theta_0\n# it is a \"pytree\", that we will be able to use to compute gradients\n\n\n#  pretty print requres the library `treescope` to be installed\nnnx.display(model)\n\n     \n\n\nNext, we create the decision rule which takes as input 5 vectors of the same size \\(n\\) for the states \\(r\\), \\(\\delta\\), \\(q\\), \\(p\\), \\(w\\) and returns two vectors of size \\(n\\) for \\(\\zeta\\) and \\(h\\), respectively. We use different nonlinear transformation for the two decision functions:\n\\[\\begin{equation*}\n\\varphi(s;\\theta)=\\left(\\begin{matrix}\\frac{1}{1+e^{-nn(s;\\theta)}}\\\\\n\\exp(nn(s;\\theta))\\end{matrix}\\right)\n\\end{equation*}\\]\nwhere nn denotes neural network; the first and second elements in the vector function \\(\\varphi\\) are used to get \\(\\zeta\\in[0,1]\\) and \\(h&gt;0\\), respectively.\n\ndef dr(theta, r: Vector, p: Vector, q: Vector, δ: Vector, w: Vector)-&gt; Tuple[Vector, Vector]:\n\n    # we normalize exogenous state variables by their 2 standard deviations \n    # so that they are typically between -1 and 1 \n    r = r/σ_e_r/2\n    δ = δ/σ_e_δ/2\n    q = q/σ_e_q/2\n    p = p/σ_e_p/2\n    \n    # we normalze income to be between -1 and 1\n    w = (w-wmin)/(wmax-wmin)*2.0-1.0\n\n    # we prepare input to the perceptron\n    # s = tf.concat([_e[:,None] for _e in [r,p,q,δ,w]], axis=1) # equivalent to np.column_stack\n    \n    s = jnp.column_stack([r,p,q,δ,w])\n\n    x = model.apply(theta, s) # n x 2 matrix \n\n    # consumption share is always in [0,1]\n    ζ = jax.nn.sigmoid( x[:,0] )\n    \n    # expectation of marginal consumption is always positive\n    h = jnp.exp( x[:,1] )\n    \n    return (ζ, h)\n\nFinally, as an illustration, we plot the initial guess of decision rules against \\(w\\). Note that the coefficients of the perceptron are initialized with random values, so that each run will provide a different plot. Here, we are using TensorFlow in an eager mode, i.e., calculations are returned immediately, so that the library essentially behaves in the same way as numpy, and is in fact mostly compatible with it.\n\nwvec = jnp.linspace(wmin, wmax, 100)\n# r,p,q,δ are zero-mean\nζvec, hvec = dr(theta_0, wvec*0, wvec*0, wvec*0, wvec*0, wvec)\n\n\nplt.plot(wvec, wvec, linestyle='--', color='black')\nplt.plot(wvec, wvec*ζvec)\nplt.xlabel(\"$w_t$\")\nplt.ylabel(\"$c_t$\")\nplt.title(\"Initial Guess\")\nplt.grid()",
    "crumbs": [
      "Hands-on",
      "Deep learning solution method with all-in-one expectation operator"
    ]
  },
  {
    "objectID": "handson/qe_notebook_jax.html#residuals-in-the-models-equations",
    "href": "handson/qe_notebook_jax.html#residuals-in-the-models-equations",
    "title": "Deep learning solution method with all-in-one expectation operator",
    "section": "Residuals in the model’s equations",
    "text": "Residuals in the model’s equations\nTo identify the unknown decision functions for \\(\\zeta\\) and \\(h\\), we use two modelp’s equations, namely, the definition of normalized Lagrange multiplier and the FB function representing the KT conditions, respectively: \\[\\begin{gather*}\nh=\\beta \\overline{r}E_{\\epsilon }\\left[ \\left. \\frac{u^{\\prime }\\left(\nc^{\\prime }\\right) }{u^{\\prime }(c)}\\exp \\left( \\delta ^{\\prime }-\\delta\n+r^{\\prime }\\right) \\right\\vert \\epsilon \\right] , \\\\\nFB\\left( 1-\\zeta ,1-h\\right) =0\n\\end{gather*}\\] where \\(\\epsilon=(\\epsilon_r,\\epsilon_\\delta,\\epsilon_q,\\epsilon_p)\\).\nWe do not need to include the definition \\(\\zeta = \\frac{c}{w}\\) because we will impose it to hold exactly in the solution by setting \\(c=w\\zeta\\) and \\(c^{\\prime}=w^{\\prime}\\zeta ^{\\prime}\\).\nWe next construct the residuals in the above two equations which we will minimize. For given vectors of next-period shocks \\(\\epsilon=(\\epsilon_r,\\epsilon_\\delta,\\epsilon_q,\\epsilon_p)\\), state \\(s=(r,\\delta ,q,p,w)\\) and next-period shocks, we define: \\[\\begin{equation*}\n\\begin{matrix}\nR_1(s,\\epsilon)=\\beta \\overline{r}\\left[ \\left. \\frac{u^{\\prime }\\left(\nc^{\\prime }\\right) }{u^{\\prime }(c)}\\exp \\left( \\delta ^{\\prime }-\\delta\n+r^{\\prime }\\right) \\right\\vert \\epsilon \\right] -h,\n\\\\\nR_2(s)=FB\\left( 1-\\zeta ,1-h\\right),\n\\end{matrix}\n\\end{equation*}\\] where the transition equation is \\(w^{\\prime }=\\left( w-c\\right) \\overline{r%\n}\\exp (r)+\\exp (y)\\).\n\ndef Residuals(theta, e_r: Vector, e_p: Vector, e_q: Vector, e_δ: Vector, r: Vector,  p: Vector, q: Vector, δ: Vector,  w: Vector):\n\n    # all inputs are expected to have the same size n\n    n = r.shape[0]\n\n    # arguments correspond to the values of the states today\n    ζ, h = dr(theta, r, p, q, δ, w)\n    c = ζ*w\n\n    # transitions of the exogenous processes\n    rnext = r*ρ_r + e_r\n    pnext = p*ρ_p + e_p\n    qnext = q*ρ_q + e_q\n    δnext = δ*ρ_δ + e_δ\n\n    # (epsilon = (rnext, δnext, pnext, qnext))\n    \n    # transition of endogenous states (next denotes variables at t+1)\n    wnext = jnp.exp(pnext)*jnp.exp(qnext) + (w-c)*rbar*jnp.exp(rnext)\n\n    ζnext, hnext = dr(theta, rnext, pnext,  qnext, δnext,  wnext)\n    cnext = ζnext*wnext\n\n\n    R1 = β*jnp.exp(δnext-δ)*(cnext/c)**(-γ)*rbar*jnp.exp(rnext) - h\n    R2 = min_FB(1-h,1-ζ)\n\n    return (R1, R2)",
    "crumbs": [
      "Hands-on",
      "Deep learning solution method with all-in-one expectation operator"
    ]
  },
  {
    "objectID": "handson/qe_notebook_jax.html#the-expected-squared-sum-of-residuals",
    "href": "handson/qe_notebook_jax.html#the-expected-squared-sum-of-residuals",
    "title": "Deep learning solution method with all-in-one expectation operator",
    "section": "The expected squared sum of residuals",
    "text": "The expected squared sum of residuals\nWe construct the objective function for minimization as the squared sum of two residuals in the two model’s equations on a given 5-dimensional domain \\(s=(r,\\delta ,q,p,w)\\): \\[\\begin{equation*}\n\\Xi (\\theta )=E_{s}\\left[ \\left( E_{\\epsilon }\\left[ \\left.R_1(s,\\epsilon)\\right\\vert\n\\epsilon \\right] \\right) ^{2}+v\\left( R_2(s)\\right) ^{2}\\right] ,\n\\end{equation*}\\] where \\(v\\) is the exogenous relative weights of the two residuals in the objective function. We placed the first residual \\(R_1(s,\\epsilon)\\) under the expectation operator \\(E_{\\epsilon }\\) across next-period shocks $=( {r},{},{q},{p}) $ as is required by the definition of \\(h\\); the second residual \\(R_2(s)\\) does not include random variables\nand requires no expectation operator. The value of the objective function \\(\\Xi (\\theta )\\) depends on the coefficients $$ because these coefficients determine the choices via\n\\[\\begin{equation*}\n\\left(\n\\begin{matrix}\n\\zeta  \\\\\nh%\n\\end{matrix}%\n\\right) =\\varphi (s;\\theta ).\n\\end{equation*}\\] A shortcoming of the constructed objective function is that it requires a potentially costly evaluation of two nested expectation operators: for each random grid point \\(s=(r,\\delta ,q,p,w)\\), we need to construct a separate approximation of the expectation function $E_{}$ by considering a potentially large number of next period shocks $=( {r}, {},{q},{p}) \\(. In particular, if there are\\)n$ grid points and \\(J\\) next-period shocks, we have \\(n\\times J\\) function evaluations.",
    "crumbs": [
      "Hands-on",
      "Deep learning solution method with all-in-one expectation operator"
    ]
  },
  {
    "objectID": "handson/qe_notebook_jax.html#all-in-one-expectation-function",
    "href": "handson/qe_notebook_jax.html#all-in-one-expectation-function",
    "title": "Deep learning solution method with all-in-one expectation operator",
    "section": "All-in-one expectation function",
    "text": "All-in-one expectation function\nWe now introduce a technique which we call an all-in-one expectation operator that makes it possible to merge the two expectation operators into a single one. This technique relies on a simple result from probability theory that says that for two random variables \\(a\\) and \\(b\\), which are independent and follow the same distribution, we have \\(E[a]^{2}=E[a]E[b]=E[ab]\\).\nTherefore, we replace \\(\\left( E_{\\epsilon }\\left[ \\left. R_1(s,\\epsilon)\\right\\vert\n\\epsilon \\right] \\right) ^{2}\\) by the product of two residuals constructed by using two uncorrelated random draws \\(\\epsilon _{1}\\) and \\(\\epsilon _{2}\\), and as a result, we can pull the expectation out of squares \\[\\begin{equation*}\nE_{\\epsilon _{1}}\\left[ \\left. R_1(s,\\epsilon_1)\\right\\vert \\epsilon _{1}\\right]\nE_{\\epsilon _{2}}\\left[ \\left. R_1(s,\\epsilon_2)\\right\\vert \\epsilon _{2}\\right]\n=E_{\\epsilon _{1},\\epsilon _{2}}\\left[ \\left( \\left. R_1(s,\\epsilon_1)\\right\\vert \\epsilon\n_{1}\\right) \\left( \\left. R_1(s,\\epsilon_2)\\right\\vert \\epsilon _{2}\\right) \\right].\n\\end{equation*}\\] With that result, we can re-write the objective function as just one expectation operator: \\[\\begin{equation*}\n\\Xi (\\theta )=E_{s,\\epsilon _{1}\\epsilon _{2}}\\left[ \\underset{\\xi (\\omega\n;\\theta )}{\\underbrace{\\left[ \\left( \\left. R_{1}\\left( s,\\epsilon\n_{1}\\right) \\right\\vert \\epsilon _{1}\\right) \\left( \\left. R_{1}\\left(\ns,\\epsilon _{2}\\right) \\right\\vert \\epsilon _{2}\\right) \\right] +v\\left(\nR_{2}\\left( s\\right) \\right) ^{2}}}\\right] \\equiv E_{\\omega }\\left[ \\xi\n(\\omega ;\\theta )\\right],\n\\end{equation*}\\] where \\(\\omega =(s,\\epsilon _{1},\\epsilon _{2})\\). Therefore, we wrote the objective function of the deep learning method as a single expectation operator $E_{}$ of a function \\(%\n\\xi (\\omega ;\\theta )\\) that depends on a vector-valued random variable $% $. We approximate \\(\\Xi (\\theta )\\) by using Monte Carlo simulation: \\[\\begin{equation*}\n\\Xi (\\theta )\\approx \\Xi ^{n}(\\theta )=\\frac{1}{n}\\sum_{i=1}^{n}\\xi (\\omega\n_{i};\\theta ),\n\\end{equation*}\\] i.e., we draw \\(n\\) random draws of \\(\\omega =(s,\\epsilon _{1},\\epsilon _{2})\\) and compute the average of the objective function.\n\ndef Ξ(n, theta, key): # objective function for DL training\n\n    keys = jax.random.split(key, 13)\n\n    # randomly drawing current states\n    r = jax.random.normal(keys[0], shape=(n,))*σ_e_r\n    p = jax.random.normal(keys[1], shape=(n,))*σ_e_p\n    q = jax.random.normal(keys[2], shape=(n,))*σ_e_q\n    δ = jax.random.normal(keys[3], shape=(n,))*σ_e_δ\n\n    w = jax.random.uniform(keys[4], shape=(n,), minval=wmin, maxval=wmax)\n \n    # randomly drawing 1st realization for shocks\n    e1_r = jax.random.normal(keys[5], shape=(n,))*σ_r\n    e1_p = jax.random.normal(keys[6], shape=(n,))*σ_p\n    e1_q = jax.random.normal(keys[7], shape=(n,))*σ_q\n    e1_δ = jax.random.normal(keys[8], shape=(n,))*σ_δ\n\n    # randomly drawing 2nd realization for shocks\n    e2_r = jax.random.normal(keys[9], shape=(n,))*σ_r\n    e2_p = jax.random.normal(keys[10], shape=(n,))*σ_p\n    e2_q = jax.random.normal(keys[11], shape=(n,))*σ_q\n    e2_δ = jax.random.normal(keys[12], shape=(n,))*σ_δ\n    \n    \n    # residuals for n random grid points under 2 realizations of shocks\n    R1_e1, R2_e1 = Residuals(theta, e1_r, e1_p, e1_q, e1_δ, r, p, q, δ, w)\n    R1_e2, R2_e2 = Residuals(theta, e2_r, e2_p, e2_q, e2_δ, r, p, q, δ, w)\n\n    # construct all-in-one expectation operator\n    R_squared = R1_e1*R1_e2 + R2_e1*R2_e2 \n    \n    # compute average across n random draws\n    return jnp.mean(R_squared)\n\nSo far, we have been using JAX in the eager execution mode as if it was numpy: result of each operation is computed immediately.\n\nn = 128\nkey = jax.random.key(13)\nv = Ξ(n, theta_0, key)\nv\n\nArray(0.32632732, dtype=float32)\n\n\nNote that the intermediate results are still stored as special JAX objects (tensors) and they can be converted to a regular value easily.\n\nfloat(v)\n\n0.3263273239135742",
    "crumbs": [
      "Hands-on",
      "Deep learning solution method with all-in-one expectation operator"
    ]
  },
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "Ce_bb_2024",
    "section": "",
    "text": "JAX:\n\nexplain tracing compiler\nvectorization"
  },
  {
    "objectID": "slides/methods.html#dynamic",
    "href": "slides/methods.html#dynamic",
    "title": "Methods",
    "section": "Dynamic",
    "text": "Dynamic\nDynamic programming comes in two flavours:\n\nMarkov Discrete Problems (MDP)\n\nstates and controls take discrete values\n\nApproximate Dynamic Programming (ADP)\n\nstates and controls take continuous values\n\n\nFor ADP, objects of interest (shocks, decision rules) live in infinitely dimensional spaces.\nThey need be be quantized with a finite set of parameters.\nThis motivates the study of:\n\ninterpolation (for the decision rule)\ndiscretization (for the shocks)\n\nWe will also need optimization but we will defer it to december.",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#approximation",
    "href": "slides/methods.html#approximation",
    "title": "Methods",
    "section": "Approximation",
    "text": "Approximation\nDefine two continuous sets \\(X\\in R^p\\), \\(Y \\in R^q\\).\nTake a dataset: \\((x_i, y_i)_{i\\in[1,N]} \\in X \\times Y\\)\n \nTake \\(\\tilde{x} \\in X \\setminus \\{x_i\\}_{i\\in[1,N]}\\). What should be the matching \\(\\tilde{y}\\) ?\n \nApproximation method:\n\nDiscover implicit relation \\(y=f^t(x)\\) (the model) then compute \\(\\tilde{y}=f^t (\\tilde{x})\\).\n\nConcretely we choose \\(f\\) from a family \\(\\mathcal{F}\\) of functions parameterized by a parameter \\(\\theta\\), the approximation family.\n\nwe approximate the true \\(f^t(x)\\) by some \\(f(x;\\theta)\\)",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#interpolation-vs.-regression",
    "href": "slides/methods.html#interpolation-vs.-regression",
    "title": "Methods",
    "section": "Interpolation vs. Regression",
    "text": "Interpolation vs. Regression\n\nInterpolation: \\(f\\) is chosen such that \\(\\forall n, y_n=f(x_n)\\) \nRegression: \\(f\\) is chosen so as to minimize a fitness criterium such as\n\n\\(\\min_f \\sum_n \\left( y_n-f(x_n) \\right)^2\\)\nor \\(\\min_{\\theta} \\sum_n \\left( y_n-f(x_n;\\theta) \\right)^2 + \\lambda  || \\theta ||^2\\) with \\(\\lambda&gt;0\\)\n\n\n \n\nConfusing remarks:\n\nsometimes one differentiate interpolation (when \\(\\tilde{ x}\\)) is in the convex hull of \\(X\\) and extrapolation (when \\(\\tilde{x}\\) is outside)\nsome applied mathematicians tend interpolation for everything(i.e. interpolate=evaluate f outside of X)",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#examples-1-linear-interpolation",
    "href": "slides/methods.html#examples-1-linear-interpolation",
    "title": "Methods",
    "section": "Examples (1): Linear Interpolation",
    "text": "Examples (1): Linear Interpolation\n1d Graph. Join the dots. Linear/Spline\n2d Graph: Regression\nConclusion: interpolate only if \\(f\\) is known precisely on \\(X\\)",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#example-2",
    "href": "slides/methods.html#example-2",
    "title": "Methods",
    "section": "Example (2)",
    "text": "Example (2)\n\n\n\\(X\\) and \\(Y\\): large databases of low and high resolutions images\n\\(\\mathcal{F}\\): neural network",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#why-do-we-need-it",
    "href": "slides/methods.html#why-do-we-need-it",
    "title": "Methods",
    "section": "Why do we need it?",
    "text": "Why do we need it?\n\nIn economics, we often solve a problem \\(\\Phi(f)=0\\) where \\(f\\) is a function: \\(\\forall s, \\Phi(f)(s) = 0\\)\nIf we approximate \\(f\\) by some element \\(f(;\\theta)\\in\\mathcal{F}\\) we just need to identify a finite set of parameters \\(\\theta \\in R^n\\)\nHow do we identify \\(\\theta\\)?\n\nchoose a finite set of \\(n\\) criteria that must be met\n\n\\(f\\) is pinned down uniquely\nexample: colocation, choose \\(s_1, ..., s_n\\). Find \\(f\\) such that \\(\\forall i=1:n, \\Phi(f)(s_i) = 0\\)\n\nchoose higher number of objectives (\\(p&gt;n\\)) that must be minimized:\n\nexample: regression, choose \\(s_1, ..., s_p\\). Find \\(f\\) such that minimize \\(\\sum_i \\Phi(f)(s_i)^2 = 0\\)",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#several-interpolation-flavours",
    "href": "slides/methods.html#several-interpolation-flavours",
    "title": "Methods",
    "section": "Several interpolation flavours",
    "text": "Several interpolation flavours\n\nlocal vs spectral:\n\nlocal: functions in \\(f\\) have compact support\nspectral: noncompact support\n\nlinear vs nonlinear:\n\n\\(\\mathcal{F}\\) is a vector space: \\(f(x) \\approx \\sum_{i=1}^N \\theta_n b_n(x)\\) where \\(b_n\\) is a base of \\(\\mathcal{F}\\)\nnonlinear: wavelets, neural networks, ….",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#linear-splines",
    "href": "slides/methods.html#linear-splines",
    "title": "Methods",
    "section": "Linear Splines",
    "text": "Linear Splines\n\nTake function \\(f\\) defined on an interval \\([a,b]\\). Suppose the value is known at \\((a=x_1, ... x_N=b)\\). Denote \\(y_i = f(x_i)\\).\nJoin the dots: define a piecewise linear function as \\[\\forall x \\in [x_i, x_{i+1}], \\tilde{f}(x) = y_i + \\underbrace{\\frac{x-x_i}{x_{i+1}-x_i}}_{\\text{barycentric coordinate}} (y_{i+1} - y_i)\\]",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#linear-splines-1",
    "href": "slides/methods.html#linear-splines-1",
    "title": "Methods",
    "section": "Linear Splines",
    "text": "Linear Splines\n\nAlternate view: \\[\\tilde{f}(x) = \\sum_{i=1}^N y_i B^i_1(x)\\] where \\(b_1^i(x)=\\frac{x-x_{i-1}}{x_i-x_{i-1}}.1_{x\\in[x_{i-1},x_i]} + (1-\\frac{x-x_{i}}{x_{i+1}-x_{i}}).1_{x\\in [x_i, x_{i+1}]}\\)\n\\((B^i)\\) is an interpolation basis",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#splines",
    "href": "slides/methods.html#splines",
    "title": "Methods",
    "section": "Splines",
    "text": "Splines\n\n\\(n\\)-th order spline : piecewise polynomial function that is \\(n\\) times differentiable except on a finite set of break points (aka knots), where it is \\((n-1)\\) times differentiable.\nin practice the data points are the breakpoints\nexample: order 2\n\nsuppose \\(\\tilde{f}(x_i)\\) and \\(\\tilde{f}^{\\prime}(x_i)\\) are known, choose the coefficients for the patch \\(p_{i+1}(x) = a_{i+1}x^2+b_{i+1}x + c_{i+1}\\)\nAlready two constraints. Condition \\(p_{i+1}(x_{i+1})=\\tilde{f}(x_{i+1})\\) supplies another one.\nDo it for every patch. Note that it requires to set \\(f^{\\prime}(a)\\) beforehand.",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#basis-splines-much-better",
    "href": "slides/methods.html#basis-splines-much-better",
    "title": "Methods",
    "section": "Basis Splines (much better)",
    "text": "Basis Splines (much better)\n\nDefine \\[B_{i,1}(x) = 1_{x \\in [x_i, x_{i+1}]}\\] \\[B_{i,k+1}(x) = \\frac{x-x_i}{x_{i+k}-x_i}B_{i,k}(x) + \\frac{x_{i+k+1}-x}{x_{i+k+1}-x_{i+1}}B_{i+1,k}(x)\\]\nProperties:\n\nAll basis splines have compact support.\nIf grid is regularly spaced there is \\(B_k\\) such that \\(B_{i,k}(x) = B_k(x-x_i)\\)\n\nTheorem (de Boor): Any spline of order \\(k\\) on the knots \\((x_i)\\) can be expressed as a linear combination of the basis splines \\((B_{i,k})\\).",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#basis-splines",
    "href": "slides/methods.html#basis-splines",
    "title": "Methods",
    "section": "Basis splines",
    "text": "Basis splines\n\nBasis Splines",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#basis-splines-are-not-interpolating",
    "href": "slides/methods.html#basis-splines-are-not-interpolating",
    "title": "Methods",
    "section": "Basis splines are not interpolating",
    "text": "Basis splines are not interpolating\n\nUnfortunately basis splines are not “interpolating” in the sense that in general \\[f(x_i) \\neq \\sum_{n} f(x_n) B_{n,k} (x_i)\\]\nOne must choose other coefficients \\((c_n)\\) which satisfy:\n\\[y_i = \\sum_n c_n B_{n,k} (x_i)\\]\n\nthere are more coefficients than data points:\n\nrequires boundary conditions\n\n\\(f''=0\\): natural spline\n\ngoing from \\(y_n\\) to \\(c_n\\) is called prefiltering",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#in-practice-interpolations",
    "href": "slides/methods.html#in-practice-interpolations",
    "title": "Methods",
    "section": "In practice: Interpolations",
    "text": "In practice: Interpolations\nimport numpy as np\nfrom scipy.interpolate import RegularGridInterpolator\nf = lambda x: np.log(x)\nxs = np.linspace(1, 5, 10)\nA = f(xs)\n\n# linear interpolation\ninterp_linear = RegularGridInterpolator((xs,), A)\ninterp_linear([1.3]) # interpolate\n\n# cubic spline interpolation\ninterp_cubic = RegularGridInterpolator((xs,), A, method=\"cubic\")\ninterp_cubic([1.3]) # interpolate",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#mental-break-matrix-conditioning",
    "href": "slides/methods.html#mental-break-matrix-conditioning",
    "title": "Methods",
    "section": "Mental break: matrix conditioning",
    "text": "Mental break: matrix conditioning\n\nSuppose you want to solve vector equation \\(A x=y\\). Will a small error in \\(y\\) affect a lot the value of \\(x\\)? (in particular round-off errors)\n\ncondition number: \\(\\lim_{\\epsilon\\rightarrow 0} \\sup_{\\delta y\\leq \\epsilon} \\frac{\\delta x}{\\delta y}\\)\nor \\(\\kappa(A) = ||A^{-1}|| || A||\\) where \\(||. ||\\) is a subordonate norm.\nif very-large: the matrix is ill conditioned\n\nWhat makes a matrix ill-conditioned?\n\nsome rows/columns are very small, others are gigantic\nrows/columns are almost colinear",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#polynomial-approximation",
    "href": "slides/methods.html#polynomial-approximation",
    "title": "Methods",
    "section": "Polynomial approximation",
    "text": "Polynomial approximation",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#fitting-polynomials",
    "href": "slides/methods.html#fitting-polynomials",
    "title": "Methods",
    "section": "Fitting polynomials",
    "text": "Fitting polynomials\n\nLet’s approximate: \\(f(;\\theta) = \\sum_{n=0}^K \\theta_k x^k\\).\nWe need \\((K+1)\\) points to fit a polynomial of order \\(K\\). Let’s take grid points \\((x_0, ... x_{K})\\) and denote \\(y_k=f(x_k)\\)\nWe need to solve in \\((\\theta_k)_{k=[0,K]}\\):\n\n\\[\\forall n \\in[0,K],  \\underbrace{\\sum_k \\theta_k (x_n)^{k}}_{M \\theta} = y_k\\]",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#vandermonde-matrix",
    "href": "slides/methods.html#vandermonde-matrix",
    "title": "Methods",
    "section": "Vandermonde Matrix",
    "text": "Vandermonde Matrix\n\n\\(M\\) has a special structure, a Vandermode matrix: \\[\nM =\n\\begin{bmatrix}\n1 & x_0 & x_0^2 \\cdots & x_0^K \\\\\\\\\n1 & x_1 & x_1^2  \\cdots  & x_1^K \\\\\\\\\n1 & x_2 & x_2^2  \\cdots  & x_2^K \\\\\\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\\\\\n1 & x_K & x_K^2  \\cdots & x_K^K\n\\end{bmatrix}\n\\]\nVandermonde matrix is ill-conditioned if points are too close or if \\(K\\) is high.",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#orthogonal-polynomials",
    "href": "slides/methods.html#orthogonal-polynomials",
    "title": "Methods",
    "section": "Orthogonal polynomials",
    "text": "Orthogonal polynomials\n\nDefine a scalar product over functions on the domain \\([a,b]\\) by choosing a positive weight function \\(w(x)\\). \\[&lt;P,Q&gt; = \\int_a^b w(x) P(x)Q(x) dx\\]\nConstruct an orthogonal base \\((T_n)_{n=[1,K]}\\).\nApproximate \\[f(x)\\approx f(x; \\theta) = \\sum_{n=0}^K \\theta_n T_n(x)=\\sum_{n=0}^K &lt;f|T_n&gt; T_n(x)\\]\n\nthis is optimal for the norm associated to \\(&lt;&gt;\\) (projection on the orthogonal base)",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#vandermonde-matrix-1",
    "href": "slides/methods.html#vandermonde-matrix-1",
    "title": "Methods",
    "section": "Vandermonde matrix",
    "text": "Vandermonde matrix\nCoefficients can still be identified by inverting: \\[\\forall n \\in[0,K] \\underbrace{\\sum_k \\theta_k T_k(x_n)}_{M \\theta} = y_n\\]\n\\[\nM =\n\\begin{bmatrix}\nT_0(x_0) & T_1(x_0) & \\cdots & T_K(x_0) \\\\\\\\\nT_0(x_1) & T_1(x_1) &  \\cdots  & T_K(x_1) \\\\\\\\\nT_0(x_2) & T_1(x_2) &  \\cdots  & T_K(x_2) \\\\\\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nT_0(x_K) & T_1(x_K) &  \\cdots & T_K(x_K)\n\\end{bmatrix}\n\\]",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#problem-runge-error",
    "href": "slides/methods.html#problem-runge-error",
    "title": "Methods",
    "section": "Problem: Runge error",
    "text": "Problem: Runge error\n\n\n\nRed: Runge function \\(f(x)=\\frac{1}{1+25x^2}\\)\nBlue: interpolates at 6, regularly-spaced, points\nGreen: interpolates at 10, regularly-spaced, points\nWhat happens when interpolation order increases?\n\noscillations increase.\n\nDoes it contradict Stone-Weierstrass theorem ? No.\nSolutions:\n\nuse regression method instead\nchoose the interpolation points wisely",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#chebychev-nodes",
    "href": "slides/methods.html#chebychev-nodes",
    "title": "Methods",
    "section": "Chebychev Nodes",
    "text": "Chebychev Nodes\n\nThere is an optimal way to choose the interpolation points:\n\nthe roots of \\(cos(\\frac{2 k - 1}{2n} \\pi)\\) for [-1,1]\nrescale for a finite interval [a,b]\n\nfor the interpolating polynomial: \\[|f(x) - P_n(x)|  \\leq \\frac{1}{2^n (n+1)!} \\max_{\\xi \\in [-1,1]} |f^n(\\xi)|\\]",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#chebychev-polynomials",
    "href": "slides/methods.html#chebychev-polynomials",
    "title": "Methods",
    "section": "Chebychev polynomials",
    "text": "Chebychev polynomials\n\nChebychev polynomials (of the first kind) have their zeros on the nodes.\nDefinitions:\n\n\\(T_n(x) = \\cos(n  \\arccos(x))\\) (in [0,1])\nrecursive: \\(T_0(x)=1\\), \\(T_1(x)=x\\), \\(T_n(x)=2 x T_{n-1}(x)-T_{n-2}(x)\\)\n\nVery good choice:\n\nmatrix \\(M\\) is well conditioned: \\(\\sqrt{2}\\)",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#chebychev-polynomial",
    "href": "slides/methods.html#chebychev-polynomial",
    "title": "Methods",
    "section": "Chebychev Polynomial",
    "text": "Chebychev Polynomial",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#multidimensional-interpolation",
    "href": "slides/methods.html#multidimensional-interpolation",
    "title": "Methods",
    "section": "Multidimensional interpolation",
    "text": "Multidimensional interpolation\n\nConsider a function \\(f\\) defined on a space \\(X_1 \\times X_d\\)\nTake \\(d\\) grids \\(\\mathcal{G}_1\\subset X_1, ..., \\mathcal{G}_d\\subset X_d\\) with linear approximation bases \\(\\mathcal{B}_1=(b_1^1, ... b_1^{N_1}),..., \\mathcal{B}_d=(b_d^1, ... b_d^{N_d})\\).\nThen \\(f\\) can be approximated by \\(f(x_1, ... x_d ; \\theta) = \\sum_{i_1=1}^{N_1} ... \\sum_{i_d=1}^{N_d} \\theta_{i_1, ... i_d} \\underbrace{b_{i_1}^1(x_1) ...  b_{i_d}^d(x_d)}_{\\text{Product Base}}\\)\nMorality:\n\nlinear appoximation along each dimension induces a natural (multi)-linear in many dimensions\nCoefficients are still the solution of a linear system: \\[M \\theta = y\\]\nbut \\(M\\) has a special structure (tensor product)\n\nProblem: number of coefficients to determine increases exponentially with number of dimensions:\n\n“Curse of Dimensionality”",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#multidimensional-interpolation-2",
    "href": "slides/methods.html#multidimensional-interpolation-2",
    "title": "Methods",
    "section": "Multidimensional interpolation (2)",
    "text": "Multidimensional interpolation (2)\n\nWays to mitigate the curse of dimensionality\nRemedies:\n\nsparse grids\nadaptive approximation\n\ndelaunay tessellation\nadaptive sparse grid\n\nneural networks\n…\n\nNo black-magic theorem: there is no solution to the curse of dimensionality\n\n.. but there are methods to adapt to problem whose intrinsic dimension is smaller than the actual number of variables",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#delaunay-and-sparse-grid",
    "href": "slides/methods.html#delaunay-and-sparse-grid",
    "title": "Methods",
    "section": "Delaunay and sparse grid",
    "text": "Delaunay and sparse grid\n\n\n\n\n\nDelaunay Tessellation\n\n\n\n\n\n\nSparse Grid",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#python-libraries",
    "href": "slides/methods.html#python-libraries",
    "title": "Methods",
    "section": "Python libraries",
    "text": "Python libraries\n\nscipy.interpolation many common methods\ninterpolation.py\n\nlinear and cubic splines\njitted with numba\nalso complete and smolyak polynomials",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#several-kinds-of-discretization",
    "href": "slides/methods.html#several-kinds-of-discretization",
    "title": "Methods",
    "section": "Several kinds of Discretization",
    "text": "Several kinds of Discretization\n\napproximate operator with a finite number of iterations:\n\ncompute \\(\\int_a^b f(x) dx\\)\ncompute \\(E_\\omega f(\\omega)\\)\n\nrepresent an infinite dimensional object with a finite set of parameters:\n\n\\(f \\equiv (f(x_i))_{i=1:N}\\) with \\(x_i=a+\\frac{i-1}{N-1}(b-a)\\)\n\ndiscretize arguments\n\n\\(\\omega \\equiv (\\mu_i, \\omega_i)_{i=1:N}\\) such that \\(E_\\omega f(\\omega) \\approx \\sum_i \\mu_i f(\\omega_i)\\) (quantization)\n\ndiscretize continous process by a discrete one:\n\ncontinuous markov chain to discrete markov Chain",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#discretizing-an-ar1",
    "href": "slides/methods.html#discretizing-an-ar1",
    "title": "Methods",
    "section": "Discretizing an AR1",
    "text": "Discretizing an AR1\n\nTake \\(AR1\\) process \\[x_t = \\rho x_{t-1} + \\epsilon_t\\]\n\nwith \\(|\\rho| &lt;1\\) and \\(\\epsilon \\sim N(0,\\sigma)\\)\n\nCan we replace \\((x_t)\\) by a discrete markov chain?\n\napproximate version:\n\ngood time \\(x^g\\) and bad time \\(x^b\\). Probability \\(\\pi\\) of staying in the same, \\(1-\\pi\\) of switching.\n\ntwo systematic methods (available in QuantEcon.py)\n\nTauchen\nRouwenhorst",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#ar1-tauchen",
    "href": "slides/methods.html#ar1-tauchen",
    "title": "Methods",
    "section": "AR1: Tauchen",
    "text": "AR1: Tauchen\n\nThe unconditional distribution of an AR1 is a normal law \\(\\mathcal{N}(0,\\frac{\\sigma}{\\sqrt{1-\\rho^2}})\\)\nChoose \\(m&gt;0\\), typically \\(m=3\\)\nBound the process: \\(\\underline{x} = -m \\frac{\\sigma}{\\sqrt{1-\\rho^2}}\\) and \\(\\overline{x} = m \\frac{\\sigma}{\\sqrt{1-\\rho^2}}\\)\nDefine the \\(N\\) discretized points (\\(i\\in[1,n]\\)): \\(y_i = \\underline{x} + \\frac{i-1}{N-1}(\\overline{x}-\\underline{x})\\)\nDefine the transitions:\n\n\\[\\pi_{ij} = prob \\left( y_{t+1}=y_j|y_t=y_i\\right)\\] \\[\\pi_{ij} = prob \\left( |y_{t+1}-x_j| = \\inf_k |y_{t+1}-x_k| \\left| y_t=y_i \\right. \\right)\\]",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#ar1-tauchen-2",
    "href": "slides/methods.html#ar1-tauchen-2",
    "title": "Methods",
    "section": "AR1: Tauchen (2)",
    "text": "AR1: Tauchen (2)\n\nFormulas \\(\\delta=\\frac{\\overline{x}-\\underline{x}}{N}\\):\n\nif \\(1&lt;k&lt;N-1\\)\n\\[\\pi_{jk} = F(\\frac{y_k + \\delta/2-\\rho y_j}{\\sigma_{\\epsilon}}) - F(y_k + \\delta/2-\\rho y_j)\\]\nif \\(k=1\\)\n\\[\\pi_{j} = F(\\frac{y_k + \\delta/2-\\rho y_j}{\\sigma_{\\epsilon}}) \\]\nif \\(k=N\\)\n\\[\\pi_{j} = 1- F(\\frac{y_k - \\delta/2-\\rho y_j}{\\sigma_{\\epsilon}}) \\]",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#how-to-assess-the-quality-of-approximation",
    "href": "slides/methods.html#how-to-assess-the-quality-of-approximation",
    "title": "Methods",
    "section": "How to assess the quality of approximation ?",
    "text": "How to assess the quality of approximation ?\n\ncompare generated stationary moments between discretized process and true AR1:\n\nE(), Var(), ACor()\n\nby looking at the exact ergodic distribution or by doing some simulations\nnot very precise when the process is very persistent \\(\\rho\\approx 1\\)",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#rouvenhorst-method-1",
    "href": "slides/methods.html#rouvenhorst-method-1",
    "title": "Methods",
    "section": "Rouvenhorst method (1)",
    "text": "Rouvenhorst method (1)\n\nN = 2\n\nchoose \\(y_1=-\\psi\\), \\(y_2=\\psi\\)\ndefine transition matrix: \\[\n\\Theta_2 = \\begin{bmatrix}\np & 1-p\\\\\n1-q & q\n\\end{bmatrix}\n\\]\nchoose \\(p\\), \\(q\\) and \\(\\psi\\) to match some moments: \\(E()\\), \\(Var()\\), \\(ACor()\\)\n\nthey can be computed analytically for AR1 and for discretized version.",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#rouvenhorst-method-2",
    "href": "slides/methods.html#rouvenhorst-method-2",
    "title": "Methods",
    "section": "Rouvenhorst method (2)",
    "text": "Rouvenhorst method (2)\n\nN &gt;2 \\[\\Theta_N =\np \\begin{bmatrix}  \n\\Theta_{N-1}  & 0\\\\\\\\\n0 & 0\n\\end{bmatrix} +\n(1-p) \\begin{bmatrix}  \n0 & \\Theta_{N-1} \\\\\\\\\n0 & 0\n\\end{bmatrix} +\n(1-q) \\begin{bmatrix}  \n0 & 0\\\\\\\\\n\\Theta_{N-1} & 0\n\\end{bmatrix} +\nq \\begin{bmatrix}  \n0 & 0\\\\\\\\\n0 & \\Theta_{N-1}\n\\end{bmatrix}\n\\]\nNormalize all lines",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#rouvenhorst-method-3",
    "href": "slides/methods.html#rouvenhorst-method-3",
    "title": "Methods",
    "section": "Rouvenhorst method (3)",
    "text": "Rouvenhorst method (3)\n\nProcedure converges to Bernouilli distribution.\nMoments can be computed in closed form:\n\n\\(E() = \\frac{(q-p)\\psi}{2-(p+q)}\\)\n\\(Var() = \\psi^2 \\left[ 1-4 s (1-s) + \\frac{4s(1-s)}{N-1}\\right]\\)\n\\(Acor()= p+q-1\\)\n\nRouwenhorst method performs better for highly correlated processes",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#discretizing-an-iid-law",
    "href": "slides/methods.html#discretizing-an-iid-law",
    "title": "Methods",
    "section": "Discretizing an iid law",
    "text": "Discretizing an iid law\n\nGiven \\(f\\), and an iid process \\(\\epsilon \\sim N(0,\\sigma^2)\\), how to approximate \\(E_{\\epsilon} f(\\epsilon)\\) ?\nIdeas:\n\ndraw lots of random \\((\\epsilon\\_n)\\_{n=1:N}\\) and compute \\[\\frac{1}{N}\\sum_{n=1}^N f(\\epsilon_n)\\]\n\naka Monte-Carlo simulations\n\ngiven a method to approximate integrals, compute \\[\\int_{u=-\\infty}^{\\infty} f(u) \\mu(u) du\\] with \\(\\mu(u)=\\frac{1}{\\sigma\\sqrt{2 \\pi}}e^{-\\frac{u^2}{2\\sigma^2}}\\)\ndiscretize (or quantize) the signal \\(\\epsilon\\) as \\((w_i, \\epsilon_i)_{i=1:N}\\) and compute:\n\n\n\\[\\frac{1}{N} \\sum_n w_n f(\\epsilon_n)\\]",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#whats-wrong-with-monte-carlo-simulations",
    "href": "slides/methods.html#whats-wrong-with-monte-carlo-simulations",
    "title": "Methods",
    "section": "What’s wrong with Monte-Carlo Simulations?",
    "text": "What’s wrong with Monte-Carlo Simulations?\n\nLet’s take an exemple:\n\nconsumption is \\(C(\\epsilon)=U(e^{\\epsilon})\\)\nwith \\({\\sigma}\\_{\\epsilon}=0.05\\) and \\(U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}\\) and \\(\\gamma=40\\).\n\nLet’s compute \\(E_{\\epsilon}(C(\\epsilon))\\) precisely.\nDiscuss value of \\(\\gamma\\): is it crazy? (risk return)",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#whats-wrong-with-monte-carlo-simulations-1",
    "href": "slides/methods.html#whats-wrong-with-monte-carlo-simulations-1",
    "title": "Methods",
    "section": "What’s wrong with Monte-Carlo Simulations?",
    "text": "What’s wrong with Monte-Carlo Simulations?\nCompute expectation\nσ = 0.05; γ = 40\n\nfrom math import exp\nimport numpy as np\nfrom numpy.random import normal\nfrom matplotlib import pyplot as plt\n\nU = lambda x: (x**(-γ))/(-γ)\nC = lambda e: U(exp(e))\n\ndef E_ϵ(f, N=100):\n\n    gen = (f(normal()*σ) for e in range(N))\n    return sum(gen)/N\n\nNVec = [1000, 5000, 10000, 15000, 20000]\nvals = [E_ϵ(C, N=i) for i in NVec]",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#whats-wrong-with-monte-carlo-simulations-2",
    "href": "slides/methods.html#whats-wrong-with-monte-carlo-simulations-2",
    "title": "Methods",
    "section": "What’s wrong with Monte-Carlo Simulations?",
    "text": "What’s wrong with Monte-Carlo Simulations?\ndef stdev(f, N=100, K=100): \n    gen = (E_ε(f,N=N) for k in range(K))\n    return np.std([*gen])\n\nsdvals = [stdev(C, N=n, K=1000) for n in NVec]",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#quick-theory-1",
    "href": "slides/methods.html#quick-theory-1",
    "title": "Methods",
    "section": "Quick theory (1)",
    "text": "Quick theory (1)\n\nFact: the sum of several independent gaussian variables is a gaussian variable\nSo \\(T_N =\\frac{1}{N}\\sum_{n=1}^N \\epsilon_n\\) is gaussian variable. Its mean is 0 (unbiased). Let’s compute its variance: \\[E(T_N^2) = \\frac{1}{N^2} \\sum_{n=1}^N E\\left[ \\epsilon_n^2 \\right]\\]\nThe standard deviation is: \\[s_N = \\sigma(T_N^2) = \\frac{1}{\\sqrt{\\color{red} N}} \\sigma_{\\epsilon}\\]\nConclusion: the precision of (basic) Monte-Carlo decreases only as a square root of the number of experiments.",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#quick-theory-2",
    "href": "slides/methods.html#quick-theory-2",
    "title": "Methods",
    "section": "Quick theory (2)",
    "text": "Quick theory (2)\n\nIn the general case, the Monte-Carlo estimator is: \\[T^{MC}_N =\\frac{1}{N}\\sum_{n=1}^N f(\\epsilon_n)\\]\nIt is unbiased: \\[E(T_N^{MC}) = E\\left[f(\\epsilon) \\right]\\]\nIt’s variance is \\[E(T_N^{MC}) \\propto \\frac{1}{\\sqrt{N}}\\]\n\nslow\non the plus side: rate independent of the dimension of \\(\\epsilon\\)",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#quantization-using-quantiles",
    "href": "slides/methods.html#quantization-using-quantiles",
    "title": "Methods",
    "section": "Quantization using quantiles",
    "text": "Quantization using quantiles\n\nEquiprobable discretization\nWorks for any distribution with pdf and cdf\nSplit the space into equal \\(N\\) quantiles: \\[(I_i=[a_i,a_{i+1}])_{i=1:N}\\] such that \\[prob(\\epsilon \\in I_i)=\\frac{1}{N}\\]\nChoose the nodes as the median of each interval: \\[prob(\\epsilon\\in[a_i,x_i]) = prob(\\epsilon\\in[x_i,a_{i+1}])\\]\nThe quantization is \\((1/N, x_i)_{i=1:N}\\)",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#quadrature-rule",
    "href": "slides/methods.html#quadrature-rule",
    "title": "Methods",
    "section": "Quadrature rule",
    "text": "Quadrature rule\nIdea:\n\n\\(f\\in \\mathcal{F}\\) a Banach space\n\n\\(I: f\\rightarrow E_{\\epsilon} f(\\epsilon)\\) is a linear application\n\nsuppose there is a dense family of polynomials \\(P_n\\), spanning \\(\\mathcal{F}_n\\)\n\n\\(I\\) restricted to \\(\\mathcal{F}_N\\) is a \\(N\\)-dimensional linear form\n\ntake \\(N\\) points \\((a_n)_{n\\in[1,N]}\\). The set \\(\\{f\\rightarrow\\sum_{n=1}^N w_n f(a_n) | w_1, ... w_N\\}\\) is a vectorial space.\n\none element matches exactly \\(\\left.I\\right|_{\\mathcal{F}}\\)\n\nso the quadrature rule \\((w_n, a_n)\\) is exactly accurate for polynomials of order \\(n&lt;N\\).\n\nhow to choose the points \\(a_n\\)?",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#gauss-hermite",
    "href": "slides/methods.html#gauss-hermite",
    "title": "Methods",
    "section": "Gauss-Hermite",
    "text": "Gauss-Hermite\n\n\\(f\\in \\mathcal{F}\\) a Banach space (or \\(\\mathbb{R}^n\\)), \\(\\epsilon\\) a gaussian variable\n\n\\(I: f\\rightarrow E_{\\epsilon} f(\\epsilon)\\) is a linear application\n\nsuppose there is a dense family of polynomials \\(P_n\\), spanning \\(\\mathcal{F}_n\\)\n\n\\(I\\) restricted to \\(\\mathcal{F}_N\\) is a \\(N\\)-dimensional linear form\n\nGauss quadrature magic\n\na way to choose \\(\\epsilon_i\\) and \\(w_i\\) such that \\[\\left(f\\rightarrow\\sum_{n=1}^N w_n f(\\epsilon_i) \\right)= \\left.I\\right|_{\\mathcal{F}_{2N}}\\]",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#gauss-hermite-1",
    "href": "slides/methods.html#gauss-hermite-1",
    "title": "Methods",
    "section": "Gauss-Hermite",
    "text": "Gauss-Hermite\n\nVery accurate if a function can be approximated by polynomials\nBad:\n\nimprecise if function \\(f\\) has kinks or non local behaviour\n\npoints \\(\\epsilon_n\\) can be very far from the origin\n\nnot super easy to compute weights and nodes (but there are good libraries)",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#gauss-",
    "href": "slides/methods.html#gauss-",
    "title": "Methods",
    "section": "Gauss-*",
    "text": "Gauss-*\n\nSame logic can be applied to compute integration with weight function \\(w(x)\\): \\[\\int_a^b f(x) w(x)\\]\nGauss-Hermite:\n\n\\(w(x) = \\frac{e^{-x^2}}{2}\\), \\([a,b] = [-\\infty, \\infty]\\)\n\nGauss-Legendre:\n\n\\(w(x) = 1\\)\n\nGauss-Chebychev:\n\n\\(w(x)=\\sqrt{1-x^2}\\), \\([a,b] = [-1, 1]\\)\nfor periodic functions",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/methods.html#in-practice",
    "href": "slides/methods.html#in-practice",
    "title": "Methods",
    "section": "In practice",
    "text": "In practice\nBeware that weight is not the density of the normal law:\n\\[\\frac{1}{\\sqrt{2 \\pi \\sigma^2}}\\int f(x) e^{-\\frac{x^2}{2\\sigma^2}}dx = {\\frac{1}{\\sqrt{2 \\pi}}}\\int f(u {\\sigma}) e^{-\\frac{u^2}{2}}du \\] \\[{\\frac{1}{\\sqrt{2\\pi}}}\\sum_n w_n f(\\epsilon_n {\\sigma })\\]\nx, w = polynomial.hermite_e.hermegauss(8)\nx = x*σ # renormalize nodes\ns = sum( w_*U(exp(x_)) for (x_,w_) in zip(x,w))/sqrt(pi)/sqrt(2)\nprint(s)",
    "crumbs": [
      "Slides",
      "Methods"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#clarifications",
    "href": "slides/deeplearning.html#clarifications",
    "title": "Introduction to deeplearning",
    "section": "Clarifications:",
    "text": "Clarifications:\n\nneural networks and neurons in our brains are two distinct concepts\nbrains do things in different ways (e.g. long range connections)\nNN are fast and their organization is not always inspired by the brain",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#the-perceptron",
    "href": "slides/deeplearning.html#the-perceptron",
    "title": "Introduction to deeplearning",
    "section": "The Perceptron",
    "text": "The Perceptron\nFirst neural neuron, the perception, invented by a psychologist, Dr Rosenblatt (1952):",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#modern-neural-model",
    "href": "slides/deeplearning.html#modern-neural-model",
    "title": "Introduction to deeplearning",
    "section": "Modern neural model",
    "text": "Modern neural model\nEvolution of the model:\n\narbitrary activation function \\(f\\)",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#activation-functions",
    "href": "slides/deeplearning.html#activation-functions",
    "title": "Introduction to deeplearning",
    "section": "Activation functions",
    "text": "Activation functions\n\nheavyside function: \\(h(x)=1_{x \\geq 0}\\)\nsigmoid (logistic): \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\)\n\ncool fact: \\(\\sigma^\\prime(x)=\\sigma(x)(1-\\sigma(x))\\)\n\narctan\nrelu: \\(r(x)=x*1_{x \\geq 0}\\)\nleaky relu: \\(r(x)=\\kappa x 1_{x &lt; 0} + 1_{x \\geq 0}\\)",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#activation-functions-1",
    "href": "slides/deeplearning.html#activation-functions-1",
    "title": "Introduction to deeplearning",
    "section": "Activation functions",
    "text": "Activation functions",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#topologies-feed-forward-1",
    "href": "slides/deeplearning.html#topologies-feed-forward-1",
    "title": "Introduction to deeplearning",
    "section": "Topologies (feed forward 1)",
    "text": "Topologies (feed forward 1)\n\nMultilayer perceptron:\n\\[A_0(\\tau_1 (A_1 \\tau_2 (A_2 (.... ) + B_2)) )+ B_1\\]\n\nwhere the \\(\\tau_i\\) are activation functions, A the weights, B the biases.",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#topologies-feed-forward-2",
    "href": "slides/deeplearning.html#topologies-feed-forward-2",
    "title": "Introduction to deeplearning",
    "section": "Topologies (feed forward 2)",
    "text": "Topologies (feed forward 2)\n\nConvolutional networks:\n\nrecognize/classify images\nused for features extraction in other algos\n\nEncoder",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#topologies-others",
    "href": "slides/deeplearning.html#topologies-others",
    "title": "Introduction to deeplearning",
    "section": "Topologies (others)",
    "text": "Topologies (others)\n\nRecurrent neural network\n\nhave a memory\nuseful for sequential data (speech, text)",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#training-a-neural-network",
    "href": "slides/deeplearning.html#training-a-neural-network",
    "title": "Introduction to deeplearning",
    "section": "Training a neural network",
    "text": "Training a neural network\nOverall a neural network is a (very) nonlinear approximation function \\(f(x; \\theta)\\) which depends on a lot of deep parameters \\(\\theta\\).\nThey can be trained to perform a specific objective. For instance to fit some data \\((x_n,y_n)\\)\n\\[\\min_{\\theta} \\sum_i (f(x_i, \\theta) - y_i)^2\\]\nMore accurately if we have access to a random subset \\(\\epsilon\\in \\cal{D}\\) of the data (or the generating process), we want to perform\n\\[\\min_{\\theta} \\Xi(\\theta) = \\min_{\\theta} E_{\\epsilon} \\underbrace{\\sum_{(x_i,y_i)\\in D} (f(x_i, \\theta) - y_i)^2}_{\\xi(\\epsilon, \\theta)}\\]\n\\(\\xi(\\theta)\\) is called “empirical risk”, while \\(\\Xi(\\theta)\\) is called “theoretical risk”.\nThis is can be done for regression or classification tasks. Check tensor playground",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#why-does-it-work-now",
    "href": "slides/deeplearning.html#why-does-it-work-now",
    "title": "Introduction to deeplearning",
    "section": "Why does it work now?",
    "text": "Why does it work now?\n\ncomputational neural networks have been around for a while\n\nperceptron 1952\npopular in the 80s, less so in th 90s\nall the rage again (with deeper networks)\n\na new technological stack\n\nvectorization and parallel computing\n\nGPUS (1920 cores on gtx 1070!)\n\ncloud computing\nsoftware stack:\n\ngit, linux\ntheano, tensorflow, pytorch, jax…",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#optimization",
    "href": "slides/deeplearning.html#optimization",
    "title": "Introduction to deeplearning",
    "section": "Optimization",
    "text": "Optimization\nHow do we optimize the function \\(\\Xi(\\theta)\\) ?",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#gradient-descent",
    "href": "slides/deeplearning.html#gradient-descent",
    "title": "Introduction to deeplearning",
    "section": "Gradient descent",
    "text": "Gradient descent\nConsider the scalar function \\(\\Xi(\\theta)\\) where \\(\\theta\\) is a vector. How do we optimize it?\n\nDenote the gradient of the objective by:\n\\[\\nabla_{\\theta}=   \\begin{bmatrix} \\frac{\\partial}{\\partial \\theta_1} \\\\\\\\...\\\\\\\\\\frac{\\partial}{\\partial \\theta_n} \\end{bmatrix}\\]\nGradient descent: follow to steepest slope, apply a learning rate \\(\\gamma\\).\n\\[\\theta \\leftarrow \\theta - \\gamma \\nabla_{\\theta}\\Xi(\\theta)\\]",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#variants-of-gradient-descent",
    "href": "slides/deeplearning.html#variants-of-gradient-descent",
    "title": "Introduction to deeplearning",
    "section": "Variants of Gradient Descent",
    "text": "Variants of Gradient Descent\n\nMomentum: (ball goes down the hill, \\(\\gamma\\) is air-resistence)\n\\[v_t = \\gamma v_{t-1} + \\eta \\nabla_{\\theta} J(\\theta)\\] \\[\\theta \\leftarrow \\theta - v_t\\]\nNesterov Momentum: (slow down before going up…)\n\\[v_t = \\gamma v_{t-1} + \\eta \\nabla_{\\theta} J\\left(\\theta-\\gamma v_{t-1}\\right)\\] \\[\\theta \\leftarrow \\theta - v_t\\]",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#variants-of-gradient-descent-2",
    "href": "slides/deeplearning.html#variants-of-gradient-descent-2",
    "title": "Introduction to deeplearning",
    "section": "Variants of Gradient Descent (2)",
    "text": "Variants of Gradient Descent (2)\n\nLearning rate annealing\n\\[\\eta_t = \\eta_0 / ({1+\\kappa t})\\]\nParameter specific updates (ADAM)\n\\[m_t = \\beta_1 m_{t-1} + (1-\\beta_1) g_t\\] \\[v_t = \\beta_2  v_{t-1} + (1-\\beta_2) g_t^2\\]\n\\[\\theta_{t+1} \\leftarrow \\theta_t-\\frac{\\eta}{\\sqrt{\\frac{v_t}{1-\\beta_2^t}+\\epsilon}}\\frac{m_t}{1-\\beta_1^t}\\]\nsee AdaGrad, AdaMax, Rmsprop",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#problem-1-overshooting",
    "href": "slides/deeplearning.html#problem-1-overshooting",
    "title": "Introduction to deeplearning",
    "section": "Problem 1: overshooting",
    "text": "Problem 1: overshooting",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#problem-2-saddle-points",
    "href": "slides/deeplearning.html#problem-2-saddle-points",
    "title": "Introduction to deeplearning",
    "section": "Problem 2: saddle points",
    "text": "Problem 2: saddle points",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#problem-3-function-is-not-smooth",
    "href": "slides/deeplearning.html#problem-3-function-is-not-smooth",
    "title": "Introduction to deeplearning",
    "section": "Problem 3: function is not smooth",
    "text": "Problem 3: function is not smooth",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#stochastic-gradient-descent",
    "href": "slides/deeplearning.html#stochastic-gradient-descent",
    "title": "Introduction to deeplearning",
    "section": "Stochastic gradient descent",
    "text": "Stochastic gradient descent\n\nGiven \\(\\epsilon \\sim \\mathcal{D}\\), minimize \\[\\Xi(\\theta)=E J(\\theta,\\epsilon)\\]\nIdea: draw a random \\(\\epsilon_t\\) at each step and do: \\[\\theta\\leftarrow \\theta + \\gamma \\nabla J(\\theta,\\epsilon_t)\\]\nIt works !1\n\nReason: \\(\\nabla_{\\theta}\\Xi = E\\left[ \\nabla_{\\theta} J(\\theta,\\epsilon) \\right]\\)\n\\(\\gamma\\) small, the cumulative last steps (\\(\\sum_k \\gamma^k \\nabla_{\\theta} J(\\theta_{t-k},\\epsilon_{t-k})\\) ) are close to unbiased\nlogic extends to other GD algorithms\n\n\nTheoretical results can be obtained if learning rate decreases with \\(\\gamma_n \\rightarrow 0\\) and \\(\\sum_n 1/\\gamma_n \\rightarrow \\infty\\). Typically one establish convergence “almost surely” to a local minimim in the general case or almost surely in the convex case.",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#stochastic-gradient-descent-2",
    "href": "slides/deeplearning.html#stochastic-gradient-descent-2",
    "title": "Introduction to deeplearning",
    "section": "Stochastic gradient descent (2)",
    "text": "Stochastic gradient descent (2)\n\nCan escape local minima (with annealing)\nGradient is estimated from a random mini-batch \\((\\epsilon_1, ... \\epsilon_{N_m})\\)\n\\[\\theta\\leftarrow \\theta + \\gamma \\sum_{i=1:N_m} \\nabla J(\\theta,\\epsilon^i)\\]\nCommon case: dataset set finite \\((\\epsilon_1, ..., \\epsilon_N)\\)\n\nbatch gradient: full dataset\nmini-batch gradient: random (shuffled) \\((\\epsilon_i)_{i \\in 1:N_m}\\)\nstochastic gradient: one point",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#introduction-1",
    "href": "slides/deeplearning.html#introduction-1",
    "title": "Introduction to deeplearning",
    "section": "Introduction (1)",
    "text": "Introduction (1)\n\nDeeplearning has many impressive applications\n\nreconstruct images/scenes, produce original Chopin music or BOE speeches, play Go…\n\nWorks in “you know more than you think applications”\n\nalgorithmically/mathematically complex\neasy to do by trained humans\n\nSolving a rational expectation model should be easy!\n\nright?",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#introduction-2",
    "href": "slides/deeplearning.html#introduction-2",
    "title": "Introduction to deeplearning",
    "section": "Introduction (2)",
    "text": "Introduction (2)\n\nWe offer a unified approach for casting three fundamental objects of economic dynamics -lifetime reward, Bellman equation, Euler equation- into deep learning objective function\nWe show how to solve economic models on random grids (stochastic optimization)\nWe introduce “all-in-one expectation operator” that merges all randomness into one operator\nWe use Google TensorFlow - the software that led to break-ground applications in data science; see code in https://notes.quantecon.org/submission\n\n\ntoday: I’ ll show th code with JAX ;)",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#how-can-we-solve-so-huge-models",
    "href": "slides/deeplearning.html#how-can-we-solve-so-huge-models",
    "title": "Introduction to deeplearning",
    "section": "How can we solve so huge models?",
    "text": "How can we solve so huge models?\n\nNeural network performs model reduction: It extracts information from many inputs and condenses it into a small set of hidden layers\nNeural network deals with ill conditioning: It learns to ignore redundant and collinear variables\nWe solve the high-dimensional Krusell-Smith model using stochastic simulation: We focus on the ergodic set in which the solution “lives”\nTaken together, these three features allow us to deal with a huge state space of 2,001 variables",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#method",
    "href": "slides/deeplearning.html#method",
    "title": "Introduction to deeplearning",
    "section": "Method",
    "text": "Method\n\nDefine the objective function \\(\\Xi_{n} (\\theta)=\\frac{1}{n} \\sum _{i=1}^{n} \\xi (x_{i};\\varphi ( \\cdot ;\\theta ))\\), where \\(\\{ x_{i} \\} _{i=1}^{n}\\) is the given set of features (data points).\nDefine a family of parametric functions \\(\\{ \\varphi ( \\cdot ;\\theta ) : \\theta \\in \\mathbb{R}^{d_{\\theta }}  \\}\\).\nTrain the machine, i.e., find \\(\\theta\\) that minimizes the objectives.\nCheck accuracy of the constructed approximation.\n\nWe are just left to frame the economic model as an objective for the empirical risk!",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#consumption-saving-problem-with-multiple-shocks",
    "href": "slides/deeplearning.html#consumption-saving-problem-with-multiple-shocks",
    "title": "Introduction to deeplearning",
    "section": "Consumption-saving problem with multiple shocks",
    "text": "Consumption-saving problem with multiple shocks\n\\[\\underset{ c_{t},w_{t+1} }{\\max}E_{0}[\\sum_{t=0}^{\\infty }\\beta ^{t}e^{\\color{\\red}\\chi_{\\color{\\red}t}}u( {c_{t}})]\\]\ns.t. \\(w_{t+1}=re^{\\color{\\red}\\varrho_{\\color{\\red}t}}( w_{t}-c_{t})+e^{\\color{\\red}y_{\\color{\\red}t}}e^{\\color{\\red}p_{\\color{\\red}t} }\\),\n\\(c_{t}\\leq w_{t}\\),\n\\(( z_{0},w_{0})\\) given.\n\n\\(c_{t}\\) = consumption; \\(w_{t}\\) = cash-on-hand; \\(r\\in ( 0,\\frac{1}{\\beta })\\).\neach \\(z_t\\in \\{ y_t,p_t,\\varrho_t ,\\chi_t \\}\\) follows an AR(1) process: \\(z_{t+1}=\\rho z_{t}+\\sigma\\epsilon_{t+1}\\).",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#optimality-conditions",
    "href": "slides/deeplearning.html#optimality-conditions",
    "title": "Introduction to deeplearning",
    "section": "Optimality conditions",
    "text": "Optimality conditions\n\nKuhn-Tucker conditions:\n\n\\(c-w\\leq 0\\), \\(h\\geq 0\\) and \\(( c-w) h=0\\), \\[h\\equiv u^{\\prime }(c)e^{\\chi -\\varrho }-\\beta rE[ u^{\\prime}( c^{\\prime }) e^{\\chi ^{\\prime }}] = \\text{Lagrange multiplier}\\]\n\nBellman equation:\n\n\\(V( z,w) =\\underset{c,w^{\\prime }}{\\max } \\\\\\{ u(c)+\\beta\nE_{\\epsilon }[ V( z^{\\prime },w^{\\prime }) ]  \\\\\\}\\)",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#objective-1-lifetime-reward-maximization",
    "href": "slides/deeplearning.html#objective-1-lifetime-reward-maximization",
    "title": "Introduction to deeplearning",
    "section": "Objective 1: Lifetime reward maximization",
    "text": "Objective 1: Lifetime reward maximization\n\nParameterize consumption function \\(c ( \\cdot ;\\theta )\\)\nConstruct the objective:\n\n\\[\\Xi (\\theta ) \\equiv E_{z_{0},w_{0},\\epsilon_{1},...,\\epsilon_{T} }[ \\sum_{t=0}^{T}\\beta ^{t}u( c(z_{t},w_{t};\\theta ) ) ]\\]\n\n\\(E_{z_{0},w_{0},\\epsilon_{1},...,\\epsilon_{T} }\\) has two types of randomness: a random state \\((z_{0},w_{0})\\) and random future shocks \\(\\left( \\epsilon_{1},...,\\epsilon_{T}\\right)\\)\nWe call \\(E_{ . }\\) all-in-one expectation operator: it summarizes all random variables in one place",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#objective-1-lifetime-reward-maximization-cont.",
    "href": "slides/deeplearning.html#objective-1-lifetime-reward-maximization-cont.",
    "title": "Introduction to deeplearning",
    "section": "Objective 1: Lifetime reward maximization (cont.)",
    "text": "Objective 1: Lifetime reward maximization (cont.)\n\nLifetime reward in the baseline model.",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#objective-2-euler-equation-method-with-kuhn-tucker-conditions",
    "href": "slides/deeplearning.html#objective-2-euler-equation-method-with-kuhn-tucker-conditions",
    "title": "Introduction to deeplearning",
    "section": "Objective 2: Euler-equation method with Kuhn-Tucker conditions",
    "text": "Objective 2: Euler-equation method with Kuhn-Tucker conditions\n\nFischer-Burmeister (FB) function:\n\n\\(\\Psi ^{FB}( a,b) =a+b-\\sqrt{a^{2}+b^{2}}=0\\)\nwith \\(a=c-w\\) and \\(b=u^{\\prime} (c)- \\beta re^{\\varrho_{t}}E_{\\epsilon }[ u^{\\prime }( c^{\\prime } ) ]\\)\nrepresents Kuhn-Tucker conditions \\(a\\geq 0\\), \\(b\\geq 0\\) and \\(ab=0\\) but differentiable\n\nObjective function:\n\nFor a random vector \\((z,w)\\) construct the expectation operator \\[\\Xi (\\theta ) \\equiv E_{(z,w)}[ \\Psi ^{FB}( c-w,u^{\\prime} (c)- \\beta re^{\\varrho_{t}}E_{\\epsilon }[ u^{\\prime }( c^{\\prime } ) ] ) ) ] ^{2}\\]\nNot all-in-one-expectation operator yet!",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#objective-2-euler-residual-minimization",
    "href": "slides/deeplearning.html#objective-2-euler-residual-minimization",
    "title": "Introduction to deeplearning",
    "section": "Objective 2: Euler-residual minimization",
    "text": "Objective 2: Euler-residual minimization\n\nEuler residuals in the baseline model.",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#consumption-decision-rule",
    "href": "slides/deeplearning.html#consumption-decision-rule",
    "title": "Introduction to deeplearning",
    "section": "Consumption decision rule",
    "text": "Consumption decision rule\n\nConsumption decision rule in the baseline model.",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#all-in-one-expectation-operators",
    "href": "slides/deeplearning.html#all-in-one-expectation-operators",
    "title": "Introduction to deeplearning",
    "section": "All-in-one expectation operators",
    "text": "All-in-one expectation operators\n\nIn lifetime-reward maximization,\n\n\\(E_{(z_{0},w_{0})}[ E_{( \\epsilon_{1},...,\\epsilon_{T})}u( \\cdot ) ] =E_{( z_{0},w_{0},\\epsilon_{1},...,\\epsilon_{T}) }[ u( \\cdot ) ]\\) because expectation operators are related linearly\n\nIn Euler-residual minimization, \\(E_{(z,w) }( E_{\\epsilon }[ f_{j}(z,w,\\epsilon )] )^{2}\\neq E_{(z,w)}E_{\\epsilon }[ f_{j}(z,w,\\epsilon )^{2}]\\), i.e., expectation operators cannot be naturally combined.\nAs a result, stochastic gradient is biased \\(E_{( z,w) }( E_{\\epsilon }[ \\nabla f_{j}(z,w,\\epsilon )] ) ^{2}\\neq \\nabla E_{(z,w) }( E_{\\epsilon }[ f_{j}(z,w,\\epsilon )] )^{2}\\).",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#a-little-trick",
    "href": "slides/deeplearning.html#a-little-trick",
    "title": "Introduction to deeplearning",
    "section": "A little trick",
    "text": "A little trick\n\nThere is a simple technique that allows us to combine the expectation functions \\(E_{(z,w)}[ \\cdot]\\) and \\(E_{\\epsilon }[ \\cdot ]\\) in a single expectation operator in the presence of squares.\nSpecifically, we use two independent random draws or two batches \\(\\epsilon_{1}\\) and \\(\\epsilon_{2}\\) for the two squared terms: \\[\\left(E_{ \\epsilon}[ f( \\epsilon) ]\\right)^ 2=E_{\\epsilon_{1}}[ f( \\epsilon_{1})] E_{\\epsilon_{2}}[ f( \\epsilon_{2})]=E_{( \\epsilon_{1,}\\epsilon_{2}) }[ f( \\epsilon_{1}) f(\\epsilon_{2}) ]\\]\nWith this method, the stochastic gradient descent method is unbiased.\n\n\\[E_{\\eta}[\\left(E_{ \\epsilon}[ f(\\eta, \\epsilon) ]\\right)^ 2]=E_{(\\eta, \\epsilon_{1,}\\epsilon_{2}) }[ f( \\eta, \\epsilon_{1}) f(\\eta, \\epsilon_{2}) ]\\]",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/deeplearning.html#comments-of-the-method",
    "href": "slides/deeplearning.html#comments-of-the-method",
    "title": "Introduction to deeplearning",
    "section": "Comments of the method",
    "text": "Comments of the method\n\nadvantages\n\nneural networks:\n\nflexible functional form (kinks)\nrobust to colinearity\nimplicit dimensionality reduction\n\ngeneric training method\nscales well\n\nlots of hyperparameters to be tuned:\n\nlearning method (SGD, ADAM, AdaGrad, RmsProp)\nneural network topology (activation functions, width)",
    "crumbs": [
      "Slides",
      "Introduction to deeplearning"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#introduction-1",
    "href": "slides/time_iteration.html#introduction-1",
    "title": "Time Iteration",
    "section": "Introduction",
    "text": "Introduction\nHow do we solve models? One needs to choose between several representations.\n\nbellman representation\nfirst order conditions\nother iterative schemes\n\nGoal:\n\ndefine what is the time-iteration method for first-order models\nexplain how to discretize a model and apply it in practice",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#generic-value-function-representation",
    "href": "slides/time_iteration.html#generic-value-function-representation",
    "title": "Time Iteration",
    "section": "Generic Value Function Representation",
    "text": "Generic Value Function Representation\n\nAll variables of the model are vectors:\n\nstates \\(s \\in \\mathcal{S} \\subset R^{n_s}\\)\ncontrols \\(x \\in \\mathcal{F}(\\mathcal{S}, R^{n_x})\\)\n\nwe assume bounds \\(a(s)\\leq x \\leq b(s)\\)\n\nshocks: \\(\\epsilon \\sim \\text{i.i.d. distrib}\\)\n\nTransition: \\[s_{t+1} = g(s_t, x_t, \\epsilon_{t+1})\\]\nValue function: \\[V(s) = E_0 \\sum_{t\\geq 0} \\beta^t \\left[ U(s_t, x_t)\\right]\\]\nSolution is a function \\(V()\\) (value) which is a fixed point of the Bellman-operator: \\[\\forall s, V(s) = \\max_{a(s)\\leq x \\leq b(s)} U(s,x) + \\beta E \\left[ V(g(s,x,\\epsilon)) \\right]\\]\nThe argmax, defines a decision rule function: \\(x = \\varphi(s)\\)",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#first-order-representation",
    "href": "slides/time_iteration.html#first-order-representation",
    "title": "Time Iteration",
    "section": "First order representation",
    "text": "First order representation\n\n\n\nAll variables of the model are vectors:\n\nstates \\(s_t\\)\ncontrols \\(x_t\\)\n\nwe assume bounds \\(a(s)\\leq x \\leq b(s)\\)\n\nshocks: \\(\\epsilon_t\\) (i.i.d. random law)\n\nTransition: \\[s_{t+1} = g(s_t, x_t, \\epsilon_{t+1})\\]\nDecision rule: \\[x_t = \\varphi(s_t)\\]\nArbitrage: \\[ E_t\\left[ f(s_t, x_t, s_{t+1}, x_{t+1}) \\right] = 0 \\perp a(s_t) \\leq x_t \\leq b(s_t) \\]\n\n\n\nThese equations must be true for any \\(s_t\\).\nRemark: time subscript are conventional. They are used to precise:\n\nwhen expectation is taken (w.r.t \\(\\epsilon_{t+1}\\))\nto avoid repeating \\(x_t=\\varphi(s_t)\\) and \\(x_{t+1} = \\varphi(s_t)\\)\n\nSometimes there are bounds on the controls\n\nwe encode them with complementarity constraints\nmore on it later",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#example-1-neoclassical-growth-model",
    "href": "slides/time_iteration.html#example-1-neoclassical-growth-model",
    "title": "Time Iteration",
    "section": "Example 1: neoclassical growth model",
    "text": "Example 1: neoclassical growth model\n\n\n\ncapital accumulation: \\[k_t = (1-\\delta)k_{t-1} + i_{t-1}\\]\nproduction: \\[y_t = k_t^\\alpha\\]\nconsumption: \\[c_t = (1-s_t) y_t\\] \\[i_t = s_t y_t\\]\noptimality: \\[\\beta E_t \\left[ \\frac{U^{\\prime}(c_{t+1})}{U^{\\prime}(c_{t})} (1-\\delta + \\alpha k_{t+1}^{\\alpha-1}\\alpha) \\right]= 1\\]\n\n\n\nstates: \\(k_t\\), with one transition equation\ncontrols: \\(y_t, c_t, i_t, s_t\\), with four “arbitrage” equations\n\nit is possible but not mandatory to reduce the number of variables/equations by simple susbtitutions",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#example-2-consumption-savings-model",
    "href": "slides/time_iteration.html#example-2-consumption-savings-model",
    "title": "Time Iteration",
    "section": "Example 2: consumption-savings model",
    "text": "Example 2: consumption-savings model\n\n\nSimplest consumption/savings model:\n\nTransition: \\[w_t = \\exp(\\epsilon_t) + (w_{t-1} - c_{t-1}) \\overline{r}\\]\nObjective: \\[\\max_{0\\leq c_t \\leq w_t} E_0 \\left[ \\sum \\beta^t U(c_t) \\right]\\]\nFirst order conditions: \\[\\beta E_t \\left[  \\frac{U^{\\prime}(c_{t+1})}{U^{\\prime}(c_t)} \\overline{r} \\right] - 1 \\perp 0 \\leq c_t \\leq w_t\\]\n\n\n\nF.O.C. reads as: \\[\\beta E_t \\left[  \\frac{U^{\\prime}(c_{t+1})}{U^{\\prime}(c_t)} \\overline{r} \\right] - 1 \\leq 0 \\perp c_t \\leq w_t\\] and \\[0 \\leq \\beta E_t \\left[  \\frac{U^{\\prime}(c_{t+1})}{U^{\\prime}(c_t)} \\overline{r} \\right] - 1  \\perp 0 \\leq c_t \\]\nFirst one reads: if my marginal utility of consumption today is higher than expected mg. utility of cons. tomorrow, I’d like to consume more, but I can’t because, consumption is bounded by income (and no-borrowing constraint).\nSecond one reads: only way I could tolerate higher utility in the present, than in the future, would be if I want dissave more than I can, or equivalently, consume less than zero. This is never happening.",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#example-3-new-keynesian-with-without-zlb",
    "href": "slides/time_iteration.html#example-3-new-keynesian-with-without-zlb",
    "title": "Time Iteration",
    "section": "Example 3: new-keynesian with / without ZLB",
    "text": "Example 3: new-keynesian with / without ZLB\n\n\nConsider the following new keynesian model:\n\nAssume \\(z_t\\) is an autocorrelated shock: \\[z_t = \\rho z_{t-1} + \\epsilon_t\\]\nNew philips curve (PC):\\[\\pi_t = \\beta \\mathbb{E}_t \\pi_{t+1} + \\kappa y_t\\]\ndynamic investment-saving equation (IS):\\[y_t = \\beta \\mathbb{E}_t y_{t+1} - \\frac{1}{\\sigma}(i_t - \\mathbb{E}_t(\\pi_{t+1}) ) - {\\color{green} z_t}\\]\nInterest Rate Setting (taylor rule): \\[i_t = \\alpha_{\\pi} \\pi_t + \\alpha_{y} y_t\\]\n\n\n\nThe model satisfies the same specification with:\n\none state \\(z_t\\) and one transition equation\nthree controls: \\(\\pi_t\\), \\(y_t\\) and \\(i_t\\) with three “arbitrage” equation\n\nThese are not real first order conditions as they are not derived from a maximization program\n\nunless one tries to microfound them…\n\nIt is possible to add a zero-lower bound constraint by replacing IRS with: \\[ \\alpha_{\\pi} \\pi_t + \\alpha_{y} y_t \\leq i_t \\perp 0 \\leq i_t\\]",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#time-iteration-1",
    "href": "slides/time_iteration.html#time-iteration-1",
    "title": "Time Iteration",
    "section": "Time iteration",
    "text": "Time iteration\n\nSo we have the equation, \\(\\forall s_t\\)\n\n\\[ E_t\\left[ f(s_t, x_t, s_{t+1}, x_{t+1}) \\right] = 0 \\perp a(s_t) \\leq x_t \\leq b(s_t)\\]\\[ E_t\\left[ f(s_t, x_t, s_{t+1}, x_{t+1}) \\right] = 0\\]\n\nwhere \\[s_{t+1} = g(s_t, x_t, \\epsilon_{t+1})\\] \\[x_t = \\varphi(s_t)\\] \\[x_{t+1} = \\tilde{\\varphi}(s_{t+1})\\]\nLet’s leave the complementarity conditions aside for now\nIn equilibrium \\(\\tilde{\\varphi} = {\\varphi}\\)",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#time-iteration-2",
    "href": "slides/time_iteration.html#time-iteration-2",
    "title": "Time Iteration",
    "section": "Time iteration",
    "text": "Time iteration\n\nWe can rewrite everything as one big functional equation: \\[\\forall s, \\Phi(\\varphi, \\tilde{\\varphi})(s) = E\\left[ f(s, \\varphi(s), g(s,\\varphi(s), \\epsilon), \\tilde{\\varphi}(g(s,\\varphi(s), \\epsilon)) \\right]\\]\nA solution is \\(\\varphi\\) such that \\(\\Phi(\\varphi, \\varphi) = 0\\)\nThe Coleman operator \\(\\mathcal{T}\\) is defined implicitly by: \\[\\Phi(\\mathcal{T}(\\varphi), \\varphi)=0\\]\nThe core of the time iteration algorithm, consists in the recursion: \\[\\varphi_{n+1} = \\mathcal{T}(\\varphi_n)\\]\nIt maps future decision rules to current decision rules\n\nsame as “linear time iterations”, remember?\n\nSounds fun but how do we implement it concretely?",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#practical-implementation",
    "href": "slides/time_iteration.html#practical-implementation",
    "title": "Time Iteration",
    "section": "Practical implementation",
    "text": "Practical implementation\n\nWe need to find a way to:\n\ncompute expectations\nrepresent decision rules \\(\\varphi\\) and \\(\\varphi\\) with a finite number of parameters",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#practical-implementation-2",
    "href": "slides/time_iteration.html#practical-implementation-2",
    "title": "Time Iteration",
    "section": "Practical implementation (2)",
    "text": "Practical implementation (2)\n\nComputing expectations:\n\ndiscretize shock \\(\\epsilon\\) with finite quantization \\((w_i, e_i)_{i=1:K}\\)\nreplace optimality condition with: \\[\\forall s, \\Phi(\\varphi, \\tilde{\\varphi})(s) = \\sum_i w_i f(s, \\varphi(s), g(s,\\varphi(s), e_i), \\tilde{\\varphi}(g(s,\\varphi(s), e_i)) \\]\n\n… but we still can’t compute all the \\(\\varphi\\)",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#approximating-decision-rules",
    "href": "slides/time_iteration.html#approximating-decision-rules",
    "title": "Time Iteration",
    "section": "Approximating decision rules",
    "text": "Approximating decision rules\n\nWe’ll limit ourselves to interpolating functional spaces\n\nWe define a finite grid \\(\\mathbf{s}=(s_1, ... s_N)\\) to approximate the state space (\\(\\mathbf{s}\\) is a finite vector of points)\nIf we know the vector of values \\(\\mathbf{x}=(x_1, ..., x_N)\\) a function \\(\\varphi\\) takes on \\(\\mathbf{s}\\), we approximate \\(\\varphi\\) at any \\(s\\) using an interpolation scheme \\(\\mathcal{I}\\): \\[\\varphi(s) \\approx \\mathcal{I}(s, \\mathbf{s}, \\mathbf{x})\\]\n\nNow if we replace \\(\\varphi\\) by \\(\\mathcal{I}(s, \\mathbf{s}, \\mathbf{x})\\) and \\(\\tilde{\\varphi}\\) by \\(\\mathcal{I}(s, \\mathbf{s}, \\mathbf{\\tilde{x}})\\) the functional equation becomes: \\[\\forall s,  \\Phi(\\varphi, \\tilde{\\varphi})(s) \\approx F( \\mathbf{x}, \\mathbf{\\tilde{x}} )(s) = \\sum_i w_i f(s, x, \\tilde{s}, \\tilde{x})\\] where \\[x = \\mathcal{I}(s, \\mathbf{s}, \\mathbf{x})\\] \\[\\tilde{s} = g(s, x, e_i)\\] \\[\\tilde{x} = \\mathcal{I}(s, \\mathbf{s}, \\mathbf{\\tilde{x}})\\]",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#pinning-down-decision-rules",
    "href": "slides/time_iteration.html#pinning-down-decision-rules",
    "title": "Time Iteration",
    "section": "Pinning down decision rules",
    "text": "Pinning down decision rules\n\nNote that this equation must be statisfied \\(\\forall s\\).\nIn order to pin-down the \\(N\\) coefficients \\(\\mathbf{x}\\), it is enough to satisfy the equations at \\(N\\) different points.\nHence we solve the square system: \\[\\forall i\\in [1,N], F( \\mathbf{x}, \\mathbf{\\tilde{x}} )(s_i) = 0\\]\nIn vectorized form, this is just: \\[F( \\mathbf{x}, \\mathbf{\\tilde{x}} )(\\mathbf{s}) = 0\\]\nOr, since grid \\(\\mathbf{s}\\) is fixed: \\[F( \\mathbf{x}, \\mathbf{\\tilde{x}} ) = 0\\]\nNow the vector of decisions today, at each point of the grid, is determined as a function of the vector of decisions tomorrow, on the same grid.",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#recap",
    "href": "slides/time_iteration.html#recap",
    "title": "Time Iteration",
    "section": "Recap",
    "text": "Recap\n\nChoose a finite grid for states \\(\\mathbf{s} = (s_1, ..., s_N)\\)\nFor a given vector of controls tomorrow \\(\\mathbf{\\tilde{x}}\\), one can compute theoptimality of a vector of controls today by computing the value of :\\[F( \\mathbf{x}, \\mathbf{\\tilde{x}} ) = \\sum_i w_i f(\\mathbf{s}, \\mathbf{x}, \\tilde{\\mathbf{s}}, \\tilde{\\mathbf{x}})\\] \\[\\mathbf{\\tilde{s}} = g(\\mathbf{s}, \\mathbf{x}, e_i)\\] \\[\\mathbf{\\tilde{x}} = \\mathcal{I}(\\mathbf{\\tilde{s}}; \\mathbf{s}, \\mathbf{{x}})\\]\nNote that because we use interpolating approximation: \\(\\forall i, x_i = \\mathcal{I}(s, \\mathbf{s}, \\mathbf{x})\\)\nWe have enough to define an approximated time-iteration operator: implicitly defined by \\[F(T(\\mathbf{x}), \\mathbf{x}))\\]\nWe can then implement time-iteration, but…\n\nhow do we compute \\(T(x)\\)?",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#computing-tmathbfx",
    "href": "slides/time_iteration.html#computing-tmathbfx",
    "title": "Time Iteration",
    "section": "Computing \\(T(\\mathbf{x})\\)",
    "text": "Computing \\(T(\\mathbf{x})\\)\n\nIn each step, we have a guess, for decision rule tomorrow \\(\\mathbf{\\tilde{x}}\\)\nWe can then find the decision rule today, by solving numerically for: \\(\\mathbf{x} \\mapsto  F(\\mathbf{x}, \\mathbf{\\tilde{x}})\\)\n\nusually with some variant of a Newton method\n\nIt is possible to solve for the values at each grid point separately…\n\nfor each \\(i\\), find optimal controls \\(x_i\\) in state \\(s_i\\) that satisfy \\(F(x_i, \\mathbf{\\tilde{x}}) = 0\\)\nall the problems are independent from each other\n\n…or to solve everything as a big system\n\nthe jacobian is block-diagonal: finding optimal value in state \\(i\\) or in state \\(j\\) today are two independent problems",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#time-iteration-algorithm",
    "href": "slides/time_iteration.html#time-iteration-algorithm",
    "title": "Time Iteration",
    "section": "Time iteration algorithm",
    "text": "Time iteration algorithm\n\nDiscretize state-space with grid \\(\\mathbf{s}=(s_1, ..., s_N)\\)\nChoose initial values, for the vector of controls on the grid \\(\\mathbf{x}=(x_1, ..., x_N)\\)\nSpecify tolerance levels \\(\\eta&gt;0\\) and \\(\\epsilon&gt;0\\)\nGiven an intial guess \\(\\mathbf{x_n}\\)\n\nfind the zero \\(\\mathbf{x_{n+1}}\\) of function \\(\\mathbf{u}\\mapsto F(u,\\mathbf{x_n})\\)\n\nthat is, such that controls on the grid are optimal given controls tomorrow\nnonlinear solver can use \\(\\mathbf{x_n}\\) as initial guess\n\ncompute norm \\(\\mathbf{\\eta_n} = |\\mathbf{x_n} - \\mathbf{x_{n+1}}|\\)\nif \\(\\eta_n&lt;\\eta\\), stop and return \\(\\mathbf{x_{n+1}}\\)\n\nelse, set \\(\\mathbf{x_n} \\leftarrow \\mathbf{x_{n+1}}\\) and continue\n\n\nLike usual, during the iterations, it is useful to look at \\(\\mathbf{\\epsilon_n}=|F(\\mathbf{x_n},\\mathbf{x_n})|\\) and \\(\\lambda_n = \\frac{\\eta_n}{\\eta_{n-1}}\\)",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#what-about-the-complementarities",
    "href": "slides/time_iteration.html#what-about-the-complementarities",
    "title": "Time Iteration",
    "section": "What about the complementarities ?",
    "text": "What about the complementarities ?\n\nWhen there aren’t any occasionally binding constraint, we look for the of zero \\(\\mathbf{x_{n+1}}\\) of function \\(\\mathbf{u}\\mapsto F(u,\\mathbf{x_n})\\).\nIf we define the vector of constraints on all grid points as \\(\\mathbf{a}=(a(s_1), ..., a(s_N))\\) and \\(\\mathbf{b}=(b(s_1), ..., b(s_N))\\), we can rewrite the system to solve as: \\[F(u) \\perp \\mathbf{a} \\leq u \\leq \\mathbf{b}\\]\nThen we can:\n\nfeed \\(F\\), \\(a\\) and \\(b\\) to an NCP solver (like nlsolve.jl)\nor transform this relation using Fisher-Burmeister function into a smooth nonlinear system",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#time-iteration-variants",
    "href": "slides/time_iteration.html#time-iteration-variants",
    "title": "Time Iteration",
    "section": "Time iteration variants",
    "text": "Time iteration variants\n\nYou can check out:\n\nendogenous grid points:\n\nmathematically equivalent to TI,\nmuch faster for models that have a particular structure (consumption saving models)\nno need for a nonlinear solver\n\nimproved time iterations:\n\nsame as policy iterations for value function iterations\nconvergence is equivalent to that of TI\nmuch faster but requires correct initial guess\n\nparameterized expectations\n\nrequires that all controls are determined as a function of expectations",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Computational Economics @ Bundesbank",
    "section": "",
    "text": "My email: pwinant@escp.eu\nWebsite for this course: https://www.mosphere.fr/bbank_ce_2024"
  },
  {
    "objectID": "index.html#tentative-schedule",
    "href": "index.html#tentative-schedule",
    "title": "Computational Economics @ Bundesbank",
    "section": "Tentative schedule",
    "text": "Tentative schedule\n\nIntroduction to computational economics\n\nnov 6\n\npython\n\nnov 7\ndec 5\n\nnumpy / matplotlib\nmethods: interpolation / quantization\nalgorithm: time-iteration\nexercise: solving the neoclassical model\n(introduction to dolo)\n\ndec 6\n\nintroduction to JAX (vectorization/differentiation,…)\n\nvectorize\ndraw random numbers\ncreate a loop\n\nneural networks and deeplearning\nsolving model with deeplearning\n\nlifetime_reward: simple rule for consumption savings\nsolving euler equations: AiO operator\n\nperturbation theory"
  },
  {
    "objectID": "exercises/methods.html",
    "href": "exercises/methods.html",
    "title": "Methods",
    "section": "",
    "text": "Exercise 1 Consider the function \\(f(x,y)=1-(x-x_0)^2-0.5(y-y_0)^2\\) with \\(x_0=0.5\\) and \\(y_0=1.0\\). Check the documentatin for scipy.optimize. Use it to maximze function \\(f\\).\n\n\n# one needs to define $f$ as a function of a vector\n# f(v)=1-(v[0]-x_0)^2-0.5*(v[1]-y_0)^2$ \n\n\nConsider the function \\(g(x)=0.1+exp(-x)x(1-x)\\) over [0,2]. Choose the scipy function and find the root of \\(g\\).\n\n\n#\n\n\nConsider the function \\(h(x,y)=0.1+exp(-x)x(1-x)\\) over [0,2]. Choose the scipy function and find the root of \\(g\\). to find the root of \\(g\\)?\n\n\n#",
    "crumbs": [
      "Exercises",
      "Methods"
    ]
  },
  {
    "objectID": "exercises/methods.html#optimization-and-root-finding",
    "href": "exercises/methods.html#optimization-and-root-finding",
    "title": "Methods",
    "section": "",
    "text": "Exercise 1 Consider the function \\(f(x,y)=1-(x-x_0)^2-0.5(y-y_0)^2\\) with \\(x_0=0.5\\) and \\(y_0=1.0\\). Check the documentatin for scipy.optimize. Use it to maximze function \\(f\\).\n\n\n# one needs to define $f$ as a function of a vector\n# f(v)=1-(v[0]-x_0)^2-0.5*(v[1]-y_0)^2$ \n\n\nConsider the function \\(g(x)=0.1+exp(-x)x(1-x)\\) over [0,2]. Choose the scipy function and find the root of \\(g\\).\n\n\n#\n\n\nConsider the function \\(h(x,y)=0.1+exp(-x)x(1-x)\\) over [0,2]. Choose the scipy function and find the root of \\(g\\). to find the root of \\(g\\)?\n\n\n#",
    "crumbs": [
      "Exercises",
      "Methods"
    ]
  },
  {
    "objectID": "exercises/methods.html#interpolation",
    "href": "exercises/methods.html#interpolation",
    "title": "Methods",
    "section": "Interpolation",
    "text": "Interpolation\nWe consider the function \\(f(x) = sinc(\\lambda x) = \\frac{sin(\\lambda x)}{x}\\). Let \\(I=(x_i)_{i=[1,10]}\\) be a regularly spaced interval between -2 and +2, containing 10 points. Call \\(Y=(y_i)=f(x_i)\\) the values of \\(f\\) on this interval. Let \\(T\\) be a test set with 1000 regularly spaced points between -2.5 and 2.5.\nThe goal is to compare several ways interpolate function f on \\(T\\).\n\nExercise 2 Define f, I, Y, T with numpy.\n\n\n# \n\n\nExercise 3 Construct a stepwise approximation using numpy indexing\n\n\n# \n\n\nExercise 4 Plot it\n\n\n# \n\n\nExercise 5 Construct a linear approximation using numpy\n\n\n#\n\n\nExercise 6 Use scipy.interpolate to interpolate the data linearly. Compare the various extrapolation options.\n\n\n#\n\n\nExercise 7 Use scipy.interpolate to interolate the data with cubic splines. Compare the various extrapolation options.\n\n\n#\n\n\nExercise 8 Plot the results\n\n\n#",
    "crumbs": [
      "Exercises",
      "Methods"
    ]
  },
  {
    "objectID": "exercises/methods.html#discretization",
    "href": "exercises/methods.html#discretization",
    "title": "Methods",
    "section": "Discretization",
    "text": "Discretization\n\nExercise 9 Consider the AR1 process \\(y_t = \\rho y_{t-1} + \\epsilon_t\\) where \\(\\rho=0.9\\) and \\(\\epsilon_t=0.01\\). Use the quantecon library to discretize \\((y_t)\\) as a discrete markov chain.\n\n\n#\n\n\nExercise 10 Suppose \\(\\epsilon\\) follows a normal law with standard deviation \\(σ = 0.05\\). Take γ = 40 and define \\(U(x)=(x^{-γ})/(-γ)\\) We want to compute \\(C(\\epsilon) = \\mathbb{E} [U(exp(\\epsilon)) ]\\).\n\nChoose \\(N&gt;0\\) and construct a 1d vector with \\(N\\) realizations of \\(\\epsilon\\). Use it to compute the expectation.\nEstimate the standard deviation of this expectation.\nUse gauss-hermite method from numpy to compute the same expectation.\nCompare both methods.",
    "crumbs": [
      "Exercises",
      "Methods"
    ]
  },
  {
    "objectID": "exercises/lifetime_reward.html",
    "href": "exercises/lifetime_reward.html",
    "title": "Learning consumption rules",
    "section": "",
    "text": "This exercise is inspired from Individual learning about consumption by Todd Allen and Chris Carroll link and from Deep Learning for Solving Economic models by Maliar, Maliar and Winant link\nWe consider the following consumption saving problem. An agent receives random income \\(y_t = \\exp(\\epsilon_t)\\) where \\(\\epsilon_t\\sim \\mathcal{N}(\\sigma)\\) (\\(\\sigma\\) is the standard deviation.)\nConsumer starts the period with available income \\(w_t\\). The law of motion for available income is:\n\\[w_t = \\exp(\\epsilon_t) + (w_{t-1}-c_{t-1}) r\\]\nwhere consumption \\(c_t \\in ]0,w_t]\\) is chosen in each period in order to maximize:\n\\[E_t \\sum_{t=0}^T \\beta^t U(c_t)\\]\ngiven initial available income \\(w_0\\).\nIn the questions below, we will use the following calibration:\nThe theoretical solution to this problem is a concave function \\(\\varphi\\) such that \\(\\varphi(x)\\in ]0,x]\\) and \\(\\forall t,  c_t=\\varphi(w_t)\\). Qualitatively, agents accumulate savings, up to a certain point (a buffer stock), beyond which wealth is not increasing any more (in expectation).\nCarroll and Allen have noticed that the true solution can be approximated very well by a simple rule:\n\\[\\psi(x) = \\min(x, \\theta_0 + \\theta_1 (x - \\theta_0) )\\]\nThe main question they ask in the aforementioned paper is whether it is realistic that agents would learn good values of \\(\\theta_0\\) and \\(\\theta_1\\) by observing past experiences.\nWe would like to examine this result by learning the optimal rule using stochastic gradient descent.\nIn the whole notebook, we use JAX to perform the calculations.\nfrom jax import numpy as jnp\nclass Model:\n    pass\n# your code here\n# your code here\n# your code here\n# your code here\n# your code here",
    "crumbs": [
      "Exercises",
      "Learning consumption rules"
    ]
  },
  {
    "objectID": "exercises/lifetime_reward.html#learning-to-save",
    "href": "exercises/lifetime_reward.html#learning-to-save",
    "title": "Learning consumption rules",
    "section": "Learning to save",
    "text": "Learning to save\nWe now focus on the number of steps it takes to optimize \\(\\theta_0\\), \\(\\theta_1\\).__\n\nExercise 7 Implement a function ∇(θ:Vector, T, N)::Vector which computes the gradient of the objective w.r.t. θ==[θ_0,θ_1]__\n\n\n# your code here\n\n\nExercise 8 Implement a gradient descent algorithm to maximize \\(\\Xi^N(\\theta_0, \\theta_1)\\) using learning rate \\(\\lambda \\in ]0,1]\\). Stop after a predefined number of iterations. Compare convergence speed for different values of \\(\\lambda\\) and plot them on the \\(\\theta_0, \\theta_1\\) plan. How many steps does it take to enter the 1% error zone? The 5% and the 10% error zone?\n\n\n# your code here\n\nEven for big N, the evaluated value of ∇ are stochastic, and always slightly inaccurate. In average, they are non-biased and the algorithm converges in expectation (it fluctuates around the maximum). This is called the stochastic gradient method.\n\nExercise 9 What are the values of \\(N\\) and \\(\\lambda\\) which minimize the number of iterations before reaching the target zones (at 1%, 2%, etc…)? How many simulations periods does it correspond to? Would you say it is realistic that consumers learn from their own experience?\n\n\n# your code here",
    "crumbs": [
      "Exercises",
      "Learning consumption rules"
    ]
  }
]